{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7S_phf5KnhAu",
        "outputId": "9f7a770b-789d-40af-b0c7-a0911ec3f3d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'progNet-SAINT'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 46 (delta 16), reused 38 (delta 8), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (46/46), 882.79 KiB | 15.76 MiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://kekayan: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@github.com/kekayan/progNet-SAINT.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgQlU4gZqmcw",
        "outputId": "5a57eb70-1597-4b72-dda4-deb270128ed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -q einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVLYmdb5pLIX",
        "outputId": "da14418f-d291-44fc-c3e4-ee925d38fd6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/progNet-SAINT/src\n"
          ]
        }
      ],
      "source": [
        "%cd progNet-SAINT/src/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RE5tP4RspzL_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EZXlfvHJpPt3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"../data/clinical_and_other_features.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rJ4fblrQqBEq"
      },
      "outputs": [],
      "source": [
        "def data_split(X,y,nan_mask,indices):\n",
        "    x_d = {\n",
        "        'data': X.values[indices],\n",
        "        'mask': nan_mask.values[indices]\n",
        "    }\n",
        "\n",
        "    if x_d['data'].shape != x_d['mask'].shape:\n",
        "        raise'Shape of data not same as that of nan mask!'\n",
        "\n",
        "    y_d = {\n",
        "        'data': y[indices].reshape(-1, 1)\n",
        "    }\n",
        "    return x_d, y_d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9ASN-qSsqHEA"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class DataSetCatCon(Dataset):\n",
        "    def __init__(self, X, Y, cat_cols,task='clf',continuous_mean_std=None):\n",
        "\n",
        "        cat_cols = list(cat_cols)\n",
        "        X_mask =  X['mask'].copy()\n",
        "        X = X['data'].copy()\n",
        "        con_cols = list(set(np.arange(X.shape[1])) - set(cat_cols))\n",
        "        self.X1 = X[:,cat_cols].copy().astype(np.int64) #categorical columns\n",
        "        self.X2 = X[:,con_cols].copy().astype(np.float32) #numerical columns\n",
        "        self.X1_mask = X_mask[:,cat_cols].copy().astype(np.int64) #categorical columns\n",
        "        self.X2_mask = X_mask[:,con_cols].copy().astype(np.int64) #numerical columns\n",
        "        self.y = Y['data']#.astype(np.float32) if regression\n",
        "        self.cls = np.zeros_like(self.y,dtype=int)\n",
        "        self.cls_mask = np.ones_like(self.y,dtype=int)\n",
        "        if continuous_mean_std is not None:\n",
        "            mean, std = continuous_mean_std\n",
        "            self.X2 = (self.X2 - mean) / std\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # X1 has categorical data, X2 has continuous\n",
        "        return np.concatenate((self.cls[idx], self.X1[idx])), self.X2[idx],self.y[idx], np.concatenate((self.cls_mask[idx], self.X1_mask[idx])), self.X2_mask[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9VzlurkiNJs-"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(df):\n",
        "  df1 = df.drop(['Overall Near-complete Response:  Looser Definition','Near-complete Response (Graded Measure)'],axis=1)\n",
        "  df1.columns = df1.columns.str.strip()\n",
        "  pathologic_response_to_neoadjuvant_therapy = ['Pathologic response to Neoadjuvant therapy: Pathologic stage (T) following neoadjuvant therapy',\n",
        "        'Pathologic response to Neoadjuvant therapy:  Pathologic stage (N) following neoadjuvant therapy',\n",
        "        'Pathologic response to Neoadjuvant therapy:  Pathologic stage (M) following neoadjuvant therapy']\n",
        "  df1.drop(pathologic_response_to_neoadjuvant_therapy, axis=1, inplace=True)\n",
        "  X = df1.drop('Overall Near-complete Response:  Stricter Definition',axis=1)\n",
        "  y = df1['Overall Near-complete Response:  Stricter Definition']\n",
        "  cont_columns = ['Date of Birth (Days)', 'Days to Surgery (from the date of diagnosis)', 'Age at last contact in EMR f/u(days)(from the date of diagnosis) ,last time patient known to be alive, unless age of death is reported(in such case the age of death',\n",
        "    'Age at mammo (days)', 'Days to distant recurrence(from the date of diagnosis)', 'Days to local recurrence (from the date of diagnosis)',\n",
        "    'Days to death (from the date of diagnosis)', 'Days to last local recurrence free assessment (from the date of diagnosis)',\n",
        "    ]\n",
        "  categorical_columns = list(set(X.columns) - set(cont_columns))\n",
        "\n",
        "  # convert categorical columns to str type\n",
        "  X[categorical_columns] = X[categorical_columns].astype(str)\n",
        "\n",
        "  cat_idxs = [X.columns.get_loc(c) for c in categorical_columns]\n",
        "  con_idxs = [X.columns.get_loc(c) for c in cont_columns]\n",
        "  X[\"Set\"] = np.random.choice([\"train\", \"valid\", \"test\"], p = [.65, .15, .2], size=(X.shape[0],))\n",
        "\n",
        "  train_indices = X[X.Set==\"train\"].index\n",
        "  valid_indices = X[X.Set==\"valid\"].index\n",
        "  test_indices = X[X.Set==\"test\"].index\n",
        "\n",
        "  X = X.drop(columns=['Set'])\n",
        "  temp = X.fillna(\"MissingValue\")\n",
        "#   creates a bert style mask for the missing values\n",
        "  nan_mask = temp.ne(\"MissingValue\").astype(int)\n",
        "\n",
        "  cat_dims = []\n",
        "  for col in categorical_columns:\n",
        "      X[col] = X[col].fillna(\"MissingValue\")\n",
        "      l_enc = LabelEncoder()\n",
        "      X[col] = l_enc.fit_transform(X[col].values)\n",
        "      cat_dims.append(len(l_enc.classes_))\n",
        "\n",
        "  for col in cont_columns:\n",
        "      X[col] = pd.to_numeric(X[col], errors='coerce')\n",
        "      X.fillna(X.loc[train_indices, col].mean(), inplace=True)\n",
        "  y = y.values\n",
        "  l_enc = LabelEncoder()\n",
        "  y = l_enc.fit_transform(y)\n",
        "  X_train, y_train = data_split(X,y,nan_mask,train_indices)\n",
        "  X_valid, y_valid = data_split(X,y,nan_mask,valid_indices)\n",
        "  X_test, y_test = data_split(X,y,nan_mask,test_indices)\n",
        "  train_mean, train_std = np.array(X_train['data'][:,con_idxs],dtype=np.float32).mean(0), np.array(X_train['data'][:,con_idxs],dtype=np.float32).std(0)\n",
        "  train_std = np.where(train_std < 1e-6, 1e-6, train_std)\n",
        "  continuous_mean_std = np.array([train_mean,train_std]).astype(np.float32)\n",
        "  train_ds = DataSetCatCon(X_train, y_train, cat_idxs,'clf',continuous_mean_std)\n",
        "  trainloader = DataLoader(train_ds, batch_size=64, shuffle=True,num_workers=1)\n",
        "\n",
        "  valid_ds = DataSetCatCon(X_valid, y_valid, cat_idxs,'clf', continuous_mean_std)\n",
        "  validloader = DataLoader(valid_ds, batch_size=64, shuffle=False,num_workers=1)\n",
        "\n",
        "  test_ds = DataSetCatCon(X_test, y_test, cat_idxs,'clf', continuous_mean_std)\n",
        "  testloader = DataLoader(test_ds, batch_size=64, shuffle=False,num_workers=1)\n",
        "  y_dim = len(np.unique(y_train['data'][:,0]))\n",
        "\n",
        "  cat_dims = np.append(np.array([1]),np.array(cat_dims)).astype(int) #Appending 1 for CLS token, this is later used to generate embeddings.\n",
        "\n",
        "  return trainloader, validloader, testloader, cat_dims, con_idxs , cat_idxs, y_dim , continuous_mean_std , X_train, y_train, X_valid, y_valid, X_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "flZw24r6qI4M"
      },
      "outputs": [],
      "source": [
        "trainloader, validloader, testloader, cat_dims, con_idxs , cat_idxs, y_dim , continuous_mean_std, X_train, y_train, X_valid, y_valid, X_test, y_test = prepare_dataset(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CxDCGF1hJQqm"
      },
      "outputs": [],
      "source": [
        "from models import SAINT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "upuJoXE5qkHO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from models import SAINT\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from utils import count_parameters, classification_scores, mean_sq_error\n",
        "from augmentations import embed_data_mask\n",
        "from augmentations import add_noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "awsDTKYwqtrz"
      },
      "outputs": [],
      "source": [
        "from pretraining import SAINT_pretrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3V75GTN5qvA7"
      },
      "outputs": [],
      "source": [
        "opt_dict = {\n",
        "    'd_task': 'clf',\n",
        "    'dtask': 'clf',\n",
        "    'task': 'multiclass',\n",
        "    'batchsize': 32,\n",
        "    'pt_aug': ['mixup', 'cutmix'],\n",
        "    'pt_aug_lam': 0.1,\n",
        "    'pretrain_epochs': 250, #50\n",
        "    'nce_temp': 0.7,\n",
        "    'lam0': 0.5,\n",
        "    'lam1': 10,\n",
        "    'lam2': 1,\n",
        "    'lam3': 10,\n",
        "    'pt_projhead_style': 'diff',\n",
        "    'pt_tasks': ['contrastive','denoising'],\n",
        "    'mixup_lam': 0.3,\n",
        "    'ssl_samples': 312,\n",
        "    'lr':0.0001,\n",
        "    'train_noise_type':None,\n",
        "    'train_noise_level':0,\n",
        "}\n",
        "\n",
        "class AttributeDict(dict):\n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__\n",
        "\n",
        "opt = AttributeDict(opt_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NkrPp-RsJQqn"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BCqdQ2JbqwmR"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYCUsqCOqzPG",
        "outputId": "9783aa77-6dde-4d13-959e-dcbc457109d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretraining begins!\n",
            "Epoch: 0, Running Loss: 280153.9169921875\n",
            "Epoch: 1, Running Loss: 215140.4619140625\n",
            "Epoch: 2, Running Loss: 199677.81787109375\n",
            "Epoch: 3, Running Loss: 146509.00463867188\n",
            "Epoch: 4, Running Loss: 50692.87957763672\n",
            "Epoch: 5, Running Loss: 39251.200592041016\n",
            "Epoch: 6, Running Loss: 23956.354095458984\n",
            "Epoch: 7, Running Loss: 28442.431365966797\n",
            "Epoch: 8, Running Loss: 16023.31234741211\n",
            "Epoch: 9, Running Loss: 16396.075439453125\n",
            "Epoch: 10, Running Loss: 20169.283721923828\n",
            "Epoch: 11, Running Loss: 19488.39178466797\n",
            "Epoch: 12, Running Loss: 18820.40350341797\n",
            "Epoch: 13, Running Loss: 28228.56915283203\n",
            "Epoch: 14, Running Loss: 19507.416412353516\n",
            "Epoch: 15, Running Loss: 14537.26237487793\n",
            "Epoch: 16, Running Loss: 18519.408782958984\n",
            "Epoch: 17, Running Loss: 14649.96566772461\n",
            "Epoch: 18, Running Loss: 15363.856506347656\n",
            "Epoch: 19, Running Loss: 11152.736328125\n",
            "Epoch: 20, Running Loss: 11340.501495361328\n",
            "Epoch: 21, Running Loss: 11282.285034179688\n",
            "Epoch: 22, Running Loss: 19057.414291381836\n",
            "Epoch: 23, Running Loss: 12472.298355102539\n",
            "Epoch: 24, Running Loss: 17359.063552856445\n",
            "Epoch: 25, Running Loss: 17478.71614074707\n",
            "Epoch: 26, Running Loss: 14478.37857055664\n",
            "Epoch: 27, Running Loss: 14088.76693725586\n",
            "Epoch: 28, Running Loss: 11480.579330444336\n",
            "Epoch: 29, Running Loss: 14728.21076965332\n",
            "Epoch: 30, Running Loss: 10374.901016235352\n",
            "Epoch: 31, Running Loss: 10148.062561035156\n",
            "Epoch: 32, Running Loss: 10494.853103637695\n",
            "Epoch: 33, Running Loss: 9772.478164672852\n",
            "Epoch: 34, Running Loss: 14603.835021972656\n",
            "Epoch: 35, Running Loss: 15283.925735473633\n",
            "Epoch: 36, Running Loss: 11948.169708251953\n",
            "Epoch: 37, Running Loss: 13068.692428588867\n",
            "Epoch: 38, Running Loss: 14876.741088867188\n",
            "Epoch: 39, Running Loss: 10122.775756835938\n",
            "Epoch: 40, Running Loss: 10382.32470703125\n",
            "Epoch: 41, Running Loss: 10589.035888671875\n",
            "Epoch: 42, Running Loss: 13861.061477661133\n",
            "Epoch: 43, Running Loss: 16206.642364501953\n",
            "Epoch: 44, Running Loss: 11413.111373901367\n",
            "Epoch: 45, Running Loss: 11447.617202758789\n",
            "Epoch: 46, Running Loss: 16557.186096191406\n",
            "Epoch: 47, Running Loss: 13086.045227050781\n",
            "Epoch: 48, Running Loss: 18515.84031677246\n",
            "Epoch: 49, Running Loss: 13928.832946777344\n",
            "Epoch: 50, Running Loss: 12496.996826171875\n",
            "Epoch: 51, Running Loss: 16524.4111328125\n",
            "Epoch: 52, Running Loss: 14937.102493286133\n",
            "Epoch: 53, Running Loss: 10986.283920288086\n",
            "Epoch: 54, Running Loss: 10330.549407958984\n",
            "Epoch: 55, Running Loss: 11368.607116699219\n",
            "Epoch: 56, Running Loss: 29398.05859375\n",
            "Epoch: 57, Running Loss: 12520.518783569336\n",
            "Epoch: 58, Running Loss: 14124.825271606445\n",
            "Epoch: 59, Running Loss: 14942.027938842773\n",
            "Epoch: 60, Running Loss: 19549.267700195312\n",
            "Epoch: 61, Running Loss: 13232.588729858398\n",
            "Epoch: 62, Running Loss: 13912.373138427734\n",
            "Epoch: 63, Running Loss: 12398.951919555664\n",
            "Epoch: 64, Running Loss: 12710.829635620117\n",
            "Epoch: 65, Running Loss: 15354.993179321289\n",
            "Epoch: 66, Running Loss: 10592.683959960938\n",
            "Epoch: 67, Running Loss: 9690.184127807617\n",
            "Epoch: 68, Running Loss: 10366.755386352539\n",
            "Epoch: 69, Running Loss: 12096.536224365234\n",
            "Epoch: 70, Running Loss: 9878.667495727539\n",
            "Epoch: 71, Running Loss: 9592.444747924805\n",
            "Epoch: 72, Running Loss: 20219.48570251465\n",
            "Epoch: 73, Running Loss: 10833.901504516602\n",
            "Epoch: 74, Running Loss: 13844.535339355469\n",
            "Epoch: 75, Running Loss: 13235.735794067383\n",
            "Epoch: 76, Running Loss: 8882.333602905273\n",
            "Epoch: 77, Running Loss: 9820.235931396484\n",
            "Epoch: 78, Running Loss: 9700.334671020508\n",
            "Epoch: 79, Running Loss: 13405.184600830078\n",
            "Epoch: 80, Running Loss: 11807.181640625\n",
            "Epoch: 81, Running Loss: 10267.050186157227\n",
            "Epoch: 82, Running Loss: 12484.343872070312\n",
            "Epoch: 83, Running Loss: 16140.392807006836\n",
            "Epoch: 84, Running Loss: 18531.950164794922\n",
            "Epoch: 85, Running Loss: 9257.959259033203\n",
            "Epoch: 86, Running Loss: 14271.584899902344\n",
            "Epoch: 87, Running Loss: 29040.150451660156\n",
            "Epoch: 88, Running Loss: 11602.443374633789\n",
            "Epoch: 89, Running Loss: 9693.283386230469\n",
            "Epoch: 90, Running Loss: 18775.409072875977\n",
            "Epoch: 91, Running Loss: 17638.492401123047\n",
            "Epoch: 92, Running Loss: 10755.351287841797\n",
            "Epoch: 93, Running Loss: 12099.01252746582\n",
            "Epoch: 94, Running Loss: 9866.597686767578\n",
            "Epoch: 95, Running Loss: 12780.87759399414\n",
            "Epoch: 96, Running Loss: 23155.419143676758\n",
            "Epoch: 97, Running Loss: 12387.901885986328\n",
            "Epoch: 98, Running Loss: 11670.69612121582\n",
            "Epoch: 99, Running Loss: 9449.545455932617\n",
            "Epoch: 100, Running Loss: 9147.963668823242\n",
            "Epoch: 101, Running Loss: 8711.432723999023\n",
            "Epoch: 102, Running Loss: 18154.18505859375\n",
            "Epoch: 103, Running Loss: 15240.972259521484\n",
            "Epoch: 104, Running Loss: 25981.39747619629\n",
            "Epoch: 105, Running Loss: 12810.111846923828\n",
            "Epoch: 106, Running Loss: 11300.91162109375\n",
            "Epoch: 107, Running Loss: 15543.03872680664\n",
            "Epoch: 108, Running Loss: 8865.117813110352\n",
            "Epoch: 109, Running Loss: 11869.5380859375\n",
            "Epoch: 110, Running Loss: 14406.38687133789\n",
            "Epoch: 111, Running Loss: 10210.410247802734\n",
            "Epoch: 112, Running Loss: 23365.17152404785\n",
            "Epoch: 113, Running Loss: 15091.548202514648\n",
            "Epoch: 114, Running Loss: 21247.931091308594\n",
            "Epoch: 115, Running Loss: 11229.572494506836\n",
            "Epoch: 116, Running Loss: 9568.463775634766\n",
            "Epoch: 117, Running Loss: 10889.073150634766\n",
            "Epoch: 118, Running Loss: 11515.04118347168\n",
            "Epoch: 119, Running Loss: 9463.919708251953\n",
            "Epoch: 120, Running Loss: 8727.511505126953\n",
            "Epoch: 121, Running Loss: 13723.014831542969\n",
            "Epoch: 122, Running Loss: 9395.344116210938\n",
            "Epoch: 123, Running Loss: 8399.097610473633\n",
            "Epoch: 124, Running Loss: 8428.81771850586\n",
            "Epoch: 125, Running Loss: 7859.52360534668\n",
            "Epoch: 126, Running Loss: 8699.897872924805\n",
            "Epoch: 127, Running Loss: 9027.3779296875\n",
            "Epoch: 128, Running Loss: 8120.3836669921875\n",
            "Epoch: 129, Running Loss: 14163.198989868164\n",
            "Epoch: 130, Running Loss: 11248.145874023438\n",
            "Epoch: 131, Running Loss: 13311.462707519531\n",
            "Epoch: 132, Running Loss: 13853.4404296875\n",
            "Epoch: 133, Running Loss: 13381.716705322266\n",
            "Epoch: 134, Running Loss: 14523.43618774414\n",
            "Epoch: 135, Running Loss: 9867.541778564453\n",
            "Epoch: 136, Running Loss: 12017.653778076172\n",
            "Epoch: 137, Running Loss: 13535.835556030273\n",
            "Epoch: 138, Running Loss: 9567.991394042969\n",
            "Epoch: 139, Running Loss: 13881.303024291992\n",
            "Epoch: 140, Running Loss: 19169.77471923828\n",
            "Epoch: 141, Running Loss: 21224.631774902344\n",
            "Epoch: 142, Running Loss: 22438.38410949707\n",
            "Epoch: 143, Running Loss: 13770.446411132812\n",
            "Epoch: 144, Running Loss: 15248.838806152344\n",
            "Epoch: 145, Running Loss: 27433.802993774414\n",
            "Epoch: 146, Running Loss: 17566.40023803711\n",
            "Epoch: 147, Running Loss: 10965.097961425781\n",
            "Epoch: 148, Running Loss: 13551.454879760742\n",
            "Epoch: 149, Running Loss: 9077.896270751953\n",
            "Epoch: 150, Running Loss: 9632.977592468262\n",
            "Epoch: 151, Running Loss: 8774.264068603516\n",
            "Epoch: 152, Running Loss: 8962.549575805664\n",
            "Epoch: 153, Running Loss: 8789.811096191406\n",
            "Epoch: 154, Running Loss: 9166.161544799805\n",
            "Epoch: 155, Running Loss: 8754.929138183594\n",
            "Epoch: 156, Running Loss: 9106.284255981445\n",
            "Epoch: 157, Running Loss: 9011.866485595703\n",
            "Epoch: 158, Running Loss: 10565.318466186523\n",
            "Epoch: 159, Running Loss: 14464.660095214844\n",
            "Epoch: 160, Running Loss: 14633.276138305664\n",
            "Epoch: 161, Running Loss: 10749.133514404297\n",
            "Epoch: 162, Running Loss: 10337.874435424805\n",
            "Epoch: 163, Running Loss: 10460.162292480469\n",
            "Epoch: 164, Running Loss: 13424.716125488281\n",
            "Epoch: 165, Running Loss: 15143.318450927734\n",
            "Epoch: 166, Running Loss: 9126.573654174805\n",
            "Epoch: 167, Running Loss: 9819.092575073242\n",
            "Epoch: 168, Running Loss: 8629.806640625\n",
            "Epoch: 169, Running Loss: 8971.946563720703\n",
            "Epoch: 170, Running Loss: 8768.852493286133\n",
            "Epoch: 171, Running Loss: 8895.072280883789\n",
            "Epoch: 172, Running Loss: 9333.533142089844\n",
            "Epoch: 173, Running Loss: 13510.926208496094\n",
            "Epoch: 174, Running Loss: 9588.507446289062\n",
            "Epoch: 175, Running Loss: 11160.011322021484\n",
            "Epoch: 176, Running Loss: 8598.027603149414\n",
            "Epoch: 177, Running Loss: 10387.403823852539\n",
            "Epoch: 178, Running Loss: 8931.540954589844\n",
            "Epoch: 179, Running Loss: 9664.854690551758\n",
            "Epoch: 180, Running Loss: 8407.748794555664\n",
            "Epoch: 181, Running Loss: 8514.780014038086\n",
            "Epoch: 182, Running Loss: 15891.73503112793\n",
            "Epoch: 183, Running Loss: 28860.668838500977\n",
            "Epoch: 184, Running Loss: 14587.59504699707\n",
            "Epoch: 185, Running Loss: 9022.814727783203\n",
            "Epoch: 186, Running Loss: 9957.511657714844\n",
            "Epoch: 187, Running Loss: 18453.48304748535\n",
            "Epoch: 188, Running Loss: 11125.604858398438\n",
            "Epoch: 189, Running Loss: 12190.472045898438\n",
            "Epoch: 190, Running Loss: 9458.654830932617\n",
            "Epoch: 191, Running Loss: 18948.29867553711\n",
            "Epoch: 192, Running Loss: 11270.44839477539\n",
            "Epoch: 193, Running Loss: 19698.044326782227\n",
            "Epoch: 194, Running Loss: 21367.650512695312\n",
            "Epoch: 195, Running Loss: 13411.63362121582\n",
            "Epoch: 196, Running Loss: 10060.235061645508\n",
            "Epoch: 197, Running Loss: 11436.818115234375\n",
            "Epoch: 198, Running Loss: 11601.505004882812\n",
            "Epoch: 199, Running Loss: 13323.786254882812\n",
            "Epoch: 200, Running Loss: 13795.70182800293\n",
            "Epoch: 201, Running Loss: 12003.587600708008\n",
            "Epoch: 202, Running Loss: 9217.795700073242\n",
            "Epoch: 203, Running Loss: 8728.926071166992\n",
            "Epoch: 204, Running Loss: 8522.75747680664\n",
            "Epoch: 205, Running Loss: 8018.932876586914\n",
            "Epoch: 206, Running Loss: 8338.733901977539\n",
            "Epoch: 207, Running Loss: 8985.009872436523\n",
            "Epoch: 208, Running Loss: 8646.50439453125\n",
            "Epoch: 209, Running Loss: 8227.109603881836\n",
            "Epoch: 210, Running Loss: 8472.336669921875\n",
            "Epoch: 211, Running Loss: 13790.520263671875\n",
            "Epoch: 212, Running Loss: 11652.223205566406\n",
            "Epoch: 213, Running Loss: 9284.957290649414\n",
            "Epoch: 214, Running Loss: 12131.654602050781\n",
            "Epoch: 215, Running Loss: 8073.642471313477\n",
            "Epoch: 216, Running Loss: 8752.126754760742\n",
            "Epoch: 217, Running Loss: 7552.765182495117\n",
            "Epoch: 218, Running Loss: 7541.318344116211\n",
            "Epoch: 219, Running Loss: 7628.422256469727\n",
            "Epoch: 220, Running Loss: 22286.65737915039\n",
            "Epoch: 221, Running Loss: 13094.113876342773\n",
            "Epoch: 222, Running Loss: 10562.704284667969\n",
            "Epoch: 223, Running Loss: 10702.661148071289\n",
            "Epoch: 224, Running Loss: 7772.708877563477\n",
            "Epoch: 225, Running Loss: 8413.113723754883\n",
            "Epoch: 226, Running Loss: 8745.274841308594\n",
            "Epoch: 227, Running Loss: 9576.777450561523\n",
            "Epoch: 228, Running Loss: 9149.061508178711\n",
            "Epoch: 229, Running Loss: 8840.913345336914\n",
            "Epoch: 230, Running Loss: 10116.7451171875\n",
            "Epoch: 231, Running Loss: 9874.483825683594\n",
            "Epoch: 232, Running Loss: 7731.03630065918\n",
            "Epoch: 233, Running Loss: 8300.386108398438\n",
            "Epoch: 234, Running Loss: 8599.017272949219\n",
            "Epoch: 235, Running Loss: 13531.272598266602\n",
            "Epoch: 236, Running Loss: 12339.003890991211\n",
            "Epoch: 237, Running Loss: 11009.795639038086\n",
            "Epoch: 238, Running Loss: 14303.451354980469\n",
            "Epoch: 239, Running Loss: 12249.981750488281\n",
            "Epoch: 240, Running Loss: 8649.745147705078\n",
            "Epoch: 241, Running Loss: 11298.537551879883\n",
            "Epoch: 242, Running Loss: 24095.78382873535\n",
            "Epoch: 243, Running Loss: 15299.427490234375\n",
            "Epoch: 244, Running Loss: 13900.453720092773\n",
            "Epoch: 245, Running Loss: 8595.21167755127\n",
            "Epoch: 246, Running Loss: 12205.005569458008\n",
            "Epoch: 247, Running Loss: 10516.405364990234\n",
            "Epoch: 248, Running Loss: 16337.227920532227\n",
            "Epoch: 249, Running Loss: 12714.369354248047\n",
            "END OF PRETRAINING!\n"
          ]
        }
      ],
      "source": [
        "model = SAINT(\n",
        "categories = tuple(cat_dims),\n",
        "num_continuous = len(con_idxs),\n",
        "dim = 32,              # embedding dimension\n",
        "dim_out = 1,\n",
        "depth = 1,             # depth of the network (nr. of transformer blocks)\n",
        "heads = 8,             # number of attention heads\n",
        "attn_dropout = 0.1,\n",
        "ff_dropout = 0.1,\n",
        "mlp_hidden_mults = (4, 2),\n",
        "cont_embeddings = 'MLP', # options: 'MLP', 'linear', 'hybrid' (MLP with continuous embeddings concatenated to the transformer block outputs)\n",
        "attentiontype = 'colrow', # options: 'col', 'row', 'colrow', 'colrowv2'\n",
        "final_mlp_style = 'sep',\n",
        "y_dim = y_dim\n",
        ")\n",
        "model.to(device)\n",
        "model = SAINT_pretrain(model, cat_idxs,X_train,y_train, continuous_mean_std, opt, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sXcmKvsJQqo"
      },
      "source": [
        "### Finetune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "z4Vq0gpcPZoC"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv('../data/clinical_and_other_features_filtered.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvrEdvohOOFh",
        "outputId": "5767acbe-831f-4d44-9ea1-0321926d25d2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(922, 84)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KQmMWbROPgs",
        "outputId": "0311a83b-7cc1-4a28-9e55-efd28e08df52"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(312, 84)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efdaifJ-Sljg",
        "outputId": "8a08dd86-eb06-4243-d937-eb414ff5ec1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df.shape[1] == df2.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "i5etGHMlPWoz"
      },
      "outputs": [],
      "source": [
        "trainloader, validloader, testloader, cat_dims, con_idxs , cat_idxs, y_dim , continuous_mean_std, X_train, y_train, X_valid, y_valid, X_test, y_test = prepare_dataset(df2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzxU_sUeq1un",
        "outputId": "8717a1a9-c7bf-49b3-9da9-e5e4eee1838f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We are in semi-supervised learning case\n"
          ]
        }
      ],
      "source": [
        "print('We are in semi-supervised learning case')\n",
        "\n",
        "train_bsize = min(opt.ssl_samples//4,opt.batchsize)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = DataSetCatCon(X_train, y_train, cat_idxs,opt.dtask,continuous_mean_std)\n",
        "trainloader = DataLoader(train_ds, batch_size=train_bsize, shuffle=True,num_workers=2)"
      ],
      "metadata": {
        "id": "dEWcfDcITEjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Kexg0KluLMvi"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "QH8tAREWBnE5"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.AdamW(model.parameters(),lr=0.001, betas=(0.9,0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "0Iws3MmrHZ6H"
      },
      "outputs": [],
      "source": [
        "device = 'cuda'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "7OqZChrQH4kM"
      },
      "outputs": [],
      "source": [
        "modelsave_path='outputs'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir outputs\n"
      ],
      "metadata": {
        "id": "XOHzxHHOOtYM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre train"
      ],
      "metadata": {
        "id": "LiHBfCayS0zp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start K-Fold\n",
        "from sklearn.model_selection import KFold\n",
        "# Define the number of splits\n",
        "n_splits = 4\n",
        "best_valid_auroc = 0\n",
        "best_valid_accuracy = 0\n",
        "best_test_auroc = 0\n",
        "best_test_accuracy = 0\n",
        "best_valid_rmse = 100000\n",
        "# Define the KFold object\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store the train and validation indices for each fold\n",
        "train_indices_list = []\n",
        "valid_indices_list = []\n",
        "\n",
        "# Loop over the splits and get the train and validation indices for each fold\n",
        "for train_indices, valid_indices in kf.split(X_train['data']):\n",
        "    train_indices_list.append(train_indices)\n",
        "    valid_indices_list.append(valid_indices)\n",
        "best_valid_accuracy_list = []\n",
        "# Loop over the folds and train the model on each fold\n",
        "for fold in range(n_splits):\n",
        "    # Get the train and validation indices for this fold\n",
        "    train_indices = train_indices_list[fold]\n",
        "    valid_indices = valid_indices_list[fold]\n",
        "\n",
        "    # Create the train and validation datasets and dataloaders for this fold\n",
        "    train_ds = DataSetCatCon(X_train, y_train, cat_idxs,opt.dtask,continuous_mean_std)\n",
        "    trainloader = DataLoader(train_ds, batch_size=train_bsize,num_workers=2, sampler=torch.utils.data.SubsetRandomSampler(train_indices))\n",
        "    valid_ds = DataSetCatCon(X_train, y_train, cat_idxs,opt.dtask,continuous_mean_std)\n",
        "    validloader = DataLoader(valid_ds, batch_size=train_bsize, shuffle=False,num_workers=2, sampler=torch.utils.data.SubsetRandomSampler(valid_indices))\n",
        "    print(f'Training begins now for # {fold} Fold.')\n",
        "    # Train the model on this fold\n",
        "    for epoch in range(300):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            optimizer.zero_grad()\n",
        "            # x_categ is the the categorical data, with y appended as last feature. x_cont has continuous data. cat_mask is an array of ones same shape as x_categ except for last column(corresponding to y's) set to 0s. con_mask is an array of ones same shape as x_cont.\n",
        "            x_categ, x_cont, y_gts, cat_mask, con_mask = data[0].to(device), data[1].to(device),data[2].to(device),data[3].to(device),data[4].to(device)\n",
        "            if opt.train_noise_type is not None and opt.train_noise_level>0:\n",
        "                noise_dict = {\n",
        "                    'noise_type' : opt.train_noise_type,\n",
        "                    'lambda' : opt.train_noise_level\n",
        "                }\n",
        "                if opt.train_noise_type == 'cutmix':\n",
        "                    x_categ, x_cont = add_noise(x_categ,x_cont, noise_params = noise_dict)\n",
        "                elif opt.train_noise_type == 'missing':\n",
        "                    cat_mask, con_mask = add_noise(cat_mask, con_mask, noise_params = noise_dict)\n",
        "            # We are converting the data to embeddings in the next step\n",
        "            _ , x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask,model)\n",
        "            reps = model.transformer(x_categ_enc, x_cont_enc)\n",
        "            # select only the representations corresponding to y and apply mlp on it in the next step to get the predictions.\n",
        "            y_reps = reps[:,0,:]\n",
        "\n",
        "            y_outs = model.mlpfory(y_reps)\n",
        "            if opt.task == 'regression':\n",
        "                loss = criterion(y_outs,y_gts)\n",
        "            else:\n",
        "                loss = criterion(y_outs,y_gts.squeeze())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "        print(running_loss)\n",
        "        if epoch%5==0:\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    if opt.task in ['binary','multiclass']:\n",
        "                        accuracy, auroc = classification_scores(model, validloader, device, opt.task)\n",
        "                        test_accuracy, test_auroc = classification_scores(model, testloader, device, opt.task)\n",
        "\n",
        "                        print('[EPOCH %d] VALID ACCURACY: %.3f' %\n",
        "                            (epoch + 1, accuracy ))\n",
        "                        print('[EPOCH %d] TEST ACCURACY: %.3f' %\n",
        "                            (epoch + 1, test_accuracy ))\n",
        "\n",
        "                        if opt.task =='multiclass':\n",
        "                            if accuracy > best_valid_accuracy:\n",
        "                                best_valid_accuracy = accuracy\n",
        "    best_valid_accuracy_list.append(best_valid_accuracy)\n",
        "\n",
        "# End K Fold\n",
        "# Calculate the average of the best accuracy from each fold\n",
        "average_best_valid_accuracy = sum(best_valid_accuracy_list) / len(best_valid_accuracy_list)\n",
        "print('Average best validation accuracy from all folds:', average_best_valid_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm0lAw_fpuuy",
        "outputId": "dc095df8-3129-4d2a-b47f-bba417d47a89"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training begins now for # 0 Fold.\n",
            "35.366769313812256\n",
            "[EPOCH 1] VALID ACCURACY: 19.231\n",
            "[EPOCH 1] TEST ACCURACY: 19.355\n",
            "26.171658158302307\n",
            "21.151028633117676\n",
            "7.632342755794525\n",
            "5.666531801223755\n",
            "5.502130806446075\n",
            "[EPOCH 6] VALID ACCURACY: 75.000\n",
            "[EPOCH 6] TEST ACCURACY: 62.903\n",
            "4.870699524879456\n",
            "4.811701416969299\n",
            "4.827940940856934\n",
            "4.829614639282227\n",
            "4.8000829219818115\n",
            "[EPOCH 11] VALID ACCURACY: 75.000\n",
            "[EPOCH 11] TEST ACCURACY: 62.903\n",
            "4.7864033579826355\n",
            "4.902125716209412\n",
            "4.8491798639297485\n",
            "4.779815256595612\n",
            "4.790923833847046\n",
            "[EPOCH 16] VALID ACCURACY: 75.000\n",
            "[EPOCH 16] TEST ACCURACY: 62.903\n",
            "4.745297193527222\n",
            "4.710852324962616\n",
            "4.815933287143707\n",
            "4.838185429573059\n",
            "4.749223470687866\n",
            "[EPOCH 21] VALID ACCURACY: 75.000\n",
            "[EPOCH 21] TEST ACCURACY: 62.903\n",
            "4.828158736228943\n",
            "4.9449397921562195\n",
            "4.765003502368927\n",
            "4.744252145290375\n",
            "4.686018943786621\n",
            "[EPOCH 26] VALID ACCURACY: 75.000\n",
            "[EPOCH 26] TEST ACCURACY: 62.903\n",
            "4.690520226955414\n",
            "4.663056433200836\n",
            "4.704388320446014\n",
            "4.943358659744263\n",
            "4.818537473678589\n",
            "[EPOCH 31] VALID ACCURACY: 75.000\n",
            "[EPOCH 31] TEST ACCURACY: 62.903\n",
            "4.683345198631287\n",
            "4.868184506893158\n",
            "4.9722835421562195\n",
            "4.791409611701965\n",
            "4.6279332637786865\n",
            "[EPOCH 36] VALID ACCURACY: 75.000\n",
            "[EPOCH 36] TEST ACCURACY: 62.903\n",
            "4.7103301882743835\n",
            "4.658837020397186\n",
            "4.634909629821777\n",
            "4.632579684257507\n",
            "4.923757433891296\n",
            "[EPOCH 41] VALID ACCURACY: 75.000\n",
            "[EPOCH 41] TEST ACCURACY: 62.903\n",
            "4.651376366615295\n",
            "4.679369270801544\n",
            "4.587125718593597\n",
            "4.6880380511283875\n",
            "4.654877543449402\n",
            "[EPOCH 46] VALID ACCURACY: 75.000\n",
            "[EPOCH 46] TEST ACCURACY: 62.903\n",
            "4.785447537899017\n",
            "4.849998593330383\n",
            "4.782181143760681\n",
            "4.794636845588684\n",
            "4.798520267009735\n",
            "[EPOCH 51] VALID ACCURACY: 75.000\n",
            "[EPOCH 51] TEST ACCURACY: 62.903\n",
            "4.718438625335693\n",
            "4.890917003154755\n",
            "4.674542307853699\n",
            "4.77765828371048\n",
            "4.787094473838806\n",
            "[EPOCH 56] VALID ACCURACY: 75.000\n",
            "[EPOCH 56] TEST ACCURACY: 62.903\n",
            "4.74907523393631\n",
            "5.080369591712952\n",
            "4.886236369609833\n",
            "4.7803515791893005\n",
            "4.652277290821075\n",
            "[EPOCH 61] VALID ACCURACY: 75.000\n",
            "[EPOCH 61] TEST ACCURACY: 62.903\n",
            "4.664820313453674\n",
            "4.536848723888397\n",
            "4.5901318192481995\n",
            "4.390330612659454\n",
            "4.960616588592529\n",
            "[EPOCH 66] VALID ACCURACY: 75.000\n",
            "[EPOCH 66] TEST ACCURACY: 62.903\n",
            "4.500540196895599\n",
            "4.898786544799805\n",
            "4.966273128986359\n",
            "5.037224769592285\n",
            "5.094066679477692\n",
            "[EPOCH 71] VALID ACCURACY: 75.000\n",
            "[EPOCH 71] TEST ACCURACY: 62.903\n",
            "5.223180174827576\n",
            "4.421682715415955\n",
            "3.906076818704605\n",
            "4.944591224193573\n",
            "5.647694528102875\n",
            "[EPOCH 76] VALID ACCURACY: 75.000\n",
            "[EPOCH 76] TEST ACCURACY: 62.903\n",
            "3.5760318636894226\n",
            "3.9186571836471558\n",
            "3.9183855056762695\n",
            "3.4916565120220184\n",
            "3.1861567199230194\n",
            "[EPOCH 81] VALID ACCURACY: 88.462\n",
            "[EPOCH 81] TEST ACCURACY: 62.903\n",
            "3.329054743051529\n",
            "3.444656580686569\n",
            "11.3902188539505\n",
            "10.188093423843384\n",
            "4.7758830189704895\n",
            "[EPOCH 86] VALID ACCURACY: 75.000\n",
            "[EPOCH 86] TEST ACCURACY: 62.903\n",
            "5.022761642932892\n",
            "8.016259670257568\n",
            "3.9122202396392822\n",
            "4.171966791152954\n",
            "2.7719725370407104\n",
            "[EPOCH 91] VALID ACCURACY: 86.538\n",
            "[EPOCH 91] TEST ACCURACY: 85.484\n",
            "2.8956624269485474\n",
            "2.7237054109573364\n",
            "1.8154473006725311\n",
            "2.1505427062511444\n",
            "2.807470887899399\n",
            "[EPOCH 96] VALID ACCURACY: 92.308\n",
            "[EPOCH 96] TEST ACCURACY: 85.484\n",
            "2.812596470117569\n",
            "2.022712826728821\n",
            "1.663053810596466\n",
            "1.856388345360756\n",
            "2.020498350262642\n",
            "[EPOCH 101] VALID ACCURACY: 94.231\n",
            "[EPOCH 101] TEST ACCURACY: 88.710\n",
            "1.8496602326631546\n",
            "2.1756276190280914\n",
            "1.7075631991028786\n",
            "1.4831009954214096\n",
            "1.5064747333526611\n",
            "[EPOCH 106] VALID ACCURACY: 94.231\n",
            "[EPOCH 106] TEST ACCURACY: 88.710\n",
            "1.311934918165207\n",
            "1.6196983307600021\n",
            "2.2630143649876118\n",
            "1.8372959196567535\n",
            "1.8973595947027206\n",
            "[EPOCH 111] VALID ACCURACY: 88.462\n",
            "[EPOCH 111] TEST ACCURACY: 93.548\n",
            "1.9197513461112976\n",
            "1.6777081489562988\n",
            "1.8119619190692902\n",
            "1.287689559161663\n",
            "1.4737736582756042\n",
            "[EPOCH 116] VALID ACCURACY: 92.308\n",
            "[EPOCH 116] TEST ACCURACY: 87.097\n",
            "1.5467728972434998\n",
            "1.3797643929719925\n",
            "1.4485938102006912\n",
            "1.330675721168518\n",
            "1.3187513649463654\n",
            "[EPOCH 121] VALID ACCURACY: 94.231\n",
            "[EPOCH 121] TEST ACCURACY: 95.161\n",
            "1.3030097410082817\n",
            "1.1922350078821182\n",
            "1.2553271427750587\n",
            "1.3832341134548187\n",
            "1.3310365229845047\n",
            "[EPOCH 126] VALID ACCURACY: 92.308\n",
            "[EPOCH 126] TEST ACCURACY: 93.548\n",
            "1.1741782277822495\n",
            "1.1382628232240677\n",
            "1.2931510210037231\n",
            "0.9984951540827751\n",
            "1.10413458943367\n",
            "[EPOCH 131] VALID ACCURACY: 94.231\n",
            "[EPOCH 131] TEST ACCURACY: 93.548\n",
            "1.1316258609294891\n",
            "1.1046515554189682\n",
            "1.0638298988342285\n",
            "1.3582853078842163\n",
            "1.1455002799630165\n",
            "[EPOCH 136] VALID ACCURACY: 92.308\n",
            "[EPOCH 136] TEST ACCURACY: 95.161\n",
            "1.0089626908302307\n",
            "0.9242627546191216\n",
            "0.8760894909501076\n",
            "1.0535842925310135\n",
            "0.9867582395672798\n",
            "[EPOCH 141] VALID ACCURACY: 84.615\n",
            "[EPOCH 141] TEST ACCURACY: 90.323\n",
            "1.399595521390438\n",
            "1.1435208022594452\n",
            "0.8193765543401241\n",
            "0.9831331819295883\n",
            "0.7808388099074364\n",
            "[EPOCH 146] VALID ACCURACY: 90.385\n",
            "[EPOCH 146] TEST ACCURACY: 90.323\n",
            "0.9158523008227348\n",
            "1.2412488907575607\n",
            "1.0488950088620186\n",
            "0.7924961820244789\n",
            "0.839143667370081\n",
            "[EPOCH 151] VALID ACCURACY: 94.231\n",
            "[EPOCH 151] TEST ACCURACY: 95.161\n",
            "1.640967646613717\n",
            "1.4258579537272453\n",
            "1.8967299796640873\n",
            "1.3348897695541382\n",
            "0.9812371730804443\n",
            "[EPOCH 156] VALID ACCURACY: 88.462\n",
            "[EPOCH 156] TEST ACCURACY: 95.161\n",
            "0.677360188215971\n",
            "0.7913319915533066\n",
            "1.185611529275775\n",
            "0.6530068144202232\n",
            "1.0259250476956367\n",
            "[EPOCH 161] VALID ACCURACY: 90.385\n",
            "[EPOCH 161] TEST ACCURACY: 88.710\n",
            "0.5903317146003246\n",
            "0.45486200973391533\n",
            "0.4467136897146702\n",
            "0.6039593983441591\n",
            "0.584649606840685\n",
            "[EPOCH 166] VALID ACCURACY: 86.538\n",
            "[EPOCH 166] TEST ACCURACY: 80.645\n",
            "0.32166818901896477\n",
            "0.311442899517715\n",
            "0.2880759760737419\n",
            "0.2554089315235615\n",
            "0.389513885602355\n",
            "[EPOCH 171] VALID ACCURACY: 92.308\n",
            "[EPOCH 171] TEST ACCURACY: 93.548\n",
            "0.667265597730875\n",
            "0.42936903005465865\n",
            "0.3292861618101597\n",
            "0.5794346770271659\n",
            "0.4559754393994808\n",
            "[EPOCH 176] VALID ACCURACY: 90.385\n",
            "[EPOCH 176] TEST ACCURACY: 93.548\n",
            "0.3110653581097722\n",
            "0.25368562527000904\n",
            "0.3070305772125721\n",
            "1.2143546342849731\n",
            "1.6886614207178354\n",
            "[EPOCH 181] VALID ACCURACY: 88.462\n",
            "[EPOCH 181] TEST ACCURACY: 83.871\n",
            "1.1273009441792965\n",
            "0.5672092884778976\n",
            "1.68303544819355\n",
            "1.1302626989781857\n",
            "0.8672728976234794\n",
            "[EPOCH 186] VALID ACCURACY: 88.462\n",
            "[EPOCH 186] TEST ACCURACY: 83.871\n",
            "0.6228296458721161\n",
            "0.5252994634211063\n",
            "0.4601462781429291\n",
            "0.5234031211584806\n",
            "0.5215889369137585\n",
            "[EPOCH 191] VALID ACCURACY: 94.231\n",
            "[EPOCH 191] TEST ACCURACY: 88.710\n",
            "0.2652079416438937\n",
            "0.381778706330806\n",
            "0.5688219822477549\n",
            "0.2587563069537282\n",
            "0.2957630706951022\n",
            "[EPOCH 196] VALID ACCURACY: 94.231\n",
            "[EPOCH 196] TEST ACCURACY: 93.548\n",
            "0.5341453002765775\n",
            "0.415872173383832\n",
            "0.7252698689699173\n",
            "0.7197859426960349\n",
            "0.46208891784772277\n",
            "[EPOCH 201] VALID ACCURACY: 90.385\n",
            "[EPOCH 201] TEST ACCURACY: 87.097\n",
            "1.268742734566331\n",
            "3.093210130929947\n",
            "1.901993453502655\n",
            "3.22111377120018\n",
            "16.293246418237686\n",
            "[EPOCH 206] VALID ACCURACY: 75.000\n",
            "[EPOCH 206] TEST ACCURACY: 62.903\n",
            "251.4577875137329\n",
            "124.77583026885986\n",
            "74.1045434474945\n",
            "118.96583795547485\n",
            "87.65850019454956\n",
            "[EPOCH 211] VALID ACCURACY: 11.538\n",
            "[EPOCH 211] TEST ACCURACY: 22.581\n",
            "94.159499168396\n",
            "58.89355731010437\n",
            "21.249332666397095\n",
            "9.390812158584595\n",
            "7.498433232307434\n",
            "[EPOCH 216] VALID ACCURACY: 48.077\n",
            "[EPOCH 216] TEST ACCURACY: 56.452\n",
            "4.983078896999359\n",
            "4.757406771183014\n",
            "5.006018400192261\n",
            "4.55953061580658\n",
            "4.044386923313141\n",
            "[EPOCH 221] VALID ACCURACY: 57.692\n",
            "[EPOCH 221] TEST ACCURACY: 75.806\n",
            "4.255170404911041\n",
            "3.946511387825012\n",
            "3.940479815006256\n",
            "3.624910593032837\n",
            "3.232255518436432\n",
            "[EPOCH 226] VALID ACCURACY: 71.154\n",
            "[EPOCH 226] TEST ACCURACY: 80.645\n",
            "3.152545928955078\n",
            "2.914117395877838\n",
            "3.1432002782821655\n",
            "3.4782456159591675\n",
            "4.072193086147308\n",
            "[EPOCH 231] VALID ACCURACY: 73.077\n",
            "[EPOCH 231] TEST ACCURACY: 80.645\n",
            "3.0118246972560883\n",
            "2.7284677773714066\n",
            "3.393852651119232\n",
            "3.0102343261241913\n",
            "2.8698211908340454\n",
            "[EPOCH 236] VALID ACCURACY: 59.615\n",
            "[EPOCH 236] TEST ACCURACY: 62.903\n",
            "3.0941684544086456\n",
            "2.9851880371570587\n",
            "2.4882227778434753\n",
            "3.2745456993579865\n",
            "2.5981411039829254\n",
            "[EPOCH 241] VALID ACCURACY: 78.846\n",
            "[EPOCH 241] TEST ACCURACY: 82.258\n",
            "2.3429214358329773\n",
            "2.356950119137764\n",
            "1.9970020353794098\n",
            "2.0779545307159424\n",
            "1.8246331065893173\n",
            "[EPOCH 246] VALID ACCURACY: 80.769\n",
            "[EPOCH 246] TEST ACCURACY: 80.645\n",
            "2.0353066325187683\n",
            "1.920349344611168\n",
            "2.0063945949077606\n",
            "2.2006434202194214\n",
            "2.3520436733961105\n",
            "[EPOCH 251] VALID ACCURACY: 86.538\n",
            "[EPOCH 251] TEST ACCURACY: 85.484\n",
            "1.8082887530326843\n",
            "2.036000281572342\n",
            "1.8904353380203247\n",
            "1.9560788571834564\n",
            "1.9414274916052818\n",
            "[EPOCH 256] VALID ACCURACY: 86.538\n",
            "[EPOCH 256] TEST ACCURACY: 85.484\n",
            "2.049710601568222\n",
            "1.9993670731782913\n",
            "2.008308917284012\n",
            "1.9988521337509155\n",
            "1.8634761422872543\n",
            "[EPOCH 261] VALID ACCURACY: 86.538\n",
            "[EPOCH 261] TEST ACCURACY: 85.484\n",
            "1.8325124382972717\n",
            "2.039604961872101\n",
            "1.9581673592329025\n",
            "1.9615556597709656\n",
            "2.3106517642736435\n",
            "[EPOCH 266] VALID ACCURACY: 86.538\n",
            "[EPOCH 266] TEST ACCURACY: 88.710\n",
            "1.993095874786377\n",
            "1.958128497004509\n",
            "1.9550245106220245\n",
            "2.0459529161453247\n",
            "2.0190881937742233\n",
            "[EPOCH 271] VALID ACCURACY: 86.538\n",
            "[EPOCH 271] TEST ACCURACY: 85.484\n",
            "2.1145711839199066\n",
            "2.2017991840839386\n",
            "2.002628445625305\n",
            "1.752610832452774\n",
            "1.8431003391742706\n",
            "[EPOCH 276] VALID ACCURACY: 88.462\n",
            "[EPOCH 276] TEST ACCURACY: 87.097\n",
            "1.8025790601968765\n",
            "1.7945254147052765\n",
            "1.9202817678451538\n",
            "1.7524593770503998\n",
            "1.7380523383617401\n",
            "[EPOCH 281] VALID ACCURACY: 88.462\n",
            "[EPOCH 281] TEST ACCURACY: 85.484\n",
            "1.8444924801588058\n",
            "1.7353020161390305\n",
            "1.8302582502365112\n",
            "1.776148036122322\n",
            "1.9403245151042938\n",
            "[EPOCH 286] VALID ACCURACY: 86.538\n",
            "[EPOCH 286] TEST ACCURACY: 85.484\n",
            "1.7739982306957245\n",
            "1.725849762558937\n",
            "1.95025934278965\n",
            "1.6854221820831299\n",
            "1.7390312254428864\n",
            "[EPOCH 291] VALID ACCURACY: 86.538\n",
            "[EPOCH 291] TEST ACCURACY: 85.484\n",
            "1.9380548298358917\n",
            "1.9924040213227272\n",
            "1.5725011378526688\n",
            "1.812437579035759\n",
            "1.9036881774663925\n",
            "[EPOCH 296] VALID ACCURACY: 88.462\n",
            "[EPOCH 296] TEST ACCURACY: 85.484\n",
            "2.0991356670856476\n",
            "1.6829401552677155\n",
            "1.871711641550064\n",
            "1.8365726470947266\n",
            "Training begins now for # 1 Fold.\n",
            "1.7688142955303192\n",
            "[EPOCH 1] VALID ACCURACY: 88.462\n",
            "[EPOCH 1] TEST ACCURACY: 85.484\n",
            "1.9000527113676071\n",
            "1.7359403520822525\n",
            "1.8431134223937988\n",
            "1.7317819446325302\n",
            "1.8426029682159424\n",
            "[EPOCH 6] VALID ACCURACY: 90.385\n",
            "[EPOCH 6] TEST ACCURACY: 85.484\n",
            "1.5783726423978806\n",
            "1.7697822749614716\n",
            "1.5864315927028656\n",
            "1.5485252402722836\n",
            "1.757918819785118\n",
            "[EPOCH 11] VALID ACCURACY: 88.462\n",
            "[EPOCH 11] TEST ACCURACY: 85.484\n",
            "1.7163227796554565\n",
            "1.5684785395860672\n",
            "1.7719574272632599\n",
            "1.589308649301529\n",
            "1.5444645881652832\n",
            "[EPOCH 16] VALID ACCURACY: 90.385\n",
            "[EPOCH 16] TEST ACCURACY: 87.097\n",
            "1.5126270651817322\n",
            "1.5245613902807236\n",
            "1.7459311485290527\n",
            "1.7738225907087326\n",
            "2.2633054554462433\n",
            "[EPOCH 21] VALID ACCURACY: 88.462\n",
            "[EPOCH 21] TEST ACCURACY: 87.097\n",
            "1.8119067400693893\n",
            "1.9536250233650208\n",
            "2.1247361302375793\n",
            "2.593298524618149\n",
            "2.2869668900966644\n",
            "[EPOCH 26] VALID ACCURACY: 88.462\n",
            "[EPOCH 26] TEST ACCURACY: 85.484\n",
            "1.9539384543895721\n",
            "2.0108383893966675\n",
            "1.6782765090465546\n",
            "2.095555692911148\n",
            "1.972293198108673\n",
            "[EPOCH 31] VALID ACCURACY: 88.462\n",
            "[EPOCH 31] TEST ACCURACY: 85.484\n",
            "1.9473887979984283\n",
            "1.7273260802030563\n",
            "1.7124562710523605\n",
            "1.7954615354537964\n",
            "1.8620528876781464\n",
            "[EPOCH 36] VALID ACCURACY: 88.462\n",
            "[EPOCH 36] TEST ACCURACY: 85.484\n",
            "1.75376196205616\n",
            "2.311823934316635\n",
            "1.9667983055114746\n",
            "2.112134739756584\n",
            "1.9773724675178528\n",
            "[EPOCH 41] VALID ACCURACY: 90.385\n",
            "[EPOCH 41] TEST ACCURACY: 82.258\n",
            "2.092349737882614\n",
            "1.8689836263656616\n",
            "1.5879579186439514\n",
            "1.5881019234657288\n",
            "2.3784390538930893\n",
            "[EPOCH 46] VALID ACCURACY: 84.615\n",
            "[EPOCH 46] TEST ACCURACY: 82.258\n",
            "1.5731661766767502\n",
            "1.5926923304796219\n",
            "2.142615482211113\n",
            "3.5326811969280243\n",
            "2.230858027935028\n",
            "[EPOCH 51] VALID ACCURACY: 82.692\n",
            "[EPOCH 51] TEST ACCURACY: 82.258\n",
            "2.203674226999283\n",
            "1.9521964937448502\n",
            "2.0271990299224854\n",
            "1.8106122612953186\n",
            "1.9147049486637115\n",
            "[EPOCH 56] VALID ACCURACY: 88.462\n",
            "[EPOCH 56] TEST ACCURACY: 85.484\n",
            "1.6752682030200958\n",
            "1.728404477238655\n",
            "1.7371446788311005\n",
            "1.9535564184188843\n",
            "1.9150439649820328\n",
            "[EPOCH 61] VALID ACCURACY: 90.385\n",
            "[EPOCH 61] TEST ACCURACY: 87.097\n",
            "1.9230033308267593\n",
            "1.676336720585823\n",
            "1.7812415957450867\n",
            "1.6175044775009155\n",
            "1.6195558458566666\n",
            "[EPOCH 66] VALID ACCURACY: 92.308\n",
            "[EPOCH 66] TEST ACCURACY: 87.097\n",
            "1.5888023972511292\n",
            "1.605525255203247\n",
            "1.6834810823202133\n",
            "1.4718967378139496\n",
            "1.7597472220659256\n",
            "[EPOCH 71] VALID ACCURACY: 90.385\n",
            "[EPOCH 71] TEST ACCURACY: 87.097\n",
            "1.6352952718734741\n",
            "1.718843698501587\n",
            "1.432442881166935\n",
            "1.4334248155355453\n",
            "1.5706048607826233\n",
            "[EPOCH 76] VALID ACCURACY: 90.385\n",
            "[EPOCH 76] TEST ACCURACY: 88.710\n",
            "1.7224863022565842\n",
            "1.7082400023937225\n",
            "1.5479300916194916\n",
            "1.9422730803489685\n",
            "1.646168127655983\n",
            "[EPOCH 81] VALID ACCURACY: 90.385\n",
            "[EPOCH 81] TEST ACCURACY: 87.097\n",
            "1.8349854350090027\n",
            "1.443561613559723\n",
            "1.3598365187644958\n",
            "1.3750534653663635\n",
            "1.156777635216713\n",
            "[EPOCH 86] VALID ACCURACY: 90.385\n",
            "[EPOCH 86] TEST ACCURACY: 91.935\n",
            "1.2589362114667892\n",
            "1.3976624310016632\n",
            "1.262691356241703\n",
            "1.4883110523223877\n",
            "1.24589604139328\n",
            "[EPOCH 91] VALID ACCURACY: 90.385\n",
            "[EPOCH 91] TEST ACCURACY: 88.710\n",
            "1.5185655504465103\n",
            "1.2916912138462067\n",
            "1.2794904559850693\n",
            "1.5628001540899277\n",
            "2.5873811841011047\n",
            "[EPOCH 96] VALID ACCURACY: 86.538\n",
            "[EPOCH 96] TEST ACCURACY: 93.548\n",
            "1.8247775733470917\n",
            "1.4563914090394974\n",
            "1.530390903353691\n",
            "1.3864550590515137\n",
            "1.3710804134607315\n",
            "[EPOCH 101] VALID ACCURACY: 90.385\n",
            "[EPOCH 101] TEST ACCURACY: 85.484\n",
            "1.812539502978325\n",
            "1.7803729474544525\n",
            "1.6545073688030243\n",
            "1.6715829074382782\n",
            "1.4706814885139465\n",
            "[EPOCH 106] VALID ACCURACY: 86.538\n",
            "[EPOCH 106] TEST ACCURACY: 87.097\n",
            "1.553523674607277\n",
            "1.4608305841684341\n",
            "1.3925297409296036\n",
            "1.6018239110708237\n",
            "1.3973647356033325\n",
            "[EPOCH 111] VALID ACCURACY: 88.462\n",
            "[EPOCH 111] TEST ACCURACY: 87.097\n",
            "1.2902610003948212\n",
            "1.1872199103236198\n",
            "1.2041282504796982\n",
            "1.0908100306987762\n",
            "1.1791225224733353\n",
            "[EPOCH 116] VALID ACCURACY: 92.308\n",
            "[EPOCH 116] TEST ACCURACY: 85.484\n",
            "1.1115572452545166\n",
            "1.1220333725214005\n",
            "1.222265288233757\n",
            "0.9682747945189476\n",
            "0.9720193296670914\n",
            "[EPOCH 121] VALID ACCURACY: 90.385\n",
            "[EPOCH 121] TEST ACCURACY: 88.710\n",
            "1.0731817334890366\n",
            "1.137521080672741\n",
            "0.9988826811313629\n",
            "1.0863626822829247\n",
            "0.8689086139202118\n",
            "[EPOCH 126] VALID ACCURACY: 94.231\n",
            "[EPOCH 126] TEST ACCURACY: 85.484\n",
            "1.0216564759612083\n",
            "0.6876370590180159\n",
            "0.9498211294412613\n",
            "1.05063746124506\n",
            "1.0837670639157295\n",
            "[EPOCH 131] VALID ACCURACY: 90.385\n",
            "[EPOCH 131] TEST ACCURACY: 87.097\n",
            "0.9183449000120163\n",
            "0.8203162103891373\n",
            "0.8491584360599518\n",
            "0.8300149329006672\n",
            "1.0062420032918453\n",
            "[EPOCH 136] VALID ACCURACY: 94.231\n",
            "[EPOCH 136] TEST ACCURACY: 85.484\n",
            "0.8562799394130707\n",
            "0.9093041196465492\n",
            "0.9241734817624092\n",
            "0.9735240340232849\n",
            "0.722499031573534\n",
            "[EPOCH 141] VALID ACCURACY: 88.462\n",
            "[EPOCH 141] TEST ACCURACY: 85.484\n",
            "0.8945726305246353\n",
            "0.7774649783968925\n",
            "0.9771463163197041\n",
            "1.0450656414031982\n",
            "0.8289337940514088\n",
            "[EPOCH 146] VALID ACCURACY: 90.385\n",
            "[EPOCH 146] TEST ACCURACY: 85.484\n",
            "0.7973490916192532\n",
            "0.9486046507954597\n",
            "1.1914576590061188\n",
            "1.0548484399914742\n",
            "1.0717228651046753\n",
            "[EPOCH 151] VALID ACCURACY: 90.385\n",
            "[EPOCH 151] TEST ACCURACY: 85.484\n",
            "0.8863153085112572\n",
            "0.8906906172633171\n",
            "0.8781787306070328\n",
            "0.8906747400760651\n",
            "0.8348058424890041\n",
            "[EPOCH 156] VALID ACCURACY: 90.385\n",
            "[EPOCH 156] TEST ACCURACY: 88.710\n",
            "0.9073324725031853\n",
            "0.8979814350605011\n",
            "0.8831190168857574\n",
            "0.6871968284249306\n",
            "0.8648742735385895\n",
            "[EPOCH 161] VALID ACCURACY: 90.385\n",
            "[EPOCH 161] TEST ACCURACY: 87.097\n",
            "0.8699076548218727\n",
            "0.8954252079129219\n",
            "0.7018650583922863\n",
            "0.8353550732135773\n",
            "0.7221308089792728\n",
            "[EPOCH 166] VALID ACCURACY: 94.231\n",
            "[EPOCH 166] TEST ACCURACY: 85.484\n",
            "0.864253468811512\n",
            "0.6663258224725723\n",
            "0.6943420358002186\n",
            "0.7220825143158436\n",
            "0.7621688935905695\n",
            "[EPOCH 171] VALID ACCURACY: 90.385\n",
            "[EPOCH 171] TEST ACCURACY: 87.097\n",
            "0.7939877137541771\n",
            "0.5733039416372776\n",
            "1.3944047689437866\n",
            "1.3021920025348663\n",
            "1.138075664639473\n",
            "[EPOCH 176] VALID ACCURACY: 92.308\n",
            "[EPOCH 176] TEST ACCURACY: 83.871\n",
            "1.142233282327652\n",
            "0.8623550310730934\n",
            "0.8878897204995155\n",
            "1.0456988662481308\n",
            "1.078682504594326\n",
            "[EPOCH 181] VALID ACCURACY: 90.385\n",
            "[EPOCH 181] TEST ACCURACY: 88.710\n",
            "1.191342182457447\n",
            "1.5187703371047974\n",
            "1.2695985436439514\n",
            "1.090532325208187\n",
            "1.162880226969719\n",
            "[EPOCH 186] VALID ACCURACY: 90.385\n",
            "[EPOCH 186] TEST ACCURACY: 87.097\n",
            "0.9056094139814377\n",
            "0.7454318339005113\n",
            "0.8706889152526855\n",
            "0.7282619625329971\n",
            "0.8212663531303406\n",
            "[EPOCH 191] VALID ACCURACY: 92.308\n",
            "[EPOCH 191] TEST ACCURACY: 83.871\n",
            "0.6025667255744338\n",
            "0.7248316556215286\n",
            "0.6266954243183136\n",
            "0.9704669192433357\n",
            "0.6816936358809471\n",
            "[EPOCH 196] VALID ACCURACY: 92.308\n",
            "[EPOCH 196] TEST ACCURACY: 82.258\n",
            "0.8515195474028587\n",
            "0.7173222154378891\n",
            "0.6144560948014259\n",
            "0.5518278274685144\n",
            "0.5481269042938948\n",
            "[EPOCH 201] VALID ACCURACY: 92.308\n",
            "[EPOCH 201] TEST ACCURACY: 82.258\n",
            "0.5724533842876554\n",
            "0.5102508254349232\n",
            "0.6235915012657642\n",
            "0.6201192289590836\n",
            "0.5409010425209999\n",
            "[EPOCH 206] VALID ACCURACY: 92.308\n",
            "[EPOCH 206] TEST ACCURACY: 88.710\n",
            "0.5792895928025246\n",
            "0.5093016633763909\n",
            "0.824353227391839\n",
            "0.7634176760911942\n",
            "0.8702915981411934\n",
            "[EPOCH 211] VALID ACCURACY: 92.308\n",
            "[EPOCH 211] TEST ACCURACY: 88.710\n",
            "0.9919580370187759\n",
            "1.0094069465994835\n",
            "1.1540438085794449\n",
            "1.6848125010728836\n",
            "2.0328158736228943\n",
            "[EPOCH 216] VALID ACCURACY: 88.462\n",
            "[EPOCH 216] TEST ACCURACY: 88.710\n",
            "2.2964347153902054\n",
            "1.631050020456314\n",
            "1.4423940926790237\n",
            "1.9443803131580353\n",
            "2.524683862924576\n",
            "[EPOCH 221] VALID ACCURACY: 84.615\n",
            "[EPOCH 221] TEST ACCURACY: 87.097\n",
            "2.273993819952011\n",
            "2.385135307908058\n",
            "1.9980760216712952\n",
            "2.022650271654129\n",
            "3.339777886867523\n",
            "[EPOCH 226] VALID ACCURACY: 82.692\n",
            "[EPOCH 226] TEST ACCURACY: 79.032\n",
            "2.0423161536455154\n",
            "1.961900532245636\n",
            "1.712970346212387\n",
            "1.8891392648220062\n",
            "1.4226824045181274\n",
            "[EPOCH 231] VALID ACCURACY: 84.615\n",
            "[EPOCH 231] TEST ACCURACY: 85.484\n",
            "1.1758987307548523\n",
            "1.2535795867443085\n",
            "2.2119277119636536\n",
            "1.5331294983625412\n",
            "1.2092049270868301\n",
            "[EPOCH 236] VALID ACCURACY: 90.385\n",
            "[EPOCH 236] TEST ACCURACY: 87.097\n",
            "1.9113863110542297\n",
            "1.7051658183336258\n",
            "1.3321833610534668\n",
            "1.367445893585682\n",
            "1.2383320927619934\n",
            "[EPOCH 241] VALID ACCURACY: 92.308\n",
            "[EPOCH 241] TEST ACCURACY: 85.484\n",
            "1.2940057218074799\n",
            "1.6254583895206451\n",
            "1.2924392521381378\n",
            "1.2485108077526093\n",
            "1.2432843446731567\n",
            "[EPOCH 246] VALID ACCURACY: 94.231\n",
            "[EPOCH 246] TEST ACCURACY: 83.871\n",
            "2.451433725655079\n",
            "2.4154545664787292\n",
            "1.7441034317016602\n",
            "1.4261075258255005\n",
            "1.5991730391979218\n",
            "[EPOCH 251] VALID ACCURACY: 92.308\n",
            "[EPOCH 251] TEST ACCURACY: 87.097\n",
            "1.5302988588809967\n",
            "1.3372381627559662\n",
            "0.9702247157692909\n",
            "0.8733887001872063\n",
            "0.9028629064559937\n",
            "[EPOCH 256] VALID ACCURACY: 86.538\n",
            "[EPOCH 256] TEST ACCURACY: 82.258\n",
            "1.2018594704568386\n",
            "0.8640973623842001\n",
            "1.1901155710220337\n",
            "1.0503378435969353\n",
            "1.2079197466373444\n",
            "[EPOCH 261] VALID ACCURACY: 96.154\n",
            "[EPOCH 261] TEST ACCURACY: 74.194\n",
            "1.324843890964985\n",
            "1.352581724524498\n",
            "1.4514672458171844\n",
            "1.4942447021603584\n",
            "1.2014413699507713\n",
            "[EPOCH 266] VALID ACCURACY: 90.385\n",
            "[EPOCH 266] TEST ACCURACY: 83.871\n",
            "1.2286155819892883\n",
            "1.1243113726377487\n",
            "1.0656953901052475\n",
            "1.2568117380142212\n",
            "1.0810726657509804\n",
            "[EPOCH 271] VALID ACCURACY: 90.385\n",
            "[EPOCH 271] TEST ACCURACY: 88.710\n",
            "1.1932787895202637\n",
            "1.07152309268713\n",
            "1.2989564277231693\n",
            "1.0567153878509998\n",
            "1.6217237412929535\n",
            "[EPOCH 276] VALID ACCURACY: 90.385\n",
            "[EPOCH 276] TEST ACCURACY: 88.710\n",
            "1.3831834681332111\n",
            "1.3251117020845413\n",
            "1.183364026248455\n",
            "1.1775157302618027\n",
            "1.2583186626434326\n",
            "[EPOCH 281] VALID ACCURACY: 90.385\n",
            "[EPOCH 281] TEST ACCURACY: 85.484\n",
            "1.3012554347515106\n",
            "0.8437888249754906\n",
            "1.2333449646830559\n",
            "1.081707164645195\n",
            "1.3663531094789505\n",
            "[EPOCH 286] VALID ACCURACY: 92.308\n",
            "[EPOCH 286] TEST ACCURACY: 83.871\n",
            "1.1920564025640488\n",
            "1.0359938442707062\n",
            "1.1098111420869827\n",
            "0.8971191495656967\n",
            "0.8855354636907578\n",
            "[EPOCH 291] VALID ACCURACY: 88.462\n",
            "[EPOCH 291] TEST ACCURACY: 85.484\n",
            "0.915837973356247\n",
            "1.127296432852745\n",
            "0.9749305173754692\n",
            "1.0048254877328873\n",
            "0.8447417840361595\n",
            "[EPOCH 296] VALID ACCURACY: 88.462\n",
            "[EPOCH 296] TEST ACCURACY: 88.710\n",
            "0.9304284416139126\n",
            "0.8661419227719307\n",
            "0.7924146801233292\n",
            "0.7476956993341446\n",
            "Training begins now for # 2 Fold.\n",
            "1.6027213782072067\n",
            "[EPOCH 1] VALID ACCURACY: 96.154\n",
            "[EPOCH 1] TEST ACCURACY: 85.484\n",
            "1.1089934222400188\n",
            "1.0151035636663437\n",
            "1.0702483654022217\n",
            "1.0810017511248589\n",
            "1.0977786853909492\n",
            "[EPOCH 6] VALID ACCURACY: 96.154\n",
            "[EPOCH 6] TEST ACCURACY: 85.484\n",
            "1.0645520985126495\n",
            "1.1689889803528786\n",
            "1.0238344483077526\n",
            "1.0011657625436783\n",
            "0.8996599540114403\n",
            "[EPOCH 11] VALID ACCURACY: 96.154\n",
            "[EPOCH 11] TEST ACCURACY: 85.484\n",
            "1.00752554833889\n",
            "0.9976947382092476\n",
            "1.1125348061323166\n",
            "1.0220744162797928\n",
            "0.8641859441995621\n",
            "[EPOCH 16] VALID ACCURACY: 94.231\n",
            "[EPOCH 16] TEST ACCURACY: 85.484\n",
            "1.042450975626707\n",
            "1.0808937549591064\n",
            "1.093199461698532\n",
            "1.1312557235360146\n",
            "1.2076392695307732\n",
            "[EPOCH 21] VALID ACCURACY: 92.308\n",
            "[EPOCH 21] TEST ACCURACY: 88.710\n",
            "0.9469415247440338\n",
            "1.1196351647377014\n",
            "1.023503690958023\n",
            "0.9607285782694817\n",
            "1.0489783212542534\n",
            "[EPOCH 26] VALID ACCURACY: 92.308\n",
            "[EPOCH 26] TEST ACCURACY: 85.484\n",
            "1.2372620776295662\n",
            "1.1089619174599648\n",
            "1.0209566503763199\n",
            "1.074087992310524\n",
            "1.076305277645588\n",
            "[EPOCH 31] VALID ACCURACY: 92.308\n",
            "[EPOCH 31] TEST ACCURACY: 79.032\n",
            "0.9258249774575233\n",
            "0.9006135910749435\n",
            "1.0906360819935799\n",
            "0.7914572432637215\n",
            "0.7728469483554363\n",
            "[EPOCH 36] VALID ACCURACY: 94.231\n",
            "[EPOCH 36] TEST ACCURACY: 88.710\n",
            "1.0765066295862198\n",
            "1.0305131077766418\n",
            "0.9871051162481308\n",
            "1.282939225435257\n",
            "1.0835386887192726\n",
            "[EPOCH 41] VALID ACCURACY: 88.462\n",
            "[EPOCH 41] TEST ACCURACY: 87.097\n",
            "1.167982056736946\n",
            "1.1405221223831177\n",
            "1.1508265808224678\n",
            "0.9798010140657425\n",
            "1.0858746021986008\n",
            "[EPOCH 46] VALID ACCURACY: 92.308\n",
            "[EPOCH 46] TEST ACCURACY: 88.710\n",
            "1.0927518159151077\n",
            "1.1768451631069183\n",
            "1.0685676783323288\n",
            "1.2156960740685463\n",
            "1.0669164508581161\n",
            "[EPOCH 51] VALID ACCURACY: 92.308\n",
            "[EPOCH 51] TEST ACCURACY: 88.710\n",
            "1.1103109791874886\n",
            "1.0780352056026459\n",
            "1.0676247254014015\n",
            "1.1945692598819733\n",
            "1.0664212331175804\n",
            "[EPOCH 56] VALID ACCURACY: 88.462\n",
            "[EPOCH 56] TEST ACCURACY: 90.323\n",
            "1.0844173729419708\n",
            "0.910075768828392\n",
            "0.9382531344890594\n",
            "1.0114901885390282\n",
            "1.0312726646661758\n",
            "[EPOCH 61] VALID ACCURACY: 92.308\n",
            "[EPOCH 61] TEST ACCURACY: 88.710\n",
            "0.9646014720201492\n",
            "1.0117356851696968\n",
            "0.9270935542881489\n",
            "0.71791135892272\n",
            "0.8098865374922752\n",
            "[EPOCH 66] VALID ACCURACY: 90.385\n",
            "[EPOCH 66] TEST ACCURACY: 83.871\n",
            "0.8804173767566681\n",
            "0.8648591884411871\n",
            "1.072858428582549\n",
            "0.975816011428833\n",
            "1.0489739775657654\n",
            "[EPOCH 71] VALID ACCURACY: 92.308\n",
            "[EPOCH 71] TEST ACCURACY: 83.871\n",
            "0.8497567735612392\n",
            "0.7194572202861309\n",
            "0.6815969161689281\n",
            "0.7947012633085251\n",
            "0.7859463468194008\n",
            "[EPOCH 76] VALID ACCURACY: 96.154\n",
            "[EPOCH 76] TEST ACCURACY: 83.871\n",
            "0.9097460843622684\n",
            "0.7583601549267769\n",
            "0.6966444924473763\n",
            "0.6817377880215645\n",
            "0.6353761814534664\n",
            "[EPOCH 81] VALID ACCURACY: 92.308\n",
            "[EPOCH 81] TEST ACCURACY: 83.871\n",
            "0.650811992585659\n",
            "0.650537334382534\n",
            "0.5910401847213507\n",
            "0.6541616804897785\n",
            "0.5792305171489716\n",
            "[EPOCH 86] VALID ACCURACY: 94.231\n",
            "[EPOCH 86] TEST ACCURACY: 83.871\n",
            "0.5857904492877424\n",
            "0.5275961719453335\n",
            "0.3833213681355119\n",
            "0.49679499864578247\n",
            "0.5081958621740341\n",
            "[EPOCH 91] VALID ACCURACY: 94.231\n",
            "[EPOCH 91] TEST ACCURACY: 83.871\n",
            "0.4044077396392822\n",
            "0.6529532335698605\n",
            "0.6992572769522667\n",
            "0.7456418760120869\n",
            "0.4866303727030754\n",
            "[EPOCH 96] VALID ACCURACY: 96.154\n",
            "[EPOCH 96] TEST ACCURACY: 82.258\n",
            "0.625437006354332\n",
            "0.6414025565609336\n",
            "0.5019643101841211\n",
            "0.4805559213273227\n",
            "0.35170720517635345\n",
            "[EPOCH 101] VALID ACCURACY: 98.077\n",
            "[EPOCH 101] TEST ACCURACY: 83.871\n",
            "0.33669788553379476\n",
            "0.4183556418865919\n",
            "0.5733270347118378\n",
            "0.5895597860217094\n",
            "0.42998905293643475\n",
            "[EPOCH 106] VALID ACCURACY: 94.231\n",
            "[EPOCH 106] TEST ACCURACY: 90.323\n",
            "0.5148815102875233\n",
            "0.4688825234770775\n",
            "0.3588414844125509\n",
            "0.339357472024858\n",
            "0.4456384538207203\n",
            "[EPOCH 111] VALID ACCURACY: 98.077\n",
            "[EPOCH 111] TEST ACCURACY: 90.323\n",
            "0.3248896999284625\n",
            "0.28489623544737697\n",
            "0.36235130205750465\n",
            "0.36479080002754927\n",
            "0.41408167872577906\n",
            "[EPOCH 116] VALID ACCURACY: 96.154\n",
            "[EPOCH 116] TEST ACCURACY: 85.484\n",
            "0.8222620524466038\n",
            "0.5213749147951603\n",
            "0.4882061444222927\n",
            "0.5017718821763992\n",
            "0.5187351033091545\n",
            "[EPOCH 121] VALID ACCURACY: 94.231\n",
            "[EPOCH 121] TEST ACCURACY: 90.323\n",
            "0.7515391031047329\n",
            "0.4984140992164612\n",
            "0.4073255527764559\n",
            "0.47414257004857063\n",
            "0.4383407086133957\n",
            "[EPOCH 126] VALID ACCURACY: 94.231\n",
            "[EPOCH 126] TEST ACCURACY: 90.323\n",
            "0.3230213653296232\n",
            "0.4051148248836398\n",
            "0.38499440299347043\n",
            "0.46829173527657986\n",
            "0.34476635977625847\n",
            "[EPOCH 131] VALID ACCURACY: 94.231\n",
            "[EPOCH 131] TEST ACCURACY: 85.484\n",
            "0.43595118587836623\n",
            "0.39401428028941154\n",
            "0.6847056467086077\n",
            "0.4311880925670266\n",
            "0.5477583557367325\n",
            "[EPOCH 136] VALID ACCURACY: 96.154\n",
            "[EPOCH 136] TEST ACCURACY: 88.710\n",
            "0.5327406972646713\n",
            "0.4816132076084614\n",
            "0.5871246382594109\n",
            "0.5277332216501236\n",
            "0.38237912324257195\n",
            "[EPOCH 141] VALID ACCURACY: 92.308\n",
            "[EPOCH 141] TEST ACCURACY: 85.484\n",
            "0.7287050671875477\n",
            "0.706650149077177\n",
            "0.4795779511332512\n",
            "0.6828782148659229\n",
            "0.5306148491799831\n",
            "[EPOCH 146] VALID ACCURACY: 96.154\n",
            "[EPOCH 146] TEST ACCURACY: 85.484\n",
            "0.3063052464276552\n",
            "0.45982999727129936\n",
            "0.6489093154668808\n",
            "0.2753224642947316\n",
            "0.38908824091777205\n",
            "[EPOCH 151] VALID ACCURACY: 96.154\n",
            "[EPOCH 151] TEST ACCURACY: 90.323\n",
            "0.3034636788070202\n",
            "0.4024937991052866\n",
            "0.37426599860191345\n",
            "0.44226212333887815\n",
            "0.4937259089201689\n",
            "[EPOCH 156] VALID ACCURACY: 94.231\n",
            "[EPOCH 156] TEST ACCURACY: 88.710\n",
            "0.6622089135926217\n",
            "0.5943307178094983\n",
            "0.4763721153140068\n",
            "1.339022383093834\n",
            "1.980975866317749\n",
            "[EPOCH 161] VALID ACCURACY: 84.615\n",
            "[EPOCH 161] TEST ACCURACY: 85.484\n",
            "1.1227070987224579\n",
            "1.1441108509898186\n",
            "0.991405364125967\n",
            "1.0180790647864342\n",
            "1.0958900898694992\n",
            "[EPOCH 166] VALID ACCURACY: 84.615\n",
            "[EPOCH 166] TEST ACCURACY: 91.935\n",
            "0.8798222318291664\n",
            "0.7360090538859367\n",
            "0.8192951083183289\n",
            "0.6522005051374435\n",
            "0.7582986541092396\n",
            "[EPOCH 171] VALID ACCURACY: 96.154\n",
            "[EPOCH 171] TEST ACCURACY: 82.258\n",
            "0.6525402069091797\n",
            "0.6007674820721149\n",
            "0.7553609386086464\n",
            "0.6391100436449051\n",
            "0.7735058679245412\n",
            "[EPOCH 176] VALID ACCURACY: 98.077\n",
            "[EPOCH 176] TEST ACCURACY: 88.710\n",
            "0.5317678563296795\n",
            "0.7147749736905098\n",
            "0.43994713947176933\n",
            "0.32721373438835144\n",
            "0.5365782016888261\n",
            "[EPOCH 181] VALID ACCURACY: 98.077\n",
            "[EPOCH 181] TEST ACCURACY: 87.097\n",
            "0.3795655183494091\n",
            "0.34446113742887974\n",
            "0.47104791831225157\n",
            "0.3292540740221739\n",
            "0.36887541599571705\n",
            "[EPOCH 186] VALID ACCURACY: 98.077\n",
            "[EPOCH 186] TEST ACCURACY: 87.097\n",
            "0.3206010228022933\n",
            "0.3303904505446553\n",
            "0.4238995215855539\n",
            "0.29930212907493114\n",
            "0.45117402728646994\n",
            "[EPOCH 191] VALID ACCURACY: 96.154\n",
            "[EPOCH 191] TEST ACCURACY: 87.097\n",
            "0.37197526171803474\n",
            "0.30774533026851714\n",
            "0.39875596947968006\n",
            "0.4002403188496828\n",
            "0.44874475011602044\n",
            "[EPOCH 196] VALID ACCURACY: 90.385\n",
            "[EPOCH 196] TEST ACCURACY: 83.871\n",
            "0.45777767337858677\n",
            "0.3229239459615201\n",
            "0.5907695218920708\n",
            "0.5365603854879737\n",
            "0.4917268007993698\n",
            "[EPOCH 201] VALID ACCURACY: 96.154\n",
            "[EPOCH 201] TEST ACCURACY: 85.484\n",
            "0.4210857190191746\n",
            "0.3563396204262972\n",
            "0.5155763467773795\n",
            "0.6575736543163657\n",
            "0.4719537617638707\n",
            "[EPOCH 206] VALID ACCURACY: 96.154\n",
            "[EPOCH 206] TEST ACCURACY: 82.258\n",
            "0.625388266518712\n",
            "1.057560969144106\n",
            "1.1822057627141476\n",
            "1.2998495176434517\n",
            "2.043533444404602\n",
            "[EPOCH 211] VALID ACCURACY: 84.615\n",
            "[EPOCH 211] TEST ACCURACY: 85.484\n",
            "0.9208739101886749\n",
            "0.9330582395195961\n",
            "0.8075728341937065\n",
            "0.6997604258358479\n",
            "1.0922897532582283\n",
            "[EPOCH 216] VALID ACCURACY: 94.231\n",
            "[EPOCH 216] TEST ACCURACY: 88.710\n",
            "0.6460383869707584\n",
            "0.2983984388411045\n",
            "0.8765846453607082\n",
            "0.6192599516361952\n",
            "0.7233951636590064\n",
            "[EPOCH 221] VALID ACCURACY: 94.231\n",
            "[EPOCH 221] TEST ACCURACY: 85.484\n",
            "0.6976029514335096\n",
            "0.5347188375890255\n",
            "0.48608386516571045\n",
            "0.3355660755187273\n",
            "0.6851751729846001\n",
            "[EPOCH 226] VALID ACCURACY: 94.231\n",
            "[EPOCH 226] TEST ACCURACY: 85.484\n",
            "0.41889301873743534\n",
            "0.3704139478504658\n",
            "0.32017942890524864\n",
            "0.31638498418033123\n",
            "0.39522163197398186\n",
            "[EPOCH 231] VALID ACCURACY: 94.231\n",
            "[EPOCH 231] TEST ACCURACY: 85.484\n",
            "0.38308912701904774\n",
            "0.3217617878690362\n",
            "0.30137272365391254\n",
            "0.4146663900464773\n",
            "0.4357486106455326\n",
            "[EPOCH 236] VALID ACCURACY: 96.154\n",
            "[EPOCH 236] TEST ACCURACY: 82.258\n",
            "0.22467170096933842\n",
            "0.25480231794063\n",
            "0.3953710235655308\n",
            "0.10451883589848876\n",
            "0.1721350559964776\n",
            "[EPOCH 241] VALID ACCURACY: 98.077\n",
            "[EPOCH 241] TEST ACCURACY: 80.645\n",
            "0.1449794126674533\n",
            "0.26446570130065084\n",
            "0.10613492841366678\n",
            "0.17542878282256424\n",
            "0.17258811695501208\n",
            "[EPOCH 246] VALID ACCURACY: 94.231\n",
            "[EPOCH 246] TEST ACCURACY: 87.097\n",
            "0.3039261500816792\n",
            "0.32842615456320345\n",
            "0.20429312158375978\n",
            "0.36846304463688284\n",
            "0.36461840517586097\n",
            "[EPOCH 251] VALID ACCURACY: 96.154\n",
            "[EPOCH 251] TEST ACCURACY: 85.484\n",
            "0.10274416068568826\n",
            "0.4257836975157261\n",
            "0.1442016726359725\n",
            "0.39901129249483347\n",
            "0.5329718580469489\n",
            "[EPOCH 256] VALID ACCURACY: 98.077\n",
            "[EPOCH 256] TEST ACCURACY: 83.871\n",
            "0.21933227684348822\n",
            "0.20452928729355335\n",
            "0.1529288305900991\n",
            "0.12301561259664595\n",
            "0.09608992557332385\n",
            "[EPOCH 261] VALID ACCURACY: 98.077\n",
            "[EPOCH 261] TEST ACCURACY: 90.323\n",
            "0.06806885507739935\n",
            "0.1334472635644488\n",
            "0.24857971756136976\n",
            "0.8815836384892464\n",
            "0.22608385095372796\n",
            "[EPOCH 266] VALID ACCURACY: 92.308\n",
            "[EPOCH 266] TEST ACCURACY: 87.097\n",
            "0.42428892850875854\n",
            "0.3033002382144332\n",
            "0.16373164020478725\n",
            "0.23735388182103634\n",
            "0.2162576336413622\n",
            "[EPOCH 271] VALID ACCURACY: 94.231\n",
            "[EPOCH 271] TEST ACCURACY: 85.484\n",
            "0.2120462260209024\n",
            "0.44830576321692206\n",
            "0.34128841757774353\n",
            "0.2514818930067122\n",
            "0.3620035711210221\n",
            "[EPOCH 276] VALID ACCURACY: 96.154\n",
            "[EPOCH 276] TEST ACCURACY: 85.484\n",
            "0.1287725493311882\n",
            "0.2540626125410199\n",
            "0.1732329964870587\n",
            "0.288887778762728\n",
            "0.24335187207907438\n",
            "[EPOCH 281] VALID ACCURACY: 98.077\n",
            "[EPOCH 281] TEST ACCURACY: 87.097\n",
            "0.13191457325592637\n",
            "0.16016362141817808\n",
            "0.13656951813027263\n",
            "0.16910277144052088\n",
            "0.259879054967314\n",
            "[EPOCH 286] VALID ACCURACY: 94.231\n",
            "[EPOCH 286] TEST ACCURACY: 77.419\n",
            "1.1226070001721382\n",
            "0.9262923784554005\n",
            "0.7257085070014\n",
            "0.6506572756916285\n",
            "0.9404630437493324\n",
            "[EPOCH 291] VALID ACCURACY: 94.231\n",
            "[EPOCH 291] TEST ACCURACY: 82.258\n",
            "0.5903838253580034\n",
            "0.5250885842833668\n",
            "0.44110922142863274\n",
            "0.4793685209006071\n",
            "0.41946013597771525\n",
            "[EPOCH 296] VALID ACCURACY: 92.308\n",
            "[EPOCH 296] TEST ACCURACY: 85.484\n",
            "0.28506860975176096\n",
            "0.382995268329978\n",
            "0.2075222171843052\n",
            "0.21421745978295803\n",
            "Training begins now for # 3 Fold.\n",
            "0.7709688171744347\n",
            "[EPOCH 1] VALID ACCURACY: 98.077\n",
            "[EPOCH 1] TEST ACCURACY: 85.484\n",
            "0.6117718815803528\n",
            "0.3186214938759804\n",
            "0.5447689611464739\n",
            "0.39102430641651154\n",
            "0.2936349269002676\n",
            "[EPOCH 6] VALID ACCURACY: 98.077\n",
            "[EPOCH 6] TEST ACCURACY: 83.871\n",
            "0.25891140941530466\n",
            "0.5313421923201531\n",
            "1.0562036409974098\n",
            "0.44149214029312134\n",
            "0.28672620467841625\n",
            "[EPOCH 11] VALID ACCURACY: 98.077\n",
            "[EPOCH 11] TEST ACCURACY: 83.871\n",
            "0.4448640737682581\n",
            "0.33653761725872755\n",
            "0.2953864911105484\n",
            "0.276503071654588\n",
            "0.3623071874026209\n",
            "[EPOCH 16] VALID ACCURACY: 98.077\n",
            "[EPOCH 16] TEST ACCURACY: 83.871\n",
            "0.34185467986389995\n",
            "0.22438812628388405\n",
            "0.24383934354409575\n",
            "0.37644793977960944\n",
            "0.3868257012218237\n",
            "[EPOCH 21] VALID ACCURACY: 98.077\n",
            "[EPOCH 21] TEST ACCURACY: 83.871\n",
            "0.35732208378612995\n",
            "0.16334359114989638\n",
            "0.27350713685154915\n",
            "0.21809921227395535\n",
            "0.19036663137376308\n",
            "[EPOCH 26] VALID ACCURACY: 98.077\n",
            "[EPOCH 26] TEST ACCURACY: 85.484\n",
            "0.2283405759371817\n",
            "0.16930163092911243\n",
            "0.1302683458197862\n",
            "0.2869267964269966\n",
            "0.302951174788177\n",
            "[EPOCH 31] VALID ACCURACY: 100.000\n",
            "[EPOCH 31] TEST ACCURACY: 85.484\n",
            "0.38322446681559086\n",
            "0.24024540185928345\n",
            "0.16771678812801838\n",
            "0.2299928562133573\n",
            "0.1448163310997188\n",
            "[EPOCH 36] VALID ACCURACY: 98.077\n",
            "[EPOCH 36] TEST ACCURACY: 85.484\n",
            "0.5176719408482313\n",
            "0.9326449306681752\n",
            "0.36177557054907084\n",
            "0.28859402099624276\n",
            "0.4567162673920393\n",
            "[EPOCH 41] VALID ACCURACY: 98.077\n",
            "[EPOCH 41] TEST ACCURACY: 85.484\n",
            "0.15676584048196673\n",
            "0.14929498569108546\n",
            "0.16027975641191006\n",
            "0.11883820279035717\n",
            "0.2057402143254876\n",
            "[EPOCH 46] VALID ACCURACY: 98.077\n",
            "[EPOCH 46] TEST ACCURACY: 85.484\n",
            "0.21440633991733193\n",
            "0.1428488395176828\n",
            "0.11371041263919324\n",
            "0.7011931715533137\n",
            "1.2507687585311942\n",
            "[EPOCH 51] VALID ACCURACY: 98.077\n",
            "[EPOCH 51] TEST ACCURACY: 85.484\n",
            "0.46123602672014385\n",
            "0.4936945363879204\n",
            "0.8606718853116035\n",
            "2.4542520195245743\n",
            "5.876045912504196\n",
            "[EPOCH 56] VALID ACCURACY: 94.231\n",
            "[EPOCH 56] TEST ACCURACY: 85.484\n",
            "3.6936013996601105\n",
            "6.168351382017136\n",
            "9.956051141023636\n",
            "50.22824829816818\n",
            "128.12507820129395\n",
            "[EPOCH 61] VALID ACCURACY: 50.000\n",
            "[EPOCH 61] TEST ACCURACY: 14.516\n",
            "4655.799977779388\n",
            "1627.9675064086914\n",
            "1742.6296691894531\n",
            "1569.646827697754\n",
            "186.3000087738037\n",
            "[EPOCH 66] VALID ACCURACY: 65.385\n",
            "[EPOCH 66] TEST ACCURACY: 62.903\n",
            "81.88680076599121\n",
            "118.28240585327148\n",
            "154.65517711639404\n",
            "448.8332099914551\n",
            "124.16745090484619\n",
            "[EPOCH 71] VALID ACCURACY: 65.385\n",
            "[EPOCH 71] TEST ACCURACY: 62.903\n",
            "63.75334644317627\n",
            "23.669020652770996\n",
            "17.97497034072876\n",
            "13.0860093832016\n",
            "11.636682987213135\n",
            "[EPOCH 76] VALID ACCURACY: 65.385\n",
            "[EPOCH 76] TEST ACCURACY: 62.903\n",
            "8.736338675022125\n",
            "7.793937504291534\n",
            "6.570268511772156\n",
            "6.1414055824279785\n",
            "6.217410385608673\n",
            "[EPOCH 81] VALID ACCURACY: 65.385\n",
            "[EPOCH 81] TEST ACCURACY: 62.903\n",
            "5.684310495853424\n",
            "5.641792893409729\n",
            "5.390886545181274\n",
            "5.535432457923889\n",
            "5.360523521900177\n",
            "[EPOCH 86] VALID ACCURACY: 65.385\n",
            "[EPOCH 86] TEST ACCURACY: 62.903\n",
            "5.222705185413361\n",
            "5.117750644683838\n",
            "4.91275030374527\n",
            "5.1463662981987\n",
            "4.843756198883057\n",
            "[EPOCH 91] VALID ACCURACY: 65.385\n",
            "[EPOCH 91] TEST ACCURACY: 62.903\n",
            "4.773532748222351\n",
            "4.70058411359787\n",
            "4.818987131118774\n",
            "4.736995995044708\n",
            "4.549860894680023\n",
            "[EPOCH 96] VALID ACCURACY: 65.385\n",
            "[EPOCH 96] TEST ACCURACY: 62.903\n",
            "4.533152341842651\n",
            "4.608031988143921\n",
            "4.733681917190552\n",
            "4.676716506481171\n",
            "4.652658939361572\n",
            "[EPOCH 101] VALID ACCURACY: 65.385\n",
            "[EPOCH 101] TEST ACCURACY: 62.903\n",
            "4.499228358268738\n",
            "4.678150773048401\n",
            "4.613750338554382\n",
            "4.612426936626434\n",
            "4.5453848242759705\n",
            "[EPOCH 106] VALID ACCURACY: 65.385\n",
            "[EPOCH 106] TEST ACCURACY: 62.903\n",
            "4.587118744850159\n",
            "4.596524178981781\n",
            "4.567766487598419\n",
            "4.6863003969192505\n",
            "4.616509556770325\n",
            "[EPOCH 111] VALID ACCURACY: 65.385\n",
            "[EPOCH 111] TEST ACCURACY: 62.903\n",
            "4.572235643863678\n",
            "4.552561700344086\n",
            "4.674187958240509\n",
            "4.554192364215851\n",
            "4.552346706390381\n",
            "[EPOCH 116] VALID ACCURACY: 65.385\n",
            "[EPOCH 116] TEST ACCURACY: 62.903\n",
            "4.553378164768219\n",
            "4.442777574062347\n",
            "4.691744863986969\n",
            "4.675425052642822\n",
            "4.587762117385864\n",
            "[EPOCH 121] VALID ACCURACY: 65.385\n",
            "[EPOCH 121] TEST ACCURACY: 62.903\n",
            "4.559822201728821\n",
            "4.604266285896301\n",
            "4.5402897000312805\n",
            "4.578297793865204\n",
            "4.58808034658432\n",
            "[EPOCH 126] VALID ACCURACY: 65.385\n",
            "[EPOCH 126] TEST ACCURACY: 62.903\n",
            "4.605010449886322\n",
            "4.566406965255737\n",
            "4.409097850322723\n",
            "4.582372963428497\n",
            "4.546187222003937\n",
            "[EPOCH 131] VALID ACCURACY: 65.385\n",
            "[EPOCH 131] TEST ACCURACY: 62.903\n",
            "4.4493467807769775\n",
            "4.506856441497803\n",
            "4.61349219083786\n",
            "4.635442435741425\n",
            "4.639755010604858\n",
            "[EPOCH 136] VALID ACCURACY: 65.385\n",
            "[EPOCH 136] TEST ACCURACY: 62.903\n",
            "4.541937410831451\n",
            "4.547830939292908\n",
            "4.606925904750824\n",
            "4.561502158641815\n",
            "4.626139342784882\n",
            "[EPOCH 141] VALID ACCURACY: 65.385\n",
            "[EPOCH 141] TEST ACCURACY: 62.903\n",
            "4.617329180240631\n",
            "4.583721399307251\n",
            "4.522566437721252\n",
            "4.48277735710144\n",
            "4.521542191505432\n",
            "[EPOCH 146] VALID ACCURACY: 65.385\n",
            "[EPOCH 146] TEST ACCURACY: 62.903\n",
            "4.569768071174622\n",
            "4.514713168144226\n",
            "4.58667927980423\n",
            "4.641381740570068\n",
            "4.505593955516815\n",
            "[EPOCH 151] VALID ACCURACY: 65.385\n",
            "[EPOCH 151] TEST ACCURACY: 62.903\n",
            "4.55444061756134\n",
            "4.572860896587372\n",
            "4.5217379331588745\n",
            "4.634571731090546\n",
            "4.513400137424469\n",
            "[EPOCH 156] VALID ACCURACY: 65.385\n",
            "[EPOCH 156] TEST ACCURACY: 62.903\n",
            "4.568736255168915\n",
            "4.552443087100983\n",
            "4.551785588264465\n",
            "4.654708623886108\n",
            "4.556296408176422\n",
            "[EPOCH 161] VALID ACCURACY: 65.385\n",
            "[EPOCH 161] TEST ACCURACY: 62.903\n",
            "4.560883402824402\n",
            "4.585120737552643\n",
            "4.508768796920776\n",
            "4.576979577541351\n",
            "4.608422040939331\n",
            "[EPOCH 166] VALID ACCURACY: 65.385\n",
            "[EPOCH 166] TEST ACCURACY: 62.903\n",
            "4.56512176990509\n",
            "4.554059386253357\n",
            "4.571576535701752\n",
            "4.514059126377106\n",
            "4.523356199264526\n",
            "[EPOCH 171] VALID ACCURACY: 65.385\n",
            "[EPOCH 171] TEST ACCURACY: 62.903\n",
            "4.574233770370483\n",
            "4.570059657096863\n",
            "4.489256203174591\n",
            "4.61613792181015\n",
            "4.529570460319519\n",
            "[EPOCH 176] VALID ACCURACY: 65.385\n",
            "[EPOCH 176] TEST ACCURACY: 62.903\n",
            "4.5636685490608215\n",
            "4.5910691022872925\n",
            "4.541426599025726\n",
            "4.53518533706665\n",
            "4.516362547874451\n",
            "[EPOCH 181] VALID ACCURACY: 65.385\n",
            "[EPOCH 181] TEST ACCURACY: 62.903\n",
            "4.594601035118103\n",
            "4.468095362186432\n",
            "4.615767002105713\n",
            "4.571856677532196\n",
            "4.554205238819122\n",
            "[EPOCH 186] VALID ACCURACY: 65.385\n",
            "[EPOCH 186] TEST ACCURACY: 62.903\n",
            "4.5245959758758545\n",
            "4.539042234420776\n",
            "4.577526271343231\n",
            "4.587598204612732\n",
            "4.577713370323181\n",
            "[EPOCH 191] VALID ACCURACY: 65.385\n",
            "[EPOCH 191] TEST ACCURACY: 62.903\n",
            "4.585966765880585\n",
            "4.484514534473419\n",
            "4.5843148827552795\n",
            "4.527589857578278\n",
            "4.556256890296936\n",
            "[EPOCH 196] VALID ACCURACY: 65.385\n",
            "[EPOCH 196] TEST ACCURACY: 62.903\n",
            "4.560002267360687\n",
            "4.52137964963913\n",
            "4.625717878341675\n",
            "4.566292941570282\n",
            "4.639458239078522\n",
            "[EPOCH 201] VALID ACCURACY: 65.385\n",
            "[EPOCH 201] TEST ACCURACY: 62.903\n",
            "4.60706490278244\n",
            "4.545587122440338\n",
            "4.543600022792816\n",
            "4.532766699790955\n",
            "4.498646676540375\n",
            "[EPOCH 206] VALID ACCURACY: 65.385\n",
            "[EPOCH 206] TEST ACCURACY: 62.903\n",
            "4.60717236995697\n",
            "4.580009162425995\n",
            "4.554517984390259\n",
            "4.588430941104889\n",
            "4.520156145095825\n",
            "[EPOCH 211] VALID ACCURACY: 65.385\n",
            "[EPOCH 211] TEST ACCURACY: 62.903\n",
            "4.503171980381012\n",
            "4.530816555023193\n",
            "4.474611282348633\n",
            "4.659073889255524\n",
            "4.536837160587311\n",
            "[EPOCH 216] VALID ACCURACY: 65.385\n",
            "[EPOCH 216] TEST ACCURACY: 62.903\n",
            "4.595049858093262\n",
            "4.54368132352829\n",
            "4.685742616653442\n",
            "4.564482390880585\n",
            "4.546148061752319\n",
            "[EPOCH 221] VALID ACCURACY: 65.385\n",
            "[EPOCH 221] TEST ACCURACY: 62.903\n",
            "4.441210687160492\n",
            "4.5721107721328735\n",
            "4.504715323448181\n",
            "4.542060017585754\n",
            "4.548376262187958\n",
            "[EPOCH 226] VALID ACCURACY: 65.385\n",
            "[EPOCH 226] TEST ACCURACY: 62.903\n",
            "4.513858437538147\n",
            "4.561031103134155\n",
            "4.5770469307899475\n",
            "4.563078701496124\n",
            "4.5426207184791565\n",
            "[EPOCH 231] VALID ACCURACY: 65.385\n",
            "[EPOCH 231] TEST ACCURACY: 62.903\n",
            "4.482864141464233\n",
            "4.632446765899658\n",
            "4.496549367904663\n",
            "4.500744521617889\n",
            "4.550398349761963\n",
            "[EPOCH 236] VALID ACCURACY: 65.385\n",
            "[EPOCH 236] TEST ACCURACY: 62.903\n",
            "4.596751570701599\n",
            "4.45415335893631\n",
            "4.479525446891785\n",
            "4.57171505689621\n",
            "4.556746184825897\n",
            "[EPOCH 241] VALID ACCURACY: 65.385\n",
            "[EPOCH 241] TEST ACCURACY: 62.903\n",
            "4.547691285610199\n",
            "4.549615979194641\n",
            "4.534640669822693\n",
            "4.552693605422974\n",
            "4.506739497184753\n",
            "[EPOCH 246] VALID ACCURACY: 65.385\n",
            "[EPOCH 246] TEST ACCURACY: 62.903\n",
            "4.540585279464722\n",
            "4.504806458950043\n",
            "4.4904409646987915\n",
            "4.52114337682724\n",
            "4.53997939825058\n",
            "[EPOCH 251] VALID ACCURACY: 65.385\n",
            "[EPOCH 251] TEST ACCURACY: 62.903\n",
            "4.5613168478012085\n",
            "4.576576828956604\n",
            "4.55440366268158\n",
            "4.53695547580719\n",
            "4.532157719135284\n",
            "[EPOCH 256] VALID ACCURACY: 65.385\n",
            "[EPOCH 256] TEST ACCURACY: 62.903\n",
            "4.532009780406952\n",
            "4.529423713684082\n",
            "4.548648357391357\n",
            "4.622505962848663\n",
            "4.569660902023315\n",
            "[EPOCH 261] VALID ACCURACY: 65.385\n",
            "[EPOCH 261] TEST ACCURACY: 62.903\n",
            "4.536352157592773\n",
            "4.578378438949585\n",
            "4.523745000362396\n",
            "4.584515392780304\n",
            "4.590821266174316\n",
            "[EPOCH 266] VALID ACCURACY: 65.385\n",
            "[EPOCH 266] TEST ACCURACY: 62.903\n",
            "4.509695053100586\n",
            "4.597825229167938\n",
            "4.570517182350159\n",
            "4.584247529506683\n",
            "4.547412991523743\n",
            "[EPOCH 271] VALID ACCURACY: 65.385\n",
            "[EPOCH 271] TEST ACCURACY: 62.903\n",
            "4.5434194803237915\n",
            "4.52942955493927\n",
            "4.499357998371124\n",
            "4.57450395822525\n",
            "4.521686255931854\n",
            "[EPOCH 276] VALID ACCURACY: 65.385\n",
            "[EPOCH 276] TEST ACCURACY: 62.903\n",
            "4.615111172199249\n",
            "4.470054626464844\n",
            "4.552179992198944\n",
            "4.5290937423706055\n",
            "4.546770602464676\n",
            "[EPOCH 281] VALID ACCURACY: 65.385\n",
            "[EPOCH 281] TEST ACCURACY: 62.903\n",
            "4.578486979007721\n",
            "4.559133946895599\n",
            "4.538465917110443\n",
            "4.674623131752014\n",
            "4.498074233531952\n",
            "[EPOCH 286] VALID ACCURACY: 65.385\n",
            "[EPOCH 286] TEST ACCURACY: 62.903\n",
            "4.566157698631287\n",
            "4.435726642608643\n",
            "4.5281646847724915\n",
            "4.584338486194611\n",
            "4.625773310661316\n",
            "[EPOCH 291] VALID ACCURACY: 65.385\n",
            "[EPOCH 291] TEST ACCURACY: 62.903\n",
            "4.5299853682518005\n",
            "4.523184418678284\n",
            "4.551893830299377\n",
            "4.458243429660797\n",
            "4.598698377609253\n",
            "[EPOCH 296] VALID ACCURACY: 65.385\n",
            "[EPOCH 296] TEST ACCURACY: 62.903\n",
            "4.568056762218475\n",
            "4.589117646217346\n",
            "4.611328721046448\n",
            "4.605823278427124\n",
            "Average best validation accuracy from all folds: 97.11538696289062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytMEn18tEa4U",
        "outputId": "bc798784-ad38-4ea7-e7d8-f41b4a272f5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training begins now.\n",
            "87.74785250425339\n",
            "[EPOCH 1] VALID ACCURACY: 57.407\n",
            "[EPOCH 1] TEST ACCURACY: 63.333\n",
            "98.86373734474182\n",
            "17.61649262905121\n",
            "22.454888582229614\n",
            "7.550754427909851\n",
            "7.66910719871521\n",
            "[EPOCH 6] VALID ACCURACY: 70.370\n",
            "[EPOCH 6] TEST ACCURACY: 61.667\n",
            "7.189432740211487\n",
            "6.898833751678467\n",
            "7.352171182632446\n",
            "7.001141130924225\n",
            "7.3790130615234375\n",
            "[EPOCH 11] VALID ACCURACY: 70.370\n",
            "[EPOCH 11] TEST ACCURACY: 61.667\n",
            "6.7913647294044495\n",
            "7.701768934726715\n",
            "7.4390259981155396\n",
            "6.810224235057831\n",
            "6.506443083286285\n",
            "[EPOCH 16] VALID ACCURACY: 70.370\n",
            "[EPOCH 16] TEST ACCURACY: 61.667\n",
            "7.24504828453064\n",
            "7.26713240146637\n",
            "7.118760108947754\n",
            "7.303038716316223\n",
            "6.413333594799042\n",
            "[EPOCH 21] VALID ACCURACY: 70.370\n",
            "[EPOCH 21] TEST ACCURACY: 61.667\n",
            "7.023505747318268\n",
            "6.430636405944824\n",
            "6.691963255405426\n",
            "6.525402247905731\n",
            "6.439674258232117\n",
            "[EPOCH 26] VALID ACCURACY: 70.370\n",
            "[EPOCH 26] TEST ACCURACY: 61.667\n",
            "6.556913256645203\n",
            "6.7450984716415405\n",
            "6.736458122730255\n",
            "6.406500935554504\n",
            "6.95078432559967\n",
            "[EPOCH 31] VALID ACCURACY: 70.370\n",
            "[EPOCH 31] TEST ACCURACY: 61.667\n",
            "6.573247969150543\n",
            "6.202425241470337\n",
            "6.506989538669586\n",
            "6.374629497528076\n",
            "6.541065335273743\n",
            "[EPOCH 36] VALID ACCURACY: 70.370\n",
            "[EPOCH 36] TEST ACCURACY: 61.667\n",
            "6.641308426856995\n",
            "6.5671679973602295\n",
            "6.6516183614730835\n",
            "6.651118755340576\n",
            "6.743155777454376\n",
            "[EPOCH 41] VALID ACCURACY: 70.370\n",
            "[EPOCH 41] TEST ACCURACY: 61.667\n",
            "7.103489935398102\n",
            "6.601774036884308\n",
            "7.004699110984802\n",
            "6.644938945770264\n",
            "6.660447955131531\n",
            "[EPOCH 46] VALID ACCURACY: 70.370\n",
            "[EPOCH 46] TEST ACCURACY: 61.667\n",
            "6.591979205608368\n",
            "6.461536526679993\n",
            "6.7003955245018005\n",
            "6.638321936130524\n",
            "6.384406208992004\n",
            "[EPOCH 51] VALID ACCURACY: 70.370\n",
            "[EPOCH 51] TEST ACCURACY: 61.667\n",
            "6.438438892364502\n",
            "6.902880012989044\n",
            "7.01365864276886\n",
            "6.741681396961212\n",
            "6.353623449802399\n",
            "[EPOCH 56] VALID ACCURACY: 70.370\n",
            "[EPOCH 56] TEST ACCURACY: 61.667\n",
            "6.2735327780246735\n",
            "6.958178877830505\n",
            "6.423156797885895\n",
            "6.852429151535034\n",
            "6.677887141704559\n",
            "[EPOCH 61] VALID ACCURACY: 70.370\n",
            "[EPOCH 61] TEST ACCURACY: 61.667\n",
            "6.919077515602112\n",
            "7.097870647907257\n",
            "6.835322856903076\n",
            "7.154792904853821\n",
            "6.544926941394806\n",
            "[EPOCH 66] VALID ACCURACY: 70.370\n",
            "[EPOCH 66] TEST ACCURACY: 61.667\n",
            "6.66527259349823\n",
            "6.382335603237152\n",
            "6.805853545665741\n",
            "6.593825697898865\n",
            "6.501128792762756\n",
            "[EPOCH 71] VALID ACCURACY: 70.370\n",
            "[EPOCH 71] TEST ACCURACY: 61.667\n",
            "6.905717730522156\n",
            "6.878500521183014\n",
            "6.539611101150513\n",
            "6.583797216415405\n",
            "6.312405288219452\n",
            "[EPOCH 76] VALID ACCURACY: 70.370\n",
            "[EPOCH 76] TEST ACCURACY: 61.667\n",
            "6.614596247673035\n",
            "6.765178978443146\n",
            "6.7768648862838745\n",
            "6.5852566957473755\n",
            "6.629318177700043\n",
            "[EPOCH 81] VALID ACCURACY: 70.370\n",
            "[EPOCH 81] TEST ACCURACY: 61.667\n",
            "7.011684536933899\n",
            "6.402952432632446\n",
            "6.592065513134003\n",
            "6.567800760269165\n",
            "7.082778513431549\n",
            "[EPOCH 86] VALID ACCURACY: 70.370\n",
            "[EPOCH 86] TEST ACCURACY: 61.667\n",
            "6.77710235118866\n",
            "6.767275631427765\n",
            "6.347893118858337\n",
            "6.646559715270996\n",
            "6.3747793436050415\n",
            "[EPOCH 91] VALID ACCURACY: 70.370\n",
            "[EPOCH 91] TEST ACCURACY: 61.667\n",
            "6.878399431705475\n",
            "6.446665942668915\n",
            "7.308390855789185\n",
            "6.548298180103302\n",
            "6.3483129143714905\n",
            "[EPOCH 96] VALID ACCURACY: 70.370\n",
            "[EPOCH 96] TEST ACCURACY: 63.333\n",
            "7.650324642658234\n",
            "7.620470881462097\n",
            "7.7183051109313965\n",
            "7.184480130672455\n",
            "6.7559385895729065\n",
            "[EPOCH 101] VALID ACCURACY: 70.370\n",
            "[EPOCH 101] TEST ACCURACY: 61.667\n",
            "6.874029636383057\n",
            "6.484061181545258\n",
            "6.887408077716827\n",
            "6.533754944801331\n",
            "6.234382450580597\n",
            "[EPOCH 106] VALID ACCURACY: 70.370\n",
            "[EPOCH 106] TEST ACCURACY: 61.667\n",
            "6.3355037569999695\n",
            "5.876940190792084\n",
            "6.539638638496399\n",
            "6.964744687080383\n",
            "6.372308433055878\n",
            "[EPOCH 111] VALID ACCURACY: 70.370\n",
            "[EPOCH 111] TEST ACCURACY: 61.667\n",
            "6.220433592796326\n",
            "4.755962133407593\n",
            "4.901788413524628\n",
            "4.918975621461868\n",
            "4.579707235097885\n",
            "[EPOCH 116] VALID ACCURACY: 88.889\n",
            "[EPOCH 116] TEST ACCURACY: 88.333\n",
            "4.273999273777008\n",
            "3.521941900253296\n",
            "4.053098261356354\n",
            "4.056669235229492\n",
            "3.762753427028656\n",
            "[EPOCH 121] VALID ACCURACY: 88.889\n",
            "[EPOCH 121] TEST ACCURACY: 88.333\n",
            "3.5988045036792755\n",
            "3.5442540049552917\n",
            "3.7298524379730225\n",
            "3.1338628828525543\n",
            "3.3372955322265625\n",
            "[EPOCH 126] VALID ACCURACY: 88.889\n",
            "[EPOCH 126] TEST ACCURACY: 88.333\n",
            "3.0844407975673676\n",
            "2.943980783224106\n",
            "3.4837570786476135\n",
            "5.729760855436325\n",
            "3.358552247285843\n",
            "[EPOCH 131] VALID ACCURACY: 88.889\n",
            "[EPOCH 131] TEST ACCURACY: 88.333\n",
            "3.67333921790123\n",
            "3.60826712846756\n",
            "3.5447213649749756\n",
            "3.407779276371002\n",
            "3.5589839220046997\n",
            "[EPOCH 136] VALID ACCURACY: 88.889\n",
            "[EPOCH 136] TEST ACCURACY: 88.333\n",
            "2.9426783621311188\n",
            "3.025582656264305\n",
            "3.5787874907255173\n",
            "3.5294098556041718\n",
            "3.7497032582759857\n",
            "[EPOCH 141] VALID ACCURACY: 88.889\n",
            "[EPOCH 141] TEST ACCURACY: 86.667\n",
            "3.7354717552661896\n",
            "4.970817744731903\n",
            "4.464384138584137\n",
            "3.1972897946834564\n",
            "3.177448719739914\n",
            "[EPOCH 146] VALID ACCURACY: 88.889\n",
            "[EPOCH 146] TEST ACCURACY: 88.333\n",
            "2.824385493993759\n",
            "3.2600134909152985\n",
            "3.061042070388794\n",
            "3.1443860232830048\n",
            "3.3691800087690353\n",
            "[EPOCH 151] VALID ACCURACY: 88.889\n",
            "[EPOCH 151] TEST ACCURACY: 88.333\n",
            "3.2172959744930267\n",
            "3.9488628804683685\n",
            "3.0242435336112976\n",
            "2.927609659731388\n",
            "3.1458751261234283\n",
            "[EPOCH 156] VALID ACCURACY: 88.889\n",
            "[EPOCH 156] TEST ACCURACY: 88.333\n",
            "3.4006152749061584\n",
            "3.187872141599655\n",
            "3.220764607191086\n",
            "3.486104130744934\n",
            "2.985059529542923\n",
            "[EPOCH 161] VALID ACCURACY: 88.889\n",
            "[EPOCH 161] TEST ACCURACY: 88.333\n",
            "3.0219477117061615\n",
            "3.2553091943264008\n",
            "2.9216749370098114\n",
            "3.2516240626573563\n",
            "3.0703010261058807\n",
            "[EPOCH 166] VALID ACCURACY: 88.889\n",
            "[EPOCH 166] TEST ACCURACY: 88.333\n",
            "3.2955820560455322\n",
            "3.261163979768753\n",
            "3.009000927209854\n",
            "2.804402247071266\n",
            "3.0458199977874756\n",
            "[EPOCH 171] VALID ACCURACY: 88.889\n",
            "[EPOCH 171] TEST ACCURACY: 88.333\n",
            "3.038281112909317\n",
            "2.783979281783104\n",
            "2.75689135491848\n",
            "2.781627982854843\n",
            "3.0270623862743378\n",
            "[EPOCH 176] VALID ACCURACY: 88.889\n",
            "[EPOCH 176] TEST ACCURACY: 88.333\n",
            "2.4929183945059776\n",
            "2.2847216203808784\n",
            "2.200333885848522\n",
            "2.652009602636099\n",
            "2.681274712085724\n",
            "[EPOCH 181] VALID ACCURACY: 88.889\n",
            "[EPOCH 181] TEST ACCURACY: 88.333\n",
            "2.8586697727441788\n",
            "2.3577381372451782\n",
            "3.362751305103302\n",
            "3.3327682316303253\n",
            "2.7824721187353134\n",
            "[EPOCH 186] VALID ACCURACY: 88.889\n",
            "[EPOCH 186] TEST ACCURACY: 88.333\n",
            "3.000039353966713\n",
            "2.7275231182575226\n",
            "2.4598669558763504\n",
            "2.1755113042891026\n",
            "2.786759849637747\n",
            "[EPOCH 191] VALID ACCURACY: 75.926\n",
            "[EPOCH 191] TEST ACCURACY: 65.000\n",
            "3.3965910971164703\n",
            "2.867481529712677\n",
            "3.2030070424079895\n",
            "2.749062016606331\n",
            "2.6657626628875732\n",
            "[EPOCH 196] VALID ACCURACY: 90.741\n",
            "[EPOCH 196] TEST ACCURACY: 91.667\n",
            "2.8570856526494026\n",
            "2.3293581902980804\n",
            "2.264785811305046\n",
            "2.302096664905548\n",
            "2.4076030403375626\n",
            "[EPOCH 201] VALID ACCURACY: 90.741\n",
            "[EPOCH 201] TEST ACCURACY: 93.333\n",
            "1.9273193935514428\n",
            "6.080096788704395\n",
            "11.160157263278961\n",
            "21.002252086997032\n",
            "10.126648008823395\n",
            "[EPOCH 206] VALID ACCURACY: 88.889\n",
            "[EPOCH 206] TEST ACCURACY: 88.333\n",
            "21.79240530729294\n",
            "16.976810064108577\n",
            "7.783867627382278\n",
            "6.12466087937355\n",
            "4.782553285360336\n",
            "[EPOCH 211] VALID ACCURACY: 70.370\n",
            "[EPOCH 211] TEST ACCURACY: 61.667\n",
            "3.8014991879463196\n",
            "5.549316346645355\n",
            "4.925919026136398\n",
            "4.227041721343994\n",
            "3.433835804462433\n",
            "[EPOCH 216] VALID ACCURACY: 88.889\n",
            "[EPOCH 216] TEST ACCURACY: 88.333\n",
            "2.874354273080826\n",
            "3.2484171390533447\n",
            "3.4403743147850037\n",
            "2.8597636818885803\n",
            "3.6864984333515167\n",
            "[EPOCH 221] VALID ACCURACY: 90.741\n",
            "[EPOCH 221] TEST ACCURACY: 88.333\n",
            "2.745596021413803\n",
            "2.9793657064437866\n",
            "3.32776802778244\n",
            "2.852891683578491\n",
            "2.8571451753377914\n",
            "[EPOCH 226] VALID ACCURACY: 88.889\n",
            "[EPOCH 226] TEST ACCURACY: 88.333\n",
            "3.1000345051288605\n",
            "2.6889903843402863\n",
            "3.065393939614296\n",
            "2.344784215092659\n",
            "2.601744830608368\n",
            "[EPOCH 231] VALID ACCURACY: 88.889\n",
            "[EPOCH 231] TEST ACCURACY: 91.667\n",
            "4.479196384549141\n",
            "5.636175036430359\n",
            "4.372226610779762\n",
            "3.3153206259012222\n",
            "2.9914122745394707\n",
            "[EPOCH 236] VALID ACCURACY: 88.889\n",
            "[EPOCH 236] TEST ACCURACY: 88.333\n",
            "2.927180990576744\n",
            "2.451533133164048\n",
            "2.6772480737417936\n",
            "3.114543929696083\n",
            "2.7600997984409332\n",
            "[EPOCH 241] VALID ACCURACY: 90.741\n",
            "[EPOCH 241] TEST ACCURACY: 91.667\n",
            "2.5840011835098267\n",
            "7.361498273909092\n",
            "2.5212729275226593\n",
            "4.936425715684891\n",
            "2.9848373481072485\n",
            "[EPOCH 246] VALID ACCURACY: 88.889\n",
            "[EPOCH 246] TEST ACCURACY: 88.333\n",
            "2.9642549753189087\n",
            "2.3841323107481003\n",
            "1.9730302393436432\n",
            "2.4859079271554947\n",
            "2.230264663696289\n",
            "[EPOCH 251] VALID ACCURACY: 90.741\n",
            "[EPOCH 251] TEST ACCURACY: 91.667\n",
            "2.5526909977197647\n",
            "2.497691437602043\n",
            "2.2441997611895204\n",
            "2.630409449338913\n",
            "2.924429029226303\n",
            "[EPOCH 256] VALID ACCURACY: 90.741\n",
            "[EPOCH 256] TEST ACCURACY: 88.333\n",
            "2.043884038925171\n",
            "2.173300579190254\n",
            "2.177694782614708\n",
            "2.3762076050043106\n",
            "2.2849298417568207\n",
            "[EPOCH 261] VALID ACCURACY: 90.741\n",
            "[EPOCH 261] TEST ACCURACY: 91.667\n",
            "2.6676637083292007\n",
            "3.1425335109233856\n",
            "1.8154759630560875\n",
            "2.6986010372638702\n",
            "2.913566529750824\n",
            "[EPOCH 266] VALID ACCURACY: 90.741\n",
            "[EPOCH 266] TEST ACCURACY: 90.000\n",
            "2.5837977081537247\n",
            "2.073009103536606\n",
            "2.068286180496216\n",
            "1.8943037576973438\n",
            "1.73393876850605\n",
            "[EPOCH 271] VALID ACCURACY: 90.741\n",
            "[EPOCH 271] TEST ACCURACY: 91.667\n",
            "2.2487351447343826\n",
            "1.8230341374874115\n",
            "2.60985603928566\n",
            "2.9951105266809464\n",
            "2.541189044713974\n",
            "[EPOCH 276] VALID ACCURACY: 90.741\n",
            "[EPOCH 276] TEST ACCURACY: 91.667\n",
            "2.44451966881752\n",
            "2.2264459803700447\n",
            "3.866983348503709\n",
            "1.999777466058731\n",
            "2.0095629692077637\n",
            "[EPOCH 281] VALID ACCURACY: 94.444\n",
            "[EPOCH 281] TEST ACCURACY: 95.000\n",
            "1.81942917406559\n",
            "3.1044280529022217\n",
            "2.042965415865183\n",
            "3.102633625268936\n",
            "2.1529613714665174\n",
            "[EPOCH 286] VALID ACCURACY: 90.741\n",
            "[EPOCH 286] TEST ACCURACY: 88.333\n",
            "2.392593964934349\n",
            "2.5107249543070793\n",
            "2.8432075828313828\n",
            "2.0191068053245544\n",
            "2.8637565597891808\n",
            "[EPOCH 291] VALID ACCURACY: 88.889\n",
            "[EPOCH 291] TEST ACCURACY: 91.667\n",
            "2.730295807123184\n",
            "2.368461787700653\n",
            "2.209277555346489\n",
            "2.131783187389374\n",
            "3.718644544482231\n",
            "[EPOCH 296] VALID ACCURACY: 96.296\n",
            "[EPOCH 296] TEST ACCURACY: 95.000\n",
            "2.2823127135634422\n",
            "2.072273440659046\n",
            "1.9682108610868454\n",
            "1.787818893790245\n",
            "2.142806351184845\n",
            "[EPOCH 301] VALID ACCURACY: 92.593\n",
            "[EPOCH 301] TEST ACCURACY: 85.000\n",
            "2.662181407213211\n",
            "2.3086492642760277\n",
            "3.0377699583768845\n",
            "2.9002342969179153\n",
            "6.232573494315147\n",
            "[EPOCH 306] VALID ACCURACY: 90.741\n",
            "[EPOCH 306] TEST ACCURACY: 91.667\n",
            "4.123112171888351\n",
            "2.5229242146015167\n",
            "2.9448308050632477\n",
            "2.667254760861397\n",
            "3.226661592721939\n",
            "[EPOCH 311] VALID ACCURACY: 92.593\n",
            "[EPOCH 311] TEST ACCURACY: 91.667\n",
            "2.579987771809101\n",
            "2.4285942912101746\n",
            "2.02280505374074\n",
            "1.7929221540689468\n",
            "2.504037022590637\n",
            "[EPOCH 316] VALID ACCURACY: 90.741\n",
            "[EPOCH 316] TEST ACCURACY: 93.333\n",
            "2.4908787459135056\n",
            "2.4431097209453583\n",
            "1.9781589061021805\n",
            "2.078804526478052\n",
            "1.8049819320440292\n",
            "[EPOCH 321] VALID ACCURACY: 92.593\n",
            "[EPOCH 321] TEST ACCURACY: 95.000\n",
            "1.6248287484049797\n",
            "1.635111328214407\n",
            "2.7120802104473114\n",
            "1.8404980432242155\n",
            "1.9698030799627304\n",
            "[EPOCH 326] VALID ACCURACY: 96.296\n",
            "[EPOCH 326] TEST ACCURACY: 91.667\n",
            "2.180544301867485\n",
            "1.6339398995041847\n",
            "2.1111441291868687\n",
            "1.7493237406015396\n",
            "1.651649370789528\n",
            "[EPOCH 331] VALID ACCURACY: 94.444\n",
            "[EPOCH 331] TEST ACCURACY: 95.000\n",
            "1.620364859700203\n",
            "1.656623624265194\n",
            "1.5678695961833\n",
            "1.5558621734380722\n",
            "1.5293351951986551\n",
            "[EPOCH 336] VALID ACCURACY: 92.593\n",
            "[EPOCH 336] TEST ACCURACY: 95.000\n",
            "1.860529586672783\n",
            "1.912799559533596\n",
            "2.351347114890814\n",
            "1.7286582626402378\n",
            "2.0439493507146835\n",
            "[EPOCH 341] VALID ACCURACY: 92.593\n",
            "[EPOCH 341] TEST ACCURACY: 91.667\n",
            "2.2838335409760475\n",
            "2.614059343934059\n",
            "7.914293125271797\n",
            "9.365231305360794\n",
            "14.96415787935257\n",
            "[EPOCH 346] VALID ACCURACY: 70.370\n",
            "[EPOCH 346] TEST ACCURACY: 61.667\n",
            "15.730307161808014\n",
            "98.29052352905273\n",
            "10.62508076429367\n",
            "4.154520481824875\n",
            "4.578149616718292\n",
            "[EPOCH 351] VALID ACCURACY: 22.222\n",
            "[EPOCH 351] TEST ACCURACY: 33.333\n",
            "7.2160464227199554\n",
            "3.5074699223041534\n",
            "4.556261375546455\n",
            "6.789638549089432\n",
            "3.79268516600132\n",
            "[EPOCH 356] VALID ACCURACY: 22.222\n",
            "[EPOCH 356] TEST ACCURACY: 31.667\n",
            "4.289176821708679\n",
            "2.324830338358879\n",
            "3.7939477413892746\n",
            "3.2336865663528442\n",
            "2.9187643826007843\n",
            "[EPOCH 361] VALID ACCURACY: 90.741\n",
            "[EPOCH 361] TEST ACCURACY: 91.667\n",
            "2.4897719621658325\n",
            "2.4909836798906326\n",
            "2.5962960571050644\n",
            "2.2857466489076614\n",
            "2.4015107452869415\n",
            "[EPOCH 366] VALID ACCURACY: 90.741\n",
            "[EPOCH 366] TEST ACCURACY: 91.667\n",
            "2.2817287147045135\n",
            "2.009536564350128\n",
            "5.85890656709671\n",
            "5.245912820100784\n",
            "7.1522276699543\n",
            "[EPOCH 371] VALID ACCURACY: 88.889\n",
            "[EPOCH 371] TEST ACCURACY: 88.333\n",
            "8.66307227082143\n",
            "7.7453543320298195\n",
            "6.773146957159042\n",
            "2.9820087552070618\n",
            "2.528559982776642\n",
            "[EPOCH 376] VALID ACCURACY: 90.741\n",
            "[EPOCH 376] TEST ACCURACY: 91.667\n",
            "2.5749146938323975\n",
            "2.411065950989723\n",
            "2.629340298473835\n",
            "2.3021285384893417\n",
            "2.6039870381355286\n",
            "[EPOCH 381] VALID ACCURACY: 90.741\n",
            "[EPOCH 381] TEST ACCURACY: 93.333\n",
            "3.138357922434807\n",
            "2.282633051276207\n",
            "2.2526858150959015\n",
            "2.675281286239624\n",
            "1.8746432438492775\n",
            "[EPOCH 386] VALID ACCURACY: 90.741\n",
            "[EPOCH 386] TEST ACCURACY: 93.333\n",
            "2.2988879680633545\n",
            "2.175534501671791\n",
            "2.3792582526803017\n",
            "2.1703064367175102\n",
            "2.407562881708145\n",
            "[EPOCH 391] VALID ACCURACY: 92.593\n",
            "[EPOCH 391] TEST ACCURACY: 90.000\n",
            "2.83929480612278\n",
            "2.269994780421257\n",
            "2.521706759929657\n",
            "2.0586474910378456\n",
            "3.2241933047771454\n",
            "[EPOCH 396] VALID ACCURACY: 92.593\n",
            "[EPOCH 396] TEST ACCURACY: 90.000\n",
            "2.972452148795128\n",
            "2.821785628795624\n",
            "2.8207003474235535\n",
            "2.2369061782956123\n",
            "2.667389005422592\n",
            "[EPOCH 401] VALID ACCURACY: 90.741\n",
            "[EPOCH 401] TEST ACCURACY: 88.333\n",
            "2.6315908282995224\n",
            "2.3477909862995148\n",
            "2.866014674305916\n",
            "2.5492146611213684\n",
            "2.493552267551422\n",
            "[EPOCH 406] VALID ACCURACY: 90.741\n",
            "[EPOCH 406] TEST ACCURACY: 91.667\n",
            "2.199269711971283\n",
            "2.7370771169662476\n",
            "2.2303096503019333\n",
            "2.588326334953308\n",
            "2.178766444325447\n",
            "[EPOCH 411] VALID ACCURACY: 90.741\n",
            "[EPOCH 411] TEST ACCURACY: 91.667\n",
            "2.427125945687294\n",
            "2.1692303866147995\n",
            "1.9214787855744362\n",
            "2.130849167704582\n",
            "2.60416616499424\n",
            "[EPOCH 416] VALID ACCURACY: 90.741\n",
            "[EPOCH 416] TEST ACCURACY: 93.333\n",
            "2.3081523030996323\n",
            "3.4021880328655243\n",
            "3.1297139450907707\n",
            "3.1957335472106934\n",
            "2.954487219452858\n",
            "[EPOCH 421] VALID ACCURACY: 88.889\n",
            "[EPOCH 421] TEST ACCURACY: 88.333\n",
            "2.7786466628313065\n",
            "3.0832220911979675\n",
            "2.99094158411026\n",
            "3.5399593859910965\n",
            "3.1831517815589905\n",
            "[EPOCH 426] VALID ACCURACY: 88.889\n",
            "[EPOCH 426] TEST ACCURACY: 88.333\n",
            "3.0995119214057922\n",
            "2.991603583097458\n",
            "3.1482435762882233\n",
            "2.8582464307546616\n",
            "2.7291061729192734\n",
            "[EPOCH 431] VALID ACCURACY: 90.741\n",
            "[EPOCH 431] TEST ACCURACY: 88.333\n",
            "2.739209696650505\n",
            "2.6092367321252823\n",
            "3.1657140851020813\n",
            "3.0109097361564636\n",
            "2.876148819923401\n",
            "[EPOCH 436] VALID ACCURACY: 90.741\n",
            "[EPOCH 436] TEST ACCURACY: 88.333\n",
            "2.130601242184639\n",
            "2.169626086950302\n",
            "2.527963638305664\n",
            "2.392616853117943\n",
            "2.475569248199463\n",
            "[EPOCH 441] VALID ACCURACY: 90.741\n",
            "[EPOCH 441] TEST ACCURACY: 90.000\n",
            "2.098228804767132\n",
            "2.30476613342762\n",
            "1.9546840228140354\n",
            "2.2160110771656036\n",
            "2.204673483967781\n",
            "[EPOCH 446] VALID ACCURACY: 90.741\n",
            "[EPOCH 446] TEST ACCURACY: 91.667\n",
            "1.766905251890421\n",
            "3.364311993122101\n",
            "4.218816488981247\n",
            "2.0824009738862514\n",
            "1.9741691946983337\n",
            "[EPOCH 451] VALID ACCURACY: 90.741\n",
            "[EPOCH 451] TEST ACCURACY: 91.667\n",
            "1.8342647328972816\n",
            "1.858451947569847\n",
            "1.859247475862503\n",
            "1.7364870198071003\n",
            "2.3544639125466347\n",
            "[EPOCH 456] VALID ACCURACY: 90.741\n",
            "[EPOCH 456] TEST ACCURACY: 91.667\n",
            "2.1505281031131744\n",
            "2.2964140083640814\n",
            "3.44553779065609\n",
            "2.166010059416294\n",
            "2.9548459500074387\n",
            "[EPOCH 461] VALID ACCURACY: 88.889\n",
            "[EPOCH 461] TEST ACCURACY: 90.000\n",
            "2.7376630306243896\n",
            "2.7487078458070755\n",
            "2.9595289528369904\n",
            "3.120356932282448\n",
            "3.1950243711471558\n",
            "[EPOCH 466] VALID ACCURACY: 92.593\n",
            "[EPOCH 466] TEST ACCURACY: 88.333\n",
            "3.235131323337555\n",
            "2.7424409687519073\n",
            "2.4286665841937065\n",
            "3.272763580083847\n",
            "2.4084544330835342\n",
            "[EPOCH 471] VALID ACCURACY: 90.741\n",
            "[EPOCH 471] TEST ACCURACY: 91.667\n",
            "2.3648325353860855\n",
            "3.004170387983322\n",
            "2.795844078063965\n",
            "2.666400760412216\n",
            "2.326541319489479\n",
            "[EPOCH 476] VALID ACCURACY: 88.889\n",
            "[EPOCH 476] TEST ACCURACY: 88.333\n",
            "2.3575554713606834\n",
            "2.293415606021881\n",
            "2.2584454864263535\n",
            "2.5189898759126663\n",
            "2.806055024266243\n",
            "[EPOCH 481] VALID ACCURACY: 92.593\n",
            "[EPOCH 481] TEST ACCURACY: 91.667\n",
            "2.2294175773859024\n",
            "2.056683734059334\n",
            "2.371371626853943\n",
            "2.566551685333252\n",
            "3.376372344791889\n",
            "[EPOCH 486] VALID ACCURACY: 88.889\n",
            "[EPOCH 486] TEST ACCURACY: 85.000\n",
            "2.9300137609243393\n",
            "2.241965003311634\n",
            "2.074014201760292\n",
            "2.1973763071000576\n",
            "1.972994051873684\n",
            "[EPOCH 491] VALID ACCURACY: 90.741\n",
            "[EPOCH 491] TEST ACCURACY: 93.333\n",
            "1.7574560418725014\n",
            "2.2172595486044884\n",
            "2.5947822853922844\n",
            "2.080487310886383\n",
            "1.7679027616977692\n",
            "[EPOCH 496] VALID ACCURACY: 90.741\n",
            "[EPOCH 496] TEST ACCURACY: 91.667\n",
            "2.4923588782548904\n",
            "1.9000133648514748\n",
            "1.7815831378102303\n",
            "1.970307432115078\n",
            "1.7299597263336182\n",
            "[EPOCH 501] VALID ACCURACY: 88.889\n",
            "[EPOCH 501] TEST ACCURACY: 91.667\n",
            "1.8846375867724419\n",
            "1.707006424665451\n",
            "1.945968009531498\n",
            "1.7081026211380959\n",
            "3.2170442640781403\n",
            "[EPOCH 506] VALID ACCURACY: 90.741\n",
            "[EPOCH 506] TEST ACCURACY: 93.333\n",
            "2.2821265310049057\n",
            "2.2766059562563896\n",
            "1.7466868981719017\n",
            "2.454852744936943\n",
            "2.439900130033493\n",
            "[EPOCH 511] VALID ACCURACY: 90.741\n",
            "[EPOCH 511] TEST ACCURACY: 91.667\n",
            "3.8478281497955322\n",
            "3.3449713438749313\n",
            "4.990484431385994\n",
            "3.3950958624482155\n",
            "3.5575090497732162\n",
            "[EPOCH 516] VALID ACCURACY: 88.889\n",
            "[EPOCH 516] TEST ACCURACY: 88.333\n",
            "2.8980895280838013\n",
            "2.9131966084241867\n",
            "2.7840196192264557\n",
            "2.253621134907007\n",
            "2.0902152210474014\n",
            "[EPOCH 521] VALID ACCURACY: 94.444\n",
            "[EPOCH 521] TEST ACCURACY: 90.000\n",
            "1.8004538901150227\n",
            "2.365117147564888\n",
            "1.9831698685884476\n",
            "1.8113707229495049\n",
            "1.7949313521385193\n",
            "[EPOCH 526] VALID ACCURACY: 90.741\n",
            "[EPOCH 526] TEST ACCURACY: 88.333\n",
            "2.166606619954109\n",
            "2.409389227628708\n",
            "2.8376782089471817\n",
            "2.302933096885681\n",
            "2.3228062614798546\n",
            "[EPOCH 531] VALID ACCURACY: 90.741\n",
            "[EPOCH 531] TEST ACCURACY: 88.333\n",
            "1.878868941217661\n",
            "1.7641734965145588\n",
            "1.7620114125311375\n",
            "2.538706049323082\n",
            "1.8403757438063622\n",
            "[EPOCH 536] VALID ACCURACY: 90.741\n",
            "[EPOCH 536] TEST ACCURACY: 91.667\n",
            "2.198964886367321\n",
            "2.0461217761039734\n",
            "1.8937897570431232\n",
            "1.8612638339400291\n",
            "2.2849020063877106\n",
            "[EPOCH 541] VALID ACCURACY: 90.741\n",
            "[EPOCH 541] TEST ACCURACY: 91.667\n",
            "2.020039066672325\n",
            "2.0328588634729385\n",
            "1.9794072657823563\n",
            "2.052316725254059\n",
            "2.084440156817436\n",
            "[EPOCH 546] VALID ACCURACY: 90.741\n",
            "[EPOCH 546] TEST ACCURACY: 93.333\n",
            "1.6644960772246122\n",
            "1.9795204475522041\n",
            "1.986698105931282\n",
            "2.255004972219467\n",
            "1.8678526431322098\n",
            "[EPOCH 551] VALID ACCURACY: 94.444\n",
            "[EPOCH 551] TEST ACCURACY: 91.667\n",
            "1.8257855251431465\n",
            "1.684911448508501\n",
            "1.7932200357317924\n",
            "1.8363726884126663\n",
            "2.6433001160621643\n",
            "[EPOCH 556] VALID ACCURACY: 90.741\n",
            "[EPOCH 556] TEST ACCURACY: 91.667\n",
            "3.9714680910110474\n",
            "3.354671485722065\n",
            "2.446075737476349\n",
            "1.9644873961806297\n",
            "1.9823684841394424\n",
            "[EPOCH 561] VALID ACCURACY: 94.444\n",
            "[EPOCH 561] TEST ACCURACY: 91.667\n",
            "1.7620073705911636\n",
            "4.199484333395958\n",
            "2.425529696047306\n",
            "2.4586673378944397\n",
            "2.441708706319332\n",
            "[EPOCH 566] VALID ACCURACY: 88.889\n",
            "[EPOCH 566] TEST ACCURACY: 88.333\n",
            "2.575113359838724\n",
            "2.221417397260666\n",
            "1.998936876654625\n",
            "1.984661027789116\n",
            "1.8615802600979805\n",
            "[EPOCH 571] VALID ACCURACY: 90.741\n",
            "[EPOCH 571] TEST ACCURACY: 91.667\n",
            "2.538784183561802\n",
            "1.8478731028735638\n",
            "7.364356189966202\n",
            "2.540251523256302\n",
            "1.9125471953302622\n",
            "[EPOCH 576] VALID ACCURACY: 88.889\n",
            "[EPOCH 576] TEST ACCURACY: 88.333\n",
            "7.992392033338547\n",
            "18.046055614948273\n",
            "22.734778298065066\n",
            "57.27257315814495\n",
            "729.5182414054871\n",
            "[EPOCH 581] VALID ACCURACY: 88.889\n",
            "[EPOCH 581] TEST ACCURACY: 88.333\n",
            "386.1283836364746\n",
            "271.02577686309814\n",
            "76.91850170493126\n",
            "122.3325874209404\n",
            "25.494346618652344\n",
            "[EPOCH 586] VALID ACCURACY: 90.741\n",
            "[EPOCH 586] TEST ACCURACY: 91.667\n",
            "14.064804077148438\n",
            "28.370451867580414\n",
            "11.082873076200485\n",
            "9.099437057971954\n",
            "6.341711504384875\n",
            "[EPOCH 591] VALID ACCURACY: 88.889\n",
            "[EPOCH 591] TEST ACCURACY: 90.000\n",
            "4.4764876663684845\n",
            "5.086624562740326\n",
            "2.956579178571701\n",
            "2.613035425543785\n",
            "3.0656783878803253\n",
            "[EPOCH 596] VALID ACCURACY: 92.593\n",
            "[EPOCH 596] TEST ACCURACY: 88.333\n",
            "3.13348525762558\n",
            "2.532093569636345\n",
            "2.3496030271053314\n",
            "1.954783458262682\n",
            "TOTAL NUMBER OF PARAMS: 109770460\n",
            "Accuracy on best model:  95.000\n"
          ]
        }
      ],
      "source": [
        "best_valid_auroc = 0\n",
        "best_valid_accuracy = 0\n",
        "best_test_auroc = 0\n",
        "best_test_accuracy = 0\n",
        "best_valid_rmse = 100000\n",
        "print('Training begins now.')\n",
        "for epoch in range(600):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        optimizer.zero_grad()\n",
        "        # x_categ is the the categorical data, with y appended as last feature. x_cont has continuous data. cat_mask is an array of ones same shape as x_categ except for last column(corresponding to y's) set to 0s. con_mask is an array of ones same shape as x_cont.\n",
        "        x_categ, x_cont, y_gts, cat_mask, con_mask = data[0].to(device), data[1].to(device),data[2].to(device),data[3].to(device),data[4].to(device)\n",
        "        if opt.train_noise_type is not None and opt.train_noise_level>0:\n",
        "            noise_dict = {\n",
        "                'noise_type' : opt.train_noise_type,\n",
        "                'lambda' : opt.train_noise_level\n",
        "            }\n",
        "            if opt.train_noise_type == 'cutmix':\n",
        "                x_categ, x_cont = add_noise(x_categ,x_cont, noise_params = noise_dict)\n",
        "            elif opt.train_noise_type == 'missing':\n",
        "                cat_mask, con_mask = add_noise(cat_mask, con_mask, noise_params = noise_dict)\n",
        "        # We are converting the data to embeddings in the next step\n",
        "        _ , x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask,model)\n",
        "        reps = model.transformer(x_categ_enc, x_cont_enc)\n",
        "        # select only the representations corresponding to y and apply mlp on it in the next step to get the predictions.\n",
        "        y_reps = reps[:,0,:]\n",
        "\n",
        "        y_outs = model.mlpfory(y_reps)\n",
        "        if opt.task == 'regression':\n",
        "            loss = criterion(y_outs,y_gts)\n",
        "        else:\n",
        "            loss = criterion(y_outs,y_gts.squeeze())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    print(running_loss)\n",
        "    if epoch%5==0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                if opt.task in ['binary','multiclass']:\n",
        "                    accuracy, auroc = classification_scores(model, validloader, device, opt.task)\n",
        "                    test_accuracy, test_auroc = classification_scores(model, testloader, device, opt.task)\n",
        "\n",
        "                    print('[EPOCH %d] VALID ACCURACY: %.3f' %\n",
        "                        (epoch + 1, accuracy ))\n",
        "                    print('[EPOCH %d] TEST ACCURACY: %.3f' %\n",
        "                        (epoch + 1, test_accuracy ))\n",
        "\n",
        "                    if opt.task =='multiclass':\n",
        "                        if accuracy > best_valid_accuracy:\n",
        "                            best_valid_accuracy = accuracy\n",
        "                            best_test_auroc = test_auroc\n",
        "                            best_test_accuracy = test_accuracy\n",
        "                            torch.save(model.state_dict(),'%s/bestmodel.pth' % (modelsave_path))\n",
        "                    else:\n",
        "                        if auroc > best_valid_auroc:\n",
        "                            best_valid_auroc = auroc\n",
        "                            best_test_auroc = test_auroc\n",
        "                            best_test_accuracy = test_accuracy\n",
        "                            torch.save(model.state_dict(),'%s/bestmodel.pth' % (modelsave_path))\n",
        "\n",
        "                else:\n",
        "                    valid_rmse = mean_sq_error(model, validloader, device)\n",
        "                    test_rmse = mean_sq_error(model, testloader, device)\n",
        "                    print('[EPOCH %d] VALID RMSE: %.3f' %\n",
        "                        (epoch + 1, valid_rmse ))\n",
        "                    print('[EPOCH %d] TEST RMSE: %.3f' %\n",
        "                        (epoch + 1, test_rmse ))\n",
        "                    if valid_rmse < best_valid_rmse:\n",
        "                        best_valid_rmse = valid_rmse\n",
        "                        best_test_rmse = test_rmse\n",
        "                        torch.save(model.state_dict(),'%s/bestmodel.pth' % (modelsave_path))\n",
        "            model.train()\n",
        "\n",
        "\n",
        "\n",
        "total_parameters = count_parameters(model)\n",
        "print('TOTAL NUMBER OF PARAMS: %d' %(total_parameters))\n",
        "print('Accuracy on best model:  %.3f' %(best_test_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1TMhY58W9--"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd7l1wK-bjL7"
      },
      "source": [
        "### without pre train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "3AgUEyhee6Ew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af512615-36e7-4dd8-b89a-50146b699119"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SAINT(\n",
              "  (norm): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
              "  (simple_MLP): ModuleList(\n",
              "    (0-7): 8 x simple_MLP(\n",
              "      (layers): Sequential(\n",
              "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (transformer): RowColTransformer(\n",
              "    (embeds): Embedding(810, 32)\n",
              "    (layers): ModuleList(\n",
              "      (0): ModuleList(\n",
              "        (0): PreNorm(\n",
              "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): Residual(\n",
              "            (fn): Attention(\n",
              "              (to_qkv): Linear(in_features=32, out_features=384, bias=False)\n",
              "              (to_out): Linear(in_features=128, out_features=32, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): PreNorm(\n",
              "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): Residual(\n",
              "            (fn): FeedForward(\n",
              "              (net): Sequential(\n",
              "                (0): Linear(in_features=32, out_features=256, bias=True)\n",
              "                (1): GEGLU()\n",
              "                (2): Dropout(p=0.1, inplace=False)\n",
              "                (3): Linear(in_features=128, out_features=32, bias=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): PreNorm(\n",
              "          (norm): LayerNorm((2528,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): Residual(\n",
              "            (fn): Attention(\n",
              "              (to_qkv): Linear(in_features=2528, out_features=1536, bias=False)\n",
              "              (to_out): Linear(in_features=512, out_features=2528, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (3): PreNorm(\n",
              "          (norm): LayerNorm((2528,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): Residual(\n",
              "            (fn): FeedForward(\n",
              "              (net): Sequential(\n",
              "                (0): Linear(in_features=2528, out_features=20224, bias=True)\n",
              "                (1): GEGLU()\n",
              "                (2): Dropout(p=0.1, inplace=False)\n",
              "                (3): Linear(in_features=10112, out_features=2528, bias=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (mask_embed): Embedding(79, 32)\n",
              "  )\n",
              "  (mlp): MLP(\n",
              "    (mlp): Sequential(\n",
              "      (0): Linear(in_features=2528, out_features=1264, bias=True)\n",
              "      (1): Linear(in_features=1264, out_features=632, bias=True)\n",
              "      (2): Linear(in_features=632, out_features=1, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (embeds): Embedding(810, 32)\n",
              "  (mask_embeds_cat): Embedding(142, 32)\n",
              "  (mask_embeds_cont): Embedding(16, 32)\n",
              "  (single_mask): Embedding(2, 32)\n",
              "  (pos_encodings): Embedding(79, 32)\n",
              "  (mlp1): sep_MLP(\n",
              "    (layers): ModuleList(\n",
              "      (0): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (1): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=9, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (2): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=2, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (3): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=7, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (4): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=9, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (5): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=4, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (6-7): 2 x simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=3, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (8): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=6, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (9): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=9, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (10): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=40, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (11): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=11, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (12-13): 2 x simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=27, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (14-15): 2 x simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=2, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (16): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=4, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (17): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=2, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (18): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=4, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (19): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=27, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (20-21): 2 x simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=2, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (22): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=3, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (23): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=5, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (24): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=3, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (25-26): 2 x simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=2, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (27): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=5, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (28): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=4, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (29-30): 2 x simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=3, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (31): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=115, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (32): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=5, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (33): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=12, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (34): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=3, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (35): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=12, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (36): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=3, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (37): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=40, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (38): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=5, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (39-40): 2 x simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=3, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (41): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=4, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (42): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=2, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (43): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=5, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (44): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=4, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (45-47): 3 x simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=3, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (48): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=6, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (49-50): 2 x simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=4, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (51): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (52): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=3, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (53): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=11, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (54): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=3, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (55): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=2, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (56): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=4, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (57): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=3, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (58): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=5, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (59): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=4, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (60): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=275, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (61-62): 2 x simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=2, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (63): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=4, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (64): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=2, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (65): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=4, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (66-67): 2 x simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=2, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (68): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=4, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (69): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (70): simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=4, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (mlp2): sep_MLP(\n",
              "    (layers): ModuleList(\n",
              "      (0-7): 8 x simple_MLP(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (mlpfory): simple_MLP(\n",
              "    (layers): Sequential(\n",
              "      (0): Linear(in_features=32, out_features=1000, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=1000, out_features=4, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (pt_mlp): simple_MLP(\n",
              "    (layers): Sequential(\n",
              "      (0): Linear(in_features=2528, out_features=3033, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=3033, out_features=1264, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (pt_mlp2): simple_MLP(\n",
              "    (layers): Sequential(\n",
              "      (0): Linear(in_features=2528, out_features=3033, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=3033, out_features=1264, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "model = SAINT(\n",
        "categories = tuple(cat_dims),\n",
        "num_continuous = len(con_idxs),\n",
        "dim = 32,              # embedding dimension\n",
        "dim_out = 1,\n",
        "depth = 1,             # depth of the network (nr. of transformer blocks)\n",
        "heads = 8,             # number of attention heads\n",
        "attn_dropout = 0.1,\n",
        "ff_dropout = 0.1,\n",
        "mlp_hidden_mults = (4, 2),\n",
        "cont_embeddings = 'MLP', # options: 'MLP', 'linear', 'hybrid' (MLP with continuous embeddings concatenated to the transformer block outputs)\n",
        "attentiontype = 'colrow', # options: 'col', 'row', 'colrow', 'colrowv2'\n",
        "final_mlp_style = 'sep',\n",
        "y_dim = y_dim\n",
        ")\n",
        "model.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.AdamW(model.parameters(),lr=0.001, betas=(0.9,0.999))"
      ],
      "metadata": {
        "id": "8JDkl8HhTKjD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start K-Fold\n",
        "from sklearn.model_selection import KFold\n",
        "# Define the number of splits\n",
        "n_splits = 4\n",
        "best_valid_auroc = 0\n",
        "best_valid_accuracy = 0\n",
        "best_test_auroc = 0\n",
        "best_test_accuracy = 0\n",
        "best_valid_rmse = 100000\n",
        "# Define the KFold object\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store the train and validation indices for each fold\n",
        "train_indices_list = []\n",
        "valid_indices_list = []\n",
        "\n",
        "# Loop over the splits and get the train and validation indices for each fold\n",
        "for train_indices, valid_indices in kf.split(X_train['data']):\n",
        "    train_indices_list.append(train_indices)\n",
        "    valid_indices_list.append(valid_indices)\n",
        "best_valid_accuracy_list = []\n",
        "# Loop over the folds and train the model on each fold\n",
        "for fold in range(n_splits):\n",
        "    # Get the train and validation indices for this fold\n",
        "    train_indices = train_indices_list[fold]\n",
        "    valid_indices = valid_indices_list[fold]\n",
        "\n",
        "    # Create the train and validation datasets and dataloaders for this fold\n",
        "    train_ds = DataSetCatCon(X_train, y_train, cat_idxs,opt.dtask,continuous_mean_std)\n",
        "    trainloader = DataLoader(train_ds, batch_size=train_bsize,num_workers=2, sampler=torch.utils.data.SubsetRandomSampler(train_indices))\n",
        "    valid_ds = DataSetCatCon(X_train, y_train, cat_idxs,opt.dtask,continuous_mean_std)\n",
        "    validloader = DataLoader(valid_ds, batch_size=train_bsize, shuffle=False,num_workers=2, sampler=torch.utils.data.SubsetRandomSampler(valid_indices))\n",
        "    print(f'Training begins now for # {fold} Fold.')\n",
        "    # Train the model on this fold\n",
        "    for epoch in range(300):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            optimizer.zero_grad()\n",
        "            # x_categ is the the categorical data, with y appended as last feature. x_cont has continuous data. cat_mask is an array of ones same shape as x_categ except for last column(corresponding to y's) set to 0s. con_mask is an array of ones same shape as x_cont.\n",
        "            x_categ, x_cont, y_gts, cat_mask, con_mask = data[0].to(device), data[1].to(device),data[2].to(device),data[3].to(device),data[4].to(device)\n",
        "            if opt.train_noise_type is not None and opt.train_noise_level>0:\n",
        "                noise_dict = {\n",
        "                    'noise_type' : opt.train_noise_type,\n",
        "                    'lambda' : opt.train_noise_level\n",
        "                }\n",
        "                if opt.train_noise_type == 'cutmix':\n",
        "                    x_categ, x_cont = add_noise(x_categ,x_cont, noise_params = noise_dict)\n",
        "                elif opt.train_noise_type == 'missing':\n",
        "                    cat_mask, con_mask = add_noise(cat_mask, con_mask, noise_params = noise_dict)\n",
        "            # We are converting the data to embeddings in the next step\n",
        "            _ , x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask,model)\n",
        "            reps = model.transformer(x_categ_enc, x_cont_enc)\n",
        "            # select only the representations corresponding to y and apply mlp on it in the next step to get the predictions.\n",
        "            y_reps = reps[:,0,:]\n",
        "\n",
        "            y_outs = model.mlpfory(y_reps)\n",
        "            if opt.task == 'regression':\n",
        "                loss = criterion(y_outs,y_gts)\n",
        "            else:\n",
        "                loss = criterion(y_outs,y_gts.squeeze())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "        print(running_loss)\n",
        "        if epoch%5==0:\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    if opt.task in ['binary','multiclass']:\n",
        "                        accuracy, auroc = classification_scores(model, validloader, device, opt.task)\n",
        "                        test_accuracy, test_auroc = classification_scores(model, testloader, device, opt.task)\n",
        "\n",
        "                        print('[EPOCH %d] VALID ACCURACY: %.3f' %\n",
        "                            (epoch + 1, accuracy ))\n",
        "                        print('[EPOCH %d] TEST ACCURACY: %.3f' %\n",
        "                            (epoch + 1, test_accuracy ))\n",
        "\n",
        "                        if opt.task =='multiclass':\n",
        "                            if accuracy > best_valid_accuracy:\n",
        "                                best_valid_accuracy = accuracy\n",
        "    best_valid_accuracy_list.append(best_valid_accuracy)\n",
        "\n",
        "# End K Fold\n",
        "# Calculate the average of the best accuracy from each fold\n",
        "average_best_valid_accuracy = sum(best_valid_accuracy_list) / len(best_valid_accuracy_list)\n",
        "print('Average best validation accuracy from all folds:', average_best_valid_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrHfzSO0Sxk9",
        "outputId": "8565cd23-cb8f-4679-afbe-82bb0d63644e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training begins now for # 0 Fold.\n",
            "4.200716495513916\n",
            "[EPOCH 1] VALID ACCURACY: 57.143\n",
            "[EPOCH 1] TEST ACCURACY: 60.000\n",
            "4.394710600376129\n",
            "4.46909898519516\n",
            "4.429906845092773\n",
            "4.502045392990112\n",
            "4.31474095582962\n",
            "[EPOCH 6] VALID ACCURACY: 57.143\n",
            "[EPOCH 6] TEST ACCURACY: 60.000\n",
            "4.230892896652222\n",
            "4.278737902641296\n",
            "4.332816898822784\n",
            "4.307204961776733\n",
            "4.239581823348999\n",
            "[EPOCH 11] VALID ACCURACY: 57.143\n",
            "[EPOCH 11] TEST ACCURACY: 60.000\n",
            "4.34951239824295\n",
            "4.191678106784821\n",
            "4.317393004894257\n",
            "4.228273808956146\n",
            "4.2482582330703735\n",
            "[EPOCH 16] VALID ACCURACY: 57.143\n",
            "[EPOCH 16] TEST ACCURACY: 60.000\n",
            "4.397659778594971\n",
            "4.320188224315643\n",
            "4.4421204924583435\n",
            "4.1679182052612305\n",
            "4.103082239627838\n",
            "[EPOCH 21] VALID ACCURACY: 57.143\n",
            "[EPOCH 21] TEST ACCURACY: 60.000\n",
            "4.468958020210266\n",
            "4.286872982978821\n",
            "4.155896186828613\n",
            "4.319118082523346\n",
            "4.159042716026306\n",
            "[EPOCH 26] VALID ACCURACY: 57.143\n",
            "[EPOCH 26] TEST ACCURACY: 60.000\n",
            "4.553861320018768\n",
            "4.194734692573547\n",
            "4.7972487807273865\n",
            "4.379489839076996\n",
            "4.449049234390259\n",
            "[EPOCH 31] VALID ACCURACY: 57.143\n",
            "[EPOCH 31] TEST ACCURACY: 60.000\n",
            "4.424515962600708\n",
            "4.412181794643402\n",
            "4.393233954906464\n",
            "4.944328665733337\n",
            "4.753786683082581\n",
            "[EPOCH 36] VALID ACCURACY: 57.143\n",
            "[EPOCH 36] TEST ACCURACY: 60.000\n",
            "4.477298319339752\n",
            "4.519630968570709\n",
            "4.623380959033966\n",
            "4.354631781578064\n",
            "4.43649834394455\n",
            "[EPOCH 41] VALID ACCURACY: 57.143\n",
            "[EPOCH 41] TEST ACCURACY: 60.000\n",
            "4.258005857467651\n",
            "4.336826324462891\n",
            "4.08751505613327\n",
            "4.114793181419373\n",
            "3.9624547958374023\n",
            "[EPOCH 46] VALID ACCURACY: 57.143\n",
            "[EPOCH 46] TEST ACCURACY: 60.000\n",
            "4.104828178882599\n",
            "3.9670755863189697\n",
            "4.1264166831970215\n",
            "4.120654881000519\n",
            "3.8212554454803467\n",
            "[EPOCH 51] VALID ACCURACY: 57.143\n",
            "[EPOCH 51] TEST ACCURACY: 60.000\n",
            "3.965282678604126\n",
            "4.540640592575073\n",
            "3.8972851634025574\n",
            "4.022648394107819\n",
            "3.526512086391449\n",
            "[EPOCH 56] VALID ACCURACY: 61.224\n",
            "[EPOCH 56] TEST ACCURACY: 60.000\n",
            "3.8294010758399963\n",
            "3.8972309827804565\n",
            "3.587629020214081\n",
            "3.4486082792282104\n",
            "3.538320630788803\n",
            "[EPOCH 61] VALID ACCURACY: 69.388\n",
            "[EPOCH 61] TEST ACCURACY: 83.333\n",
            "3.198874592781067\n",
            "2.8001199066638947\n",
            "2.3317855522036552\n",
            "2.8146901428699493\n",
            "2.131894528865814\n",
            "[EPOCH 66] VALID ACCURACY: 81.633\n",
            "[EPOCH 66] TEST ACCURACY: 85.000\n",
            "1.9607976377010345\n",
            "1.9379740804433823\n",
            "1.871255099773407\n",
            "2.0528257489204407\n",
            "2.0490387082099915\n",
            "[EPOCH 71] VALID ACCURACY: 83.673\n",
            "[EPOCH 71] TEST ACCURACY: 85.000\n",
            "1.6794291883707047\n",
            "1.9171403348445892\n",
            "1.886787161231041\n",
            "1.710079237818718\n",
            "1.8317023068666458\n",
            "[EPOCH 76] VALID ACCURACY: 83.673\n",
            "[EPOCH 76] TEST ACCURACY: 85.000\n",
            "1.5396840870380402\n",
            "1.4075216948986053\n",
            "1.346888929605484\n",
            "1.310064822435379\n",
            "1.6057700514793396\n",
            "[EPOCH 81] VALID ACCURACY: 85.714\n",
            "[EPOCH 81] TEST ACCURACY: 90.000\n",
            "1.3699655160307884\n",
            "1.0901915654540062\n",
            "0.9630950316786766\n",
            "1.0874430313706398\n",
            "1.2108827233314514\n",
            "[EPOCH 86] VALID ACCURACY: 89.796\n",
            "[EPOCH 86] TEST ACCURACY: 85.000\n",
            "1.422964945435524\n",
            "0.8956182841211557\n",
            "1.5302097648382187\n",
            "1.7383470088243484\n",
            "0.9711421132087708\n",
            "[EPOCH 91] VALID ACCURACY: 89.796\n",
            "[EPOCH 91] TEST ACCURACY: 85.000\n",
            "1.9416438415646553\n",
            "1.4722185581922531\n",
            "1.0464989021420479\n",
            "1.0820998772978783\n",
            "1.2102153897285461\n",
            "[EPOCH 96] VALID ACCURACY: 89.796\n",
            "[EPOCH 96] TEST ACCURACY: 88.333\n",
            "1.0425665671937168\n",
            "1.750072375871241\n",
            "1.2258079871535301\n",
            "1.1537077594548464\n",
            "1.033478394150734\n",
            "[EPOCH 101] VALID ACCURACY: 81.633\n",
            "[EPOCH 101] TEST ACCURACY: 86.667\n",
            "1.0260654762387276\n",
            "1.2290362939238548\n",
            "1.1500730626285076\n",
            "1.2503679692745209\n",
            "1.0686095654964447\n",
            "[EPOCH 106] VALID ACCURACY: 89.796\n",
            "[EPOCH 106] TEST ACCURACY: 86.667\n",
            "0.8869637176394463\n",
            "1.010163702070713\n",
            "0.8571099899709225\n",
            "1.0046098157763481\n",
            "0.9025688618421555\n",
            "[EPOCH 111] VALID ACCURACY: 91.837\n",
            "[EPOCH 111] TEST ACCURACY: 90.000\n",
            "1.009161101654172\n",
            "0.851165484637022\n",
            "0.9240429252386093\n",
            "0.8510250821709633\n",
            "0.9943494200706482\n",
            "[EPOCH 116] VALID ACCURACY: 89.796\n",
            "[EPOCH 116] TEST ACCURACY: 88.333\n",
            "0.9908314719796181\n",
            "1.1721086706966162\n",
            "0.9295251742005348\n",
            "1.335874356329441\n",
            "1.0657560974359512\n",
            "[EPOCH 121] VALID ACCURACY: 89.796\n",
            "[EPOCH 121] TEST ACCURACY: 85.000\n",
            "1.3598192315548658\n",
            "1.0898514688014984\n",
            "0.9877924583852291\n",
            "1.3177233263850212\n",
            "1.0490402430295944\n",
            "[EPOCH 126] VALID ACCURACY: 91.837\n",
            "[EPOCH 126] TEST ACCURACY: 90.000\n",
            "0.8265956565737724\n",
            "1.0366650372743607\n",
            "1.3223182708024979\n",
            "1.508897554129362\n",
            "0.9692974016070366\n",
            "[EPOCH 131] VALID ACCURACY: 91.837\n",
            "[EPOCH 131] TEST ACCURACY: 90.000\n",
            "1.1958134472370148\n",
            "1.1249860189855099\n",
            "0.8536901250481606\n",
            "0.8678903914988041\n",
            "0.785011775791645\n",
            "[EPOCH 136] VALID ACCURACY: 89.796\n",
            "[EPOCH 136] TEST ACCURACY: 90.000\n",
            "0.8392572700977325\n",
            "0.8153515234589577\n",
            "0.9136842675507069\n",
            "1.010634832084179\n",
            "0.8673455342650414\n",
            "[EPOCH 141] VALID ACCURACY: 91.837\n",
            "[EPOCH 141] TEST ACCURACY: 88.333\n",
            "0.9097237065434456\n",
            "0.8715491779148579\n",
            "0.8555605076253414\n",
            "0.8282504305243492\n",
            "0.8492204174399376\n",
            "[EPOCH 146] VALID ACCURACY: 91.837\n",
            "[EPOCH 146] TEST ACCURACY: 90.000\n",
            "1.0850449427962303\n",
            "0.9803620800375938\n",
            "1.0171617418527603\n",
            "0.9180441722273827\n",
            "0.8503828719258308\n",
            "[EPOCH 151] VALID ACCURACY: 91.837\n",
            "[EPOCH 151] TEST ACCURACY: 90.000\n",
            "0.9040653333067894\n",
            "0.7613974921405315\n",
            "0.8139127343893051\n",
            "0.7741939872503281\n",
            "0.7806624993681908\n",
            "[EPOCH 156] VALID ACCURACY: 87.755\n",
            "[EPOCH 156] TEST ACCURACY: 93.333\n",
            "0.9060036204755306\n",
            "0.8526526391506195\n",
            "0.991843968629837\n",
            "0.8613996803760529\n",
            "0.7926031742244959\n",
            "[EPOCH 161] VALID ACCURACY: 91.837\n",
            "[EPOCH 161] TEST ACCURACY: 88.333\n",
            "0.8152921944856644\n",
            "0.8287766128778458\n",
            "0.9788997117429972\n",
            "0.970847837626934\n",
            "0.8806152194738388\n",
            "[EPOCH 166] VALID ACCURACY: 89.796\n",
            "[EPOCH 166] TEST ACCURACY: 90.000\n",
            "0.8894293904304504\n",
            "0.8595233075320721\n",
            "1.0299866870045662\n",
            "0.8345514945685863\n",
            "0.8520980104804039\n",
            "[EPOCH 171] VALID ACCURACY: 91.837\n",
            "[EPOCH 171] TEST ACCURACY: 88.333\n",
            "0.8105383981019258\n",
            "1.0542775429785252\n",
            "0.8627588599920273\n",
            "0.8070613406598568\n",
            "0.8111250810325146\n",
            "[EPOCH 176] VALID ACCURACY: 91.837\n",
            "[EPOCH 176] TEST ACCURACY: 90.000\n",
            "0.8613653630018234\n",
            "0.8905254825949669\n",
            "0.845132939517498\n",
            "0.8536745756864548\n",
            "0.8067823648452759\n",
            "[EPOCH 181] VALID ACCURACY: 89.796\n",
            "[EPOCH 181] TEST ACCURACY: 93.333\n",
            "0.8848483115434647\n",
            "0.7586344555020332\n",
            "0.939864244312048\n",
            "0.862344391644001\n",
            "0.7280163131654263\n",
            "[EPOCH 186] VALID ACCURACY: 89.796\n",
            "[EPOCH 186] TEST ACCURACY: 93.333\n",
            "0.7761487103998661\n",
            "0.8177064619958401\n",
            "0.7120026014745235\n",
            "0.8646127544343472\n",
            "0.8195563554763794\n",
            "[EPOCH 191] VALID ACCURACY: 89.796\n",
            "[EPOCH 191] TEST ACCURACY: 90.000\n",
            "0.7783075496554375\n",
            "0.8087579347193241\n",
            "0.7322746217250824\n",
            "0.8190741688013077\n",
            "0.9793762788176537\n",
            "[EPOCH 196] VALID ACCURACY: 89.796\n",
            "[EPOCH 196] TEST ACCURACY: 90.000\n",
            "0.7449880987405777\n",
            "0.7825383320450783\n",
            "0.7506878301501274\n",
            "0.8189195580780506\n",
            "0.7978427559137344\n",
            "[EPOCH 201] VALID ACCURACY: 85.714\n",
            "[EPOCH 201] TEST ACCURACY: 93.333\n",
            "0.815239205956459\n",
            "0.8883535787463188\n",
            "0.8043684177100658\n",
            "0.8341079857200384\n",
            "0.9679240845143795\n",
            "[EPOCH 206] VALID ACCURACY: 89.796\n",
            "[EPOCH 206] TEST ACCURACY: 90.000\n",
            "0.9770436659455299\n",
            "0.7882211655378342\n",
            "1.1638229563832283\n",
            "1.2035222500562668\n",
            "0.9859246388077736\n",
            "[EPOCH 211] VALID ACCURACY: 91.837\n",
            "[EPOCH 211] TEST ACCURACY: 90.000\n",
            "0.9065188392996788\n",
            "1.121042400598526\n",
            "14.711120698601007\n",
            "1.5361074209213257\n",
            "1.3291023820638657\n",
            "[EPOCH 216] VALID ACCURACY: 59.184\n",
            "[EPOCH 216] TEST ACCURACY: 61.667\n",
            "14.12334007024765\n",
            "20.486143231391907\n",
            "58.06013277173042\n",
            "47.91125297546387\n",
            "98.67197036743164\n",
            "[EPOCH 221] VALID ACCURACY: 24.490\n",
            "[EPOCH 221] TEST ACCURACY: 26.667\n",
            "55.44973421096802\n",
            "34.095732390880585\n",
            "60.79244396276772\n",
            "43.78402483463287\n",
            "20.75720977783203\n",
            "[EPOCH 226] VALID ACCURACY: 81.633\n",
            "[EPOCH 226] TEST ACCURACY: 85.000\n",
            "26.003122806549072\n",
            "27.641419112682343\n",
            "16.313476502895355\n",
            "2.6347978934645653\n",
            "10.427046835422516\n",
            "[EPOCH 231] VALID ACCURACY: 81.633\n",
            "[EPOCH 231] TEST ACCURACY: 86.667\n",
            "6.291502416133881\n",
            "2.440402939915657\n",
            "3.013135641813278\n",
            "2.613691061735153\n",
            "1.9817795306444168\n",
            "[EPOCH 236] VALID ACCURACY: 89.796\n",
            "[EPOCH 236] TEST ACCURACY: 85.000\n",
            "1.5709692686796188\n",
            "1.4373823627829552\n",
            "1.5425450429320335\n",
            "1.300096571445465\n",
            "0.897524930536747\n",
            "[EPOCH 241] VALID ACCURACY: 89.796\n",
            "[EPOCH 241] TEST ACCURACY: 88.333\n",
            "1.1343326047062874\n",
            "1.2378127574920654\n",
            "1.4050831841304898\n",
            "1.1607073992490768\n",
            "1.3047418668866158\n",
            "[EPOCH 246] VALID ACCURACY: 89.796\n",
            "[EPOCH 246] TEST ACCURACY: 85.000\n",
            "1.3392834216356277\n",
            "0.9769867807626724\n",
            "0.9299441128969193\n",
            "1.2183020487427711\n",
            "0.9083563461899757\n",
            "[EPOCH 251] VALID ACCURACY: 91.837\n",
            "[EPOCH 251] TEST ACCURACY: 88.333\n",
            "0.9639440849423409\n",
            "0.773832980543375\n",
            "0.9725470282137394\n",
            "0.9870283007621765\n",
            "0.922108992934227\n",
            "[EPOCH 256] VALID ACCURACY: 89.796\n",
            "[EPOCH 256] TEST ACCURACY: 88.333\n",
            "0.7358570620417595\n",
            "1.0062444359064102\n",
            "0.8183100000023842\n",
            "0.8899597674608231\n",
            "1.0353156626224518\n",
            "[EPOCH 261] VALID ACCURACY: 91.837\n",
            "[EPOCH 261] TEST ACCURACY: 88.333\n",
            "0.9682606235146523\n",
            "0.9403752163052559\n",
            "1.0961789526045322\n",
            "0.8651176542043686\n",
            "1.11800616979599\n",
            "[EPOCH 266] VALID ACCURACY: 89.796\n",
            "[EPOCH 266] TEST ACCURACY: 88.333\n",
            "0.8324926421046257\n",
            "0.953991249203682\n",
            "0.8816227540373802\n",
            "0.8961566798388958\n",
            "1.5209371149539948\n",
            "[EPOCH 271] VALID ACCURACY: 87.755\n",
            "[EPOCH 271] TEST ACCURACY: 88.333\n",
            "1.2065871506929398\n",
            "0.8974699210375547\n",
            "1.0777507983148098\n",
            "1.175693079829216\n",
            "0.9365781173110008\n",
            "[EPOCH 276] VALID ACCURACY: 89.796\n",
            "[EPOCH 276] TEST ACCURACY: 86.667\n",
            "1.0146388672292233\n",
            "0.8114587645977736\n",
            "0.8650506753474474\n",
            "0.925539169460535\n",
            "1.2429268509149551\n",
            "[EPOCH 281] VALID ACCURACY: 89.796\n",
            "[EPOCH 281] TEST ACCURACY: 86.667\n",
            "1.0749510526657104\n",
            "1.1846485882997513\n",
            "0.9935304000973701\n",
            "1.0102617964148521\n",
            "0.9972374327480793\n",
            "[EPOCH 286] VALID ACCURACY: 89.796\n",
            "[EPOCH 286] TEST ACCURACY: 88.333\n",
            "0.872744582593441\n",
            "0.8415820971131325\n",
            "0.8356149978935719\n",
            "1.0056918002665043\n",
            "1.0081686917692423\n",
            "[EPOCH 291] VALID ACCURACY: 89.796\n",
            "[EPOCH 291] TEST ACCURACY: 90.000\n",
            "0.8973035514354706\n",
            "0.8430049642920494\n",
            "1.0620386060327291\n",
            "0.82859006524086\n",
            "0.8924675658345222\n",
            "[EPOCH 296] VALID ACCURACY: 89.796\n",
            "[EPOCH 296] TEST ACCURACY: 88.333\n",
            "0.9294158592820168\n",
            "0.9730761796236038\n",
            "0.975237749516964\n",
            "0.7865763530135155\n",
            "Training begins now for # 1 Fold.\n",
            "0.9517187923192978\n",
            "[EPOCH 1] VALID ACCURACY: 95.833\n",
            "[EPOCH 1] TEST ACCURACY: 88.333\n",
            "1.1362954378128052\n",
            "1.068485677242279\n",
            "1.1271993219852448\n",
            "1.1780334413051605\n",
            "1.0970707684755325\n",
            "[EPOCH 6] VALID ACCURACY: 95.833\n",
            "[EPOCH 6] TEST ACCURACY: 88.333\n",
            "1.4483039565384388\n",
            "1.2266183719038963\n",
            "1.3490086048841476\n",
            "0.9715989865362644\n",
            "1.0550064519047737\n",
            "[EPOCH 11] VALID ACCURACY: 95.833\n",
            "[EPOCH 11] TEST ACCURACY: 88.333\n",
            "1.01451425999403\n",
            "1.364757165312767\n",
            "1.041998103260994\n",
            "0.9601117819547653\n",
            "1.0345487780869007\n",
            "[EPOCH 16] VALID ACCURACY: 95.833\n",
            "[EPOCH 16] TEST ACCURACY: 88.333\n",
            "0.9307281076908112\n",
            "1.1165704280138016\n",
            "1.1386444717645645\n",
            "0.9759748727083206\n",
            "1.351062349975109\n",
            "[EPOCH 21] VALID ACCURACY: 95.833\n",
            "[EPOCH 21] TEST ACCURACY: 88.333\n",
            "1.2658644393086433\n",
            "1.006903424859047\n",
            "0.9378302246332169\n",
            "1.234783347696066\n",
            "1.2448631078004837\n",
            "[EPOCH 26] VALID ACCURACY: 95.833\n",
            "[EPOCH 26] TEST ACCURACY: 91.667\n",
            "1.3885096460580826\n",
            "1.2711666971445084\n",
            "1.1125283986330032\n",
            "1.078544955700636\n",
            "1.0068036168813705\n",
            "[EPOCH 31] VALID ACCURACY: 95.833\n",
            "[EPOCH 31] TEST ACCURACY: 88.333\n",
            "1.0818324238061905\n",
            "1.1712848842144012\n",
            "1.118280652910471\n",
            "1.0160920396447182\n",
            "0.9648297801613808\n",
            "[EPOCH 36] VALID ACCURACY: 95.833\n",
            "[EPOCH 36] TEST ACCURACY: 88.333\n",
            "0.9266621842980385\n",
            "0.850543737411499\n",
            "0.9976516366004944\n",
            "1.3634987249970436\n",
            "1.0814853683114052\n",
            "[EPOCH 41] VALID ACCURACY: 93.750\n",
            "[EPOCH 41] TEST ACCURACY: 88.333\n",
            "0.9706879481673241\n",
            "1.2246504724025726\n",
            "1.0179684478789568\n",
            "1.0871378481388092\n",
            "0.9640378952026367\n",
            "[EPOCH 46] VALID ACCURACY: 95.833\n",
            "[EPOCH 46] TEST ACCURACY: 88.333\n",
            "0.9559289962053299\n",
            "0.9195836186408997\n",
            "1.3652979619801044\n",
            "0.9604219272732735\n",
            "1.273064836859703\n",
            "[EPOCH 51] VALID ACCURACY: 95.833\n",
            "[EPOCH 51] TEST ACCURACY: 88.333\n",
            "1.0580431148409843\n",
            "1.312443695962429\n",
            "0.9755912013351917\n",
            "0.9515907242894173\n",
            "1.0349372774362564\n",
            "[EPOCH 56] VALID ACCURACY: 95.833\n",
            "[EPOCH 56] TEST ACCURACY: 88.333\n",
            "1.2799574062228203\n",
            "1.034671664237976\n",
            "0.8720893589779735\n",
            "0.9909878894686699\n",
            "0.9011443182826042\n",
            "[EPOCH 61] VALID ACCURACY: 95.833\n",
            "[EPOCH 61] TEST ACCURACY: 88.333\n",
            "1.2338336948305368\n",
            "1.210162915289402\n",
            "1.115724802017212\n",
            "0.9795016050338745\n",
            "1.1540623046457767\n",
            "[EPOCH 66] VALID ACCURACY: 95.833\n",
            "[EPOCH 66] TEST ACCURACY: 88.333\n",
            "1.1965321600437164\n",
            "1.015277437865734\n",
            "0.9071781579405069\n",
            "1.0527273751795292\n",
            "1.1149819046258926\n",
            "[EPOCH 71] VALID ACCURACY: 95.833\n",
            "[EPOCH 71] TEST ACCURACY: 88.333\n",
            "1.0901294946670532\n",
            "0.9492264576256275\n",
            "1.027886502444744\n",
            "1.00095434486866\n",
            "1.06840281188488\n",
            "[EPOCH 76] VALID ACCURACY: 95.833\n",
            "[EPOCH 76] TEST ACCURACY: 88.333\n",
            "1.215737745165825\n",
            "0.9963621832430363\n",
            "1.142307087779045\n",
            "1.0179945155978203\n",
            "1.148491844534874\n",
            "[EPOCH 81] VALID ACCURACY: 95.833\n",
            "[EPOCH 81] TEST ACCURACY: 88.333\n",
            "1.1677635684609413\n",
            "1.1526228189468384\n",
            "1.1526245102286339\n",
            "1.143331840634346\n",
            "0.947531171143055\n",
            "[EPOCH 86] VALID ACCURACY: 95.833\n",
            "[EPOCH 86] TEST ACCURACY: 88.333\n",
            "1.0655938386917114\n",
            "1.1197754852473736\n",
            "1.0746794044971466\n",
            "0.9422146715223789\n",
            "1.1955107897520065\n",
            "[EPOCH 91] VALID ACCURACY: 95.833\n",
            "[EPOCH 91] TEST ACCURACY: 88.333\n",
            "1.0056667067110538\n",
            "0.9790770672261715\n",
            "1.1872893199324608\n",
            "0.984081044793129\n",
            "0.9276924394071102\n",
            "[EPOCH 96] VALID ACCURACY: 95.833\n",
            "[EPOCH 96] TEST ACCURACY: 88.333\n",
            "1.0891966372728348\n",
            "0.9910248965024948\n",
            "0.9724418967962265\n",
            "1.042782761156559\n",
            "1.0101431012153625\n",
            "[EPOCH 101] VALID ACCURACY: 95.833\n",
            "[EPOCH 101] TEST ACCURACY: 88.333\n",
            "1.0552247613668442\n",
            "1.0433179289102554\n",
            "1.0727291703224182\n",
            "1.0522528886795044\n",
            "1.0004743076860905\n",
            "[EPOCH 106] VALID ACCURACY: 95.833\n",
            "[EPOCH 106] TEST ACCURACY: 88.333\n",
            "1.1218051053583622\n",
            "1.0625689402222633\n",
            "1.1310273706912994\n",
            "1.0251577273011208\n",
            "1.0135277286171913\n",
            "[EPOCH 111] VALID ACCURACY: 95.833\n",
            "[EPOCH 111] TEST ACCURACY: 88.333\n",
            "0.8898858446627855\n",
            "1.0674113780260086\n",
            "0.8880998939275742\n",
            "0.9350971430540085\n",
            "0.8859206140041351\n",
            "[EPOCH 116] VALID ACCURACY: 95.833\n",
            "[EPOCH 116] TEST ACCURACY: 88.333\n",
            "1.1180580705404282\n",
            "1.0301178991794586\n",
            "1.0330943018198013\n",
            "0.9609409309923649\n",
            "1.834434062242508\n",
            "[EPOCH 121] VALID ACCURACY: 95.833\n",
            "[EPOCH 121] TEST ACCURACY: 88.333\n",
            "1.010564148426056\n",
            "0.9253666363656521\n",
            "1.1324387080967426\n",
            "1.0200628265738487\n",
            "0.9636771939694881\n",
            "[EPOCH 126] VALID ACCURACY: 95.833\n",
            "[EPOCH 126] TEST ACCURACY: 88.333\n",
            "1.2648183107376099\n",
            "1.0709874108433723\n",
            "0.9841915369033813\n",
            "1.047393947839737\n",
            "1.0148781463503838\n",
            "[EPOCH 131] VALID ACCURACY: 95.833\n",
            "[EPOCH 131] TEST ACCURACY: 88.333\n",
            "0.9489677771925926\n",
            "1.0828532576560974\n",
            "1.0960879176855087\n",
            "0.9793382845818996\n",
            "1.0324213728308678\n",
            "[EPOCH 136] VALID ACCURACY: 95.833\n",
            "[EPOCH 136] TEST ACCURACY: 88.333\n",
            "1.0516363866627216\n",
            "1.045474961400032\n",
            "1.0387780368328094\n",
            "0.9617668464779854\n",
            "1.010462261736393\n",
            "[EPOCH 141] VALID ACCURACY: 95.833\n",
            "[EPOCH 141] TEST ACCURACY: 88.333\n",
            "0.9548818320035934\n",
            "0.9901375621557236\n",
            "0.9327099546790123\n",
            "0.8940810710191727\n",
            "0.9065722748637199\n",
            "[EPOCH 146] VALID ACCURACY: 95.833\n",
            "[EPOCH 146] TEST ACCURACY: 88.333\n",
            "0.9205083027482033\n",
            "1.0499660074710846\n",
            "0.853704147040844\n",
            "0.896917887032032\n",
            "0.9016989544034004\n",
            "[EPOCH 151] VALID ACCURACY: 95.833\n",
            "[EPOCH 151] TEST ACCURACY: 88.333\n",
            "1.0886213779449463\n",
            "1.1158853732049465\n",
            "1.0604633688926697\n",
            "1.0348977372050285\n",
            "0.9594572484493256\n",
            "[EPOCH 156] VALID ACCURACY: 95.833\n",
            "[EPOCH 156] TEST ACCURACY: 88.333\n",
            "1.3924982100725174\n",
            "0.999957486987114\n",
            "1.068460002541542\n",
            "0.9438928514719009\n",
            "0.9902313351631165\n",
            "[EPOCH 161] VALID ACCURACY: 95.833\n",
            "[EPOCH 161] TEST ACCURACY: 88.333\n",
            "1.1526452079415321\n",
            "1.0285016596317291\n",
            "1.053583487868309\n",
            "0.9444140456616879\n",
            "0.9837541729211807\n",
            "[EPOCH 166] VALID ACCURACY: 95.833\n",
            "[EPOCH 166] TEST ACCURACY: 88.333\n",
            "1.01814516633749\n",
            "1.1064649373292923\n",
            "0.9487743601202965\n",
            "1.0701586231589317\n",
            "1.1629186198115349\n",
            "[EPOCH 171] VALID ACCURACY: 95.833\n",
            "[EPOCH 171] TEST ACCURACY: 88.333\n",
            "1.3481948897242546\n",
            "1.0691610723733902\n",
            "1.0927957817912102\n",
            "1.0455275177955627\n",
            "1.078869253396988\n",
            "[EPOCH 176] VALID ACCURACY: 95.833\n",
            "[EPOCH 176] TEST ACCURACY: 88.333\n",
            "1.1625724136829376\n",
            "1.0811514258384705\n",
            "1.047408401966095\n",
            "1.0376646295189857\n",
            "0.9873012006282806\n",
            "[EPOCH 181] VALID ACCURACY: 95.833\n",
            "[EPOCH 181] TEST ACCURACY: 88.333\n",
            "1.035226710140705\n",
            "0.9747511260211468\n",
            "1.0554576590657234\n",
            "1.0625172518193722\n",
            "0.9642412588000298\n",
            "[EPOCH 186] VALID ACCURACY: 95.833\n",
            "[EPOCH 186] TEST ACCURACY: 88.333\n",
            "0.9052637107670307\n",
            "0.9483961649239063\n",
            "0.9807388484477997\n",
            "1.1131341382861137\n",
            "1.0361634008586407\n",
            "[EPOCH 191] VALID ACCURACY: 95.833\n",
            "[EPOCH 191] TEST ACCURACY: 88.333\n",
            "0.9958161786198616\n",
            "1.0187830105423927\n",
            "1.0588976815342903\n",
            "0.9362640045583248\n",
            "1.1914207488298416\n",
            "[EPOCH 196] VALID ACCURACY: 95.833\n",
            "[EPOCH 196] TEST ACCURACY: 88.333\n",
            "1.0387596860527992\n",
            "0.9326731972396374\n",
            "1.003942996263504\n",
            "1.04170411080122\n",
            "1.0282926298677921\n",
            "[EPOCH 201] VALID ACCURACY: 95.833\n",
            "[EPOCH 201] TEST ACCURACY: 88.333\n",
            "1.0127042084932327\n",
            "1.099947765469551\n",
            "0.9678785502910614\n",
            "0.9271513894200325\n",
            "1.0039504319429398\n",
            "[EPOCH 206] VALID ACCURACY: 95.833\n",
            "[EPOCH 206] TEST ACCURACY: 88.333\n",
            "0.9371918812394142\n",
            "1.0116874426603317\n",
            "1.230426974594593\n",
            "0.941443145275116\n",
            "0.9352088645100594\n",
            "[EPOCH 211] VALID ACCURACY: 95.833\n",
            "[EPOCH 211] TEST ACCURACY: 86.667\n",
            "0.8563412241637707\n",
            "0.9581926017999649\n",
            "1.0157329365611076\n",
            "1.0468700490891933\n",
            "1.0584871619939804\n",
            "[EPOCH 216] VALID ACCURACY: 95.833\n",
            "[EPOCH 216] TEST ACCURACY: 86.667\n",
            "0.8445669487118721\n",
            "1.1886503547430038\n",
            "0.994260236620903\n",
            "1.0339213497936726\n",
            "0.8469709642231464\n",
            "[EPOCH 221] VALID ACCURACY: 95.833\n",
            "[EPOCH 221] TEST ACCURACY: 86.667\n",
            "1.0199904143810272\n",
            "0.8579250574111938\n",
            "1.1954246684908867\n",
            "1.0219198912382126\n",
            "0.9751164987683296\n",
            "[EPOCH 226] VALID ACCURACY: 95.833\n",
            "[EPOCH 226] TEST ACCURACY: 88.333\n",
            "0.9199740886688232\n",
            "0.9814499989151955\n",
            "0.9675281047821045\n",
            "0.9615993201732635\n",
            "0.9543674141168594\n",
            "[EPOCH 231] VALID ACCURACY: 95.833\n",
            "[EPOCH 231] TEST ACCURACY: 88.333\n",
            "1.077366128563881\n",
            "1.0638371109962463\n",
            "1.0365316420793533\n",
            "1.1439807713031769\n",
            "0.9459264799952507\n",
            "[EPOCH 236] VALID ACCURACY: 95.833\n",
            "[EPOCH 236] TEST ACCURACY: 88.333\n",
            "0.9682385250926018\n",
            "1.2440989762544632\n",
            "0.9058820754289627\n",
            "1.368187054991722\n",
            "0.9224122017621994\n",
            "[EPOCH 241] VALID ACCURACY: 95.833\n",
            "[EPOCH 241] TEST ACCURACY: 86.667\n",
            "1.3001766130328178\n",
            "1.0913529694080353\n",
            "1.5514701195061207\n",
            "0.9273875989019871\n",
            "0.9729700535535812\n",
            "[EPOCH 246] VALID ACCURACY: 97.917\n",
            "[EPOCH 246] TEST ACCURACY: 88.333\n",
            "1.0265510529279709\n",
            "1.5419724099338055\n",
            "1.1721587479114532\n",
            "1.023077704012394\n",
            "1.0473148971796036\n",
            "[EPOCH 251] VALID ACCURACY: 97.917\n",
            "[EPOCH 251] TEST ACCURACY: 86.667\n",
            "1.8292432948946953\n",
            "1.6457069367170334\n",
            "1.7698164135217667\n",
            "1.0940440595149994\n",
            "1.0400189310312271\n",
            "[EPOCH 256] VALID ACCURACY: 91.667\n",
            "[EPOCH 256] TEST ACCURACY: 90.000\n",
            "1.0907387807965279\n",
            "1.1195446625351906\n",
            "1.1575848385691643\n",
            "1.6771610453724861\n",
            "5.627159848809242\n",
            "[EPOCH 261] VALID ACCURACY: 95.833\n",
            "[EPOCH 261] TEST ACCURACY: 93.333\n",
            "1.7444734573364258\n",
            "1.8941990286111832\n",
            "1.161777213215828\n",
            "1.5487831085920334\n",
            "2.6832875572144985\n",
            "[EPOCH 266] VALID ACCURACY: 93.750\n",
            "[EPOCH 266] TEST ACCURACY: 85.000\n",
            "2.5561231076717377\n",
            "2.492889016866684\n",
            "2.1362108141183853\n",
            "2.403457246720791\n",
            "1.8153345882892609\n",
            "[EPOCH 271] VALID ACCURACY: 95.833\n",
            "[EPOCH 271] TEST ACCURACY: 88.333\n",
            "1.2081868723034859\n",
            "1.433163858950138\n",
            "1.2730997204780579\n",
            "1.0592945292592049\n",
            "1.5092705488204956\n",
            "[EPOCH 276] VALID ACCURACY: 93.750\n",
            "[EPOCH 276] TEST ACCURACY: 91.667\n",
            "1.2205050885677338\n",
            "1.1149436458945274\n",
            "1.0701407715678215\n",
            "1.128011792898178\n",
            "1.1337947472929955\n",
            "[EPOCH 281] VALID ACCURACY: 95.833\n",
            "[EPOCH 281] TEST ACCURACY: 91.667\n",
            "1.5813411474227905\n",
            "1.881835050880909\n",
            "1.311163306236267\n",
            "1.1742764487862587\n",
            "1.2749757319688797\n",
            "[EPOCH 286] VALID ACCURACY: 97.917\n",
            "[EPOCH 286] TEST ACCURACY: 86.667\n",
            "1.236211284995079\n",
            "1.165089026093483\n",
            "1.40880386531353\n",
            "1.253932923078537\n",
            "1.242040641605854\n",
            "[EPOCH 291] VALID ACCURACY: 95.833\n",
            "[EPOCH 291] TEST ACCURACY: 86.667\n",
            "1.1877003386616707\n",
            "1.1113983392715454\n",
            "1.2869751304388046\n",
            "1.134511187672615\n",
            "2.3929316997528076\n",
            "[EPOCH 296] VALID ACCURACY: 95.833\n",
            "[EPOCH 296] TEST ACCURACY: 86.667\n",
            "1.8496225029230118\n",
            "1.1794897466897964\n",
            "2.392698794603348\n",
            "1.6008803248405457\n",
            "Training begins now for # 2 Fold.\n",
            "1.2435589581727982\n",
            "[EPOCH 1] VALID ACCURACY: 89.583\n",
            "[EPOCH 1] TEST ACCURACY: 86.667\n",
            "1.1843050867319107\n",
            "1.2408101111650467\n",
            "1.994805559515953\n",
            "0.9646002538502216\n",
            "1.2229308933019638\n",
            "[EPOCH 6] VALID ACCURACY: 89.583\n",
            "[EPOCH 6] TEST ACCURACY: 86.667\n",
            "1.0670675225555897\n",
            "1.0900827571749687\n",
            "1.1712196916341782\n",
            "1.300303403288126\n",
            "1.103378601372242\n",
            "[EPOCH 11] VALID ACCURACY: 89.583\n",
            "[EPOCH 11] TEST ACCURACY: 91.667\n",
            "1.0183085799217224\n",
            "0.8774568513035774\n",
            "1.4001398542895913\n",
            "1.591974351555109\n",
            "1.1138815358281136\n",
            "[EPOCH 16] VALID ACCURACY: 89.583\n",
            "[EPOCH 16] TEST ACCURACY: 91.667\n",
            "0.9331443998962641\n",
            "1.0340141654014587\n",
            "0.9584647491574287\n",
            "1.182487040758133\n",
            "1.086132898926735\n",
            "[EPOCH 21] VALID ACCURACY: 89.583\n",
            "[EPOCH 21] TEST ACCURACY: 86.667\n",
            "0.8924298211932182\n",
            "0.9081988856196404\n",
            "0.9153525978326797\n",
            "1.0754320323467255\n",
            "0.8240221925079823\n",
            "[EPOCH 26] VALID ACCURACY: 89.583\n",
            "[EPOCH 26] TEST ACCURACY: 86.667\n",
            "1.010648787021637\n",
            "0.8207944855093956\n",
            "0.9174060821533203\n",
            "1.0553558580577374\n",
            "0.9133228752762079\n",
            "[EPOCH 31] VALID ACCURACY: 95.833\n",
            "[EPOCH 31] TEST ACCURACY: 90.000\n",
            "1.0530303567647934\n",
            "0.9029965549707413\n",
            "1.0103326737880707\n",
            "1.246471431106329\n",
            "0.9143789038062096\n",
            "[EPOCH 36] VALID ACCURACY: 89.583\n",
            "[EPOCH 36] TEST ACCURACY: 86.667\n",
            "1.0124495103955269\n",
            "1.1601098105311394\n",
            "0.9751966223120689\n",
            "0.9503420665860176\n",
            "0.9093251153826714\n",
            "[EPOCH 41] VALID ACCURACY: 93.750\n",
            "[EPOCH 41] TEST ACCURACY: 90.000\n",
            "1.1491724625229836\n",
            "1.1613349467515945\n",
            "1.1034035682678223\n",
            "0.9490917716175318\n",
            "1.0347912833094597\n",
            "[EPOCH 46] VALID ACCURACY: 91.667\n",
            "[EPOCH 46] TEST ACCURACY: 90.000\n",
            "1.0741937085986137\n",
            "1.087970994412899\n",
            "1.0312155820429325\n",
            "0.982879288494587\n",
            "1.5104674026370049\n",
            "[EPOCH 51] VALID ACCURACY: 91.667\n",
            "[EPOCH 51] TEST ACCURACY: 93.333\n",
            "1.0235605239868164\n",
            "0.8386602811515331\n",
            "0.998731903731823\n",
            "0.9572846405208111\n",
            "1.038874328136444\n",
            "[EPOCH 56] VALID ACCURACY: 89.583\n",
            "[EPOCH 56] TEST ACCURACY: 91.667\n",
            "0.9385439306497574\n",
            "0.953169547021389\n",
            "1.1429811418056488\n",
            "1.2510792165994644\n",
            "0.889741562306881\n",
            "[EPOCH 61] VALID ACCURACY: 87.500\n",
            "[EPOCH 61] TEST ACCURACY: 86.667\n",
            "0.9363366514444351\n",
            "1.0178726818412542\n",
            "1.0679525062441826\n",
            "0.9632756561040878\n",
            "1.4647406376898289\n",
            "[EPOCH 66] VALID ACCURACY: 89.583\n",
            "[EPOCH 66] TEST ACCURACY: 86.667\n",
            "1.5648195818066597\n",
            "1.1635225117206573\n",
            "1.130139671266079\n",
            "1.184082731604576\n",
            "0.9660356864333153\n",
            "[EPOCH 71] VALID ACCURACY: 91.667\n",
            "[EPOCH 71] TEST ACCURACY: 90.000\n",
            "0.9997599199414253\n",
            "0.7127201277762651\n",
            "0.864031407982111\n",
            "0.9556149840354919\n",
            "0.9937368184328079\n",
            "[EPOCH 76] VALID ACCURACY: 89.583\n",
            "[EPOCH 76] TEST ACCURACY: 86.667\n",
            "0.848368763923645\n",
            "0.9784865379333496\n",
            "0.776652880012989\n",
            "0.8911384642124176\n",
            "0.9347925148904324\n",
            "[EPOCH 81] VALID ACCURACY: 89.583\n",
            "[EPOCH 81] TEST ACCURACY: 88.333\n",
            "0.94971863925457\n",
            "0.8225808069109917\n",
            "1.0746245719492435\n",
            "0.8808098882436752\n",
            "0.8980156816542149\n",
            "[EPOCH 86] VALID ACCURACY: 89.583\n",
            "[EPOCH 86] TEST ACCURACY: 88.333\n",
            "0.9408015534281731\n",
            "0.8893287368118763\n",
            "0.8515800349414349\n",
            "0.9171292781829834\n",
            "0.7838190011680126\n",
            "[EPOCH 91] VALID ACCURACY: 89.583\n",
            "[EPOCH 91] TEST ACCURACY: 88.333\n",
            "0.8998192995786667\n",
            "0.8300229050219059\n",
            "0.8947089686989784\n",
            "0.874729186296463\n",
            "0.8510710075497627\n",
            "[EPOCH 96] VALID ACCURACY: 89.583\n",
            "[EPOCH 96] TEST ACCURACY: 86.667\n",
            "0.7999064810574055\n",
            "0.8695185072720051\n",
            "0.7825963497161865\n",
            "0.9111387021839619\n",
            "0.8003383651375771\n",
            "[EPOCH 101] VALID ACCURACY: 91.667\n",
            "[EPOCH 101] TEST ACCURACY: 86.667\n",
            "0.8233349919319153\n",
            "0.8369873911142349\n",
            "0.9004908129572868\n",
            "0.7933813780546188\n",
            "0.7847025543451309\n",
            "[EPOCH 106] VALID ACCURACY: 89.583\n",
            "[EPOCH 106] TEST ACCURACY: 86.667\n",
            "0.8367079477757215\n",
            "0.7102303002029657\n",
            "0.7544006705284119\n",
            "0.7520170509815216\n",
            "0.7877591233700514\n",
            "[EPOCH 111] VALID ACCURACY: 93.750\n",
            "[EPOCH 111] TEST ACCURACY: 90.000\n",
            "0.8398072347044945\n",
            "0.969154879450798\n",
            "0.8161379098892212\n",
            "0.9426317177712917\n",
            "1.265964150428772\n",
            "[EPOCH 116] VALID ACCURACY: 91.667\n",
            "[EPOCH 116] TEST ACCURACY: 90.000\n",
            "0.9105859845876694\n",
            "0.9590095691382885\n",
            "0.8749967589974403\n",
            "0.9134747385978699\n",
            "0.905251681804657\n",
            "[EPOCH 121] VALID ACCURACY: 95.833\n",
            "[EPOCH 121] TEST ACCURACY: 90.000\n",
            "0.7601604387164116\n",
            "0.7331893090158701\n",
            "0.8430831804871559\n",
            "0.8418223634362221\n",
            "0.8226794600486755\n",
            "[EPOCH 126] VALID ACCURACY: 91.667\n",
            "[EPOCH 126] TEST ACCURACY: 90.000\n",
            "0.8182624690234661\n",
            "0.7411847561597824\n",
            "0.8622915521264076\n",
            "0.9343472421169281\n",
            "0.8251214027404785\n",
            "[EPOCH 131] VALID ACCURACY: 89.583\n",
            "[EPOCH 131] TEST ACCURACY: 90.000\n",
            "0.8853833414614201\n",
            "0.7660166993737221\n",
            "0.8821144066751003\n",
            "0.8060716241598129\n",
            "0.7189532592892647\n",
            "[EPOCH 136] VALID ACCURACY: 89.583\n",
            "[EPOCH 136] TEST ACCURACY: 90.000\n",
            "0.7576476782560349\n",
            "0.6951213665306568\n",
            "0.8728553578257561\n",
            "0.8548747450113297\n",
            "0.7370146885514259\n",
            "[EPOCH 141] VALID ACCURACY: 91.667\n",
            "[EPOCH 141] TEST ACCURACY: 90.000\n",
            "0.7507332563400269\n",
            "0.7000276409089565\n",
            "0.7398703992366791\n",
            "0.7771161571145058\n",
            "0.7900243476033211\n",
            "[EPOCH 146] VALID ACCURACY: 89.583\n",
            "[EPOCH 146] TEST ACCURACY: 90.000\n",
            "0.8335695192217827\n",
            "0.8314328826963902\n",
            "1.058959685266018\n",
            "0.880330678075552\n",
            "0.7757666036486626\n",
            "[EPOCH 151] VALID ACCURACY: 89.583\n",
            "[EPOCH 151] TEST ACCURACY: 90.000\n",
            "1.143379632383585\n",
            "1.0770804286003113\n",
            "0.9897356182336807\n",
            "1.0138771794736385\n",
            "0.7844096422195435\n",
            "[EPOCH 156] VALID ACCURACY: 91.667\n",
            "[EPOCH 156] TEST ACCURACY: 90.000\n",
            "0.9614853896200657\n",
            "0.9124940484762192\n",
            "1.0605524694547057\n",
            "1.1325806453824043\n",
            "0.8665880709886551\n",
            "[EPOCH 161] VALID ACCURACY: 95.833\n",
            "[EPOCH 161] TEST ACCURACY: 90.000\n",
            "0.7712545357644558\n",
            "0.7936896979808807\n",
            "0.8054693043231964\n",
            "0.8321148175746202\n",
            "0.8288901671767235\n",
            "[EPOCH 166] VALID ACCURACY: 91.667\n",
            "[EPOCH 166] TEST ACCURACY: 91.667\n",
            "0.8072177916765213\n",
            "0.798042755573988\n",
            "0.7924863994121552\n",
            "0.9076392352581024\n",
            "0.7328562177717686\n",
            "[EPOCH 171] VALID ACCURACY: 93.750\n",
            "[EPOCH 171] TEST ACCURACY: 90.000\n",
            "1.0434189662337303\n",
            "0.8990889564156532\n",
            "0.9262408763170242\n",
            "0.8974786624312401\n",
            "0.7795994803309441\n",
            "[EPOCH 176] VALID ACCURACY: 93.750\n",
            "[EPOCH 176] TEST ACCURACY: 90.000\n",
            "0.7220683060586452\n",
            "0.7062594518065453\n",
            "0.6884922757744789\n",
            "0.7441440187394619\n",
            "0.8664597533643246\n",
            "[EPOCH 181] VALID ACCURACY: 91.667\n",
            "[EPOCH 181] TEST ACCURACY: 90.000\n",
            "0.6736138127744198\n",
            "0.7577731609344482\n",
            "0.7414126321673393\n",
            "0.6690281480550766\n",
            "0.8383975848555565\n",
            "[EPOCH 186] VALID ACCURACY: 91.667\n",
            "[EPOCH 186] TEST ACCURACY: 90.000\n",
            "0.8541797734797001\n",
            "0.6806606836616993\n",
            "1.0455518625676632\n",
            "0.8730493187904358\n",
            "0.7847715467214584\n",
            "[EPOCH 191] VALID ACCURACY: 91.667\n",
            "[EPOCH 191] TEST ACCURACY: 90.000\n",
            "0.8405201435089111\n",
            "0.7803255915641785\n",
            "0.851536363363266\n",
            "0.8959721699357033\n",
            "0.7523526176810265\n",
            "[EPOCH 196] VALID ACCURACY: 89.583\n",
            "[EPOCH 196] TEST ACCURACY: 90.000\n",
            "0.6971696633845568\n",
            "0.8204441890120506\n",
            "0.7231373637914658\n",
            "0.7235901094973087\n",
            "0.6629713140428066\n",
            "[EPOCH 201] VALID ACCURACY: 91.667\n",
            "[EPOCH 201] TEST ACCURACY: 91.667\n",
            "0.6945051550865173\n",
            "0.7597574666142464\n",
            "0.6724827326834202\n",
            "0.6748826280236244\n",
            "0.6521846987307072\n",
            "[EPOCH 206] VALID ACCURACY: 89.583\n",
            "[EPOCH 206] TEST ACCURACY: 90.000\n",
            "0.7461347579956055\n",
            "0.7060191798955202\n",
            "0.6850716266781092\n",
            "0.6784760318696499\n",
            "1.5992930978536606\n",
            "[EPOCH 211] VALID ACCURACY: 91.667\n",
            "[EPOCH 211] TEST ACCURACY: 90.000\n",
            "0.8308951333165169\n",
            "0.8046642951667309\n",
            "0.8440007902681828\n",
            "0.7215989157557487\n",
            "0.714723901823163\n",
            "[EPOCH 216] VALID ACCURACY: 91.667\n",
            "[EPOCH 216] TEST ACCURACY: 90.000\n",
            "0.7434234619140625\n",
            "0.6990273967385292\n",
            "0.7944480516016483\n",
            "0.7879349123686552\n",
            "0.635350376367569\n",
            "[EPOCH 221] VALID ACCURACY: 91.667\n",
            "[EPOCH 221] TEST ACCURACY: 93.333\n",
            "0.736262172460556\n",
            "0.6781345941126347\n",
            "0.6660550683736801\n",
            "0.9017302691936493\n",
            "0.7385947331786156\n",
            "[EPOCH 226] VALID ACCURACY: 91.667\n",
            "[EPOCH 226] TEST ACCURACY: 93.333\n",
            "0.731297992169857\n",
            "0.851479347795248\n",
            "0.8295871391892433\n",
            "0.7238909229636192\n",
            "0.7811335399746895\n",
            "[EPOCH 231] VALID ACCURACY: 89.583\n",
            "[EPOCH 231] TEST ACCURACY: 90.000\n",
            "0.7111612446606159\n",
            "0.7122213989496231\n",
            "0.6712669134140015\n",
            "0.7967588230967522\n",
            "0.6714506447315216\n",
            "[EPOCH 236] VALID ACCURACY: 91.667\n",
            "[EPOCH 236] TEST ACCURACY: 90.000\n",
            "0.7099466808140278\n",
            "0.7750759944319725\n",
            "0.8183443527668715\n",
            "0.8086431175470352\n",
            "0.7121936231851578\n",
            "[EPOCH 241] VALID ACCURACY: 91.667\n",
            "[EPOCH 241] TEST ACCURACY: 91.667\n",
            "0.5981081109493971\n",
            "0.7480296678841114\n",
            "0.7963515147566795\n",
            "0.7049047239124775\n",
            "0.6015131175518036\n",
            "[EPOCH 246] VALID ACCURACY: 91.667\n",
            "[EPOCH 246] TEST ACCURACY: 90.000\n",
            "0.6389410272240639\n",
            "0.7206616345793009\n",
            "0.719839982688427\n",
            "0.8373691588640213\n",
            "0.637585636228323\n",
            "[EPOCH 251] VALID ACCURACY: 91.667\n",
            "[EPOCH 251] TEST ACCURACY: 90.000\n",
            "0.6882108934223652\n",
            "0.6898949928581715\n",
            "0.7777260076254606\n",
            "0.7523006610572338\n",
            "0.7353010289371014\n",
            "[EPOCH 256] VALID ACCURACY: 89.583\n",
            "[EPOCH 256] TEST ACCURACY: 90.000\n",
            "0.7589676082134247\n",
            "0.696478208526969\n",
            "0.6969866119325161\n",
            "0.8039459064602852\n",
            "0.709424264729023\n",
            "[EPOCH 261] VALID ACCURACY: 91.667\n",
            "[EPOCH 261] TEST ACCURACY: 90.000\n",
            "0.7365970015525818\n",
            "0.7570968493819237\n",
            "0.741775743663311\n",
            "0.6488770768046379\n",
            "0.7277521565556526\n",
            "[EPOCH 266] VALID ACCURACY: 93.750\n",
            "[EPOCH 266] TEST ACCURACY: 90.000\n",
            "0.7359221577644348\n",
            "0.9326088763773441\n",
            "0.9514796957373619\n",
            "1.0240042172372341\n",
            "0.9807092174887657\n",
            "[EPOCH 271] VALID ACCURACY: 89.583\n",
            "[EPOCH 271] TEST ACCURACY: 90.000\n",
            "3.709446668624878\n",
            "28.48195767402649\n",
            "113.44235706329346\n",
            "162.45305156707764\n",
            "351.54031562805176\n",
            "[EPOCH 276] VALID ACCURACY: 62.500\n",
            "[EPOCH 276] TEST ACCURACY: 60.000\n",
            "105.63776350021362\n",
            "96.75516605377197\n",
            "17.720908880233765\n",
            "28.21535813808441\n",
            "33.56596279144287\n",
            "[EPOCH 281] VALID ACCURACY: 62.500\n",
            "[EPOCH 281] TEST ACCURACY: 60.000\n",
            "61.313772678375244\n",
            "10.520742654800415\n",
            "31.78638756275177\n",
            "21.07732355594635\n",
            "6.163472473621368\n",
            "[EPOCH 286] VALID ACCURACY: 77.083\n",
            "[EPOCH 286] TEST ACCURACY: 83.333\n",
            "5.038832724094391\n",
            "10.851508617401123\n",
            "4.109755635261536\n",
            "3.3338339924812317\n",
            "3.1132698357105255\n",
            "[EPOCH 291] VALID ACCURACY: 85.417\n",
            "[EPOCH 291] TEST ACCURACY: 85.000\n",
            "2.7149428725242615\n",
            "2.3891164362430573\n",
            "2.3306992948055267\n",
            "1.9859303832054138\n",
            "2.1236796528100967\n",
            "[EPOCH 296] VALID ACCURACY: 85.417\n",
            "[EPOCH 296] TEST ACCURACY: 85.000\n",
            "2.03498038649559\n",
            "1.8565375208854675\n",
            "2.129349708557129\n",
            "1.8372045904397964\n",
            "Training begins now for # 3 Fold.\n",
            "2.2939480245113373\n",
            "[EPOCH 1] VALID ACCURACY: 89.583\n",
            "[EPOCH 1] TEST ACCURACY: 85.000\n",
            "2.2283133268356323\n",
            "2.4156537652015686\n",
            "2.1407106071710587\n",
            "2.2999802827835083\n",
            "2.1149931848049164\n",
            "[EPOCH 6] VALID ACCURACY: 89.583\n",
            "[EPOCH 6] TEST ACCURACY: 85.000\n",
            "2.328071355819702\n",
            "2.250578761100769\n",
            "2.218702256679535\n",
            "2.2777303755283356\n",
            "2.2341813147068024\n",
            "[EPOCH 11] VALID ACCURACY: 89.583\n",
            "[EPOCH 11] TEST ACCURACY: 85.000\n",
            "2.154026374220848\n",
            "2.1397867500782013\n",
            "2.1856577694416046\n",
            "1.9868620187044144\n",
            "2.1686026453971863\n",
            "[EPOCH 16] VALID ACCURACY: 89.583\n",
            "[EPOCH 16] TEST ACCURACY: 85.000\n",
            "2.106773719191551\n",
            "2.099362552165985\n",
            "2.1196305453777313\n",
            "2.0164923667907715\n",
            "2.244027331471443\n",
            "[EPOCH 21] VALID ACCURACY: 89.583\n",
            "[EPOCH 21] TEST ACCURACY: 85.000\n",
            "2.020293563604355\n",
            "2.1181979179382324\n",
            "2.0362539887428284\n",
            "1.9448001682758331\n",
            "1.7829369753599167\n",
            "[EPOCH 26] VALID ACCURACY: 89.583\n",
            "[EPOCH 26] TEST ACCURACY: 85.000\n",
            "1.8228841125965118\n",
            "1.6124399229884148\n",
            "1.5722418427467346\n",
            "1.5306869000196457\n",
            "1.7234193533658981\n",
            "[EPOCH 31] VALID ACCURACY: 89.583\n",
            "[EPOCH 31] TEST ACCURACY: 93.333\n",
            "1.6222477406263351\n",
            "1.714308962225914\n",
            "3.623825341463089\n",
            "1.8420378789305687\n",
            "2.2146648466587067\n",
            "[EPOCH 36] VALID ACCURACY: 89.583\n",
            "[EPOCH 36] TEST ACCURACY: 85.000\n",
            "1.6843715757131577\n",
            "1.9925170540809631\n",
            "1.7039699405431747\n",
            "1.589739739894867\n",
            "1.6234077215194702\n",
            "[EPOCH 41] VALID ACCURACY: 89.583\n",
            "[EPOCH 41] TEST ACCURACY: 90.000\n",
            "1.4950232356786728\n",
            "1.583077535033226\n",
            "1.382136084139347\n",
            "1.38262140750885\n",
            "1.2567458152770996\n",
            "[EPOCH 46] VALID ACCURACY: 89.583\n",
            "[EPOCH 46] TEST ACCURACY: 86.667\n",
            "1.472244679927826\n",
            "1.442326471209526\n",
            "1.1841317787766457\n",
            "1.3648470342159271\n",
            "1.062748298048973\n",
            "[EPOCH 51] VALID ACCURACY: 89.583\n",
            "[EPOCH 51] TEST ACCURACY: 86.667\n",
            "1.1990512609481812\n",
            "1.1466814056038857\n",
            "1.4276978597044945\n",
            "1.1364863887429237\n",
            "1.199769139289856\n",
            "[EPOCH 56] VALID ACCURACY: 97.917\n",
            "[EPOCH 56] TEST ACCURACY: 86.667\n",
            "1.2792711965739727\n",
            "1.1708956956863403\n",
            "1.1923250332474709\n",
            "1.132914811372757\n",
            "1.087133802473545\n",
            "[EPOCH 61] VALID ACCURACY: 93.750\n",
            "[EPOCH 61] TEST ACCURACY: 86.667\n",
            "1.2397140711545944\n",
            "1.0852736681699753\n",
            "1.286203846335411\n",
            "1.1064398661255836\n",
            "1.420279547572136\n",
            "[EPOCH 66] VALID ACCURACY: 97.917\n",
            "[EPOCH 66] TEST ACCURACY: 91.667\n",
            "1.2789357155561447\n",
            "1.277270182967186\n",
            "1.4618943706154823\n",
            "1.2187825292348862\n",
            "1.3252329230308533\n",
            "[EPOCH 71] VALID ACCURACY: 97.917\n",
            "[EPOCH 71] TEST ACCURACY: 91.667\n",
            "1.1405401229858398\n",
            "1.1860985960811377\n",
            "1.1570943146944046\n",
            "1.0746902376413345\n",
            "0.96189995855093\n",
            "[EPOCH 76] VALID ACCURACY: 95.833\n",
            "[EPOCH 76] TEST ACCURACY: 93.333\n",
            "1.0229762569069862\n",
            "1.033255621790886\n",
            "0.908111160621047\n",
            "1.3198754861950874\n",
            "1.0967553704977036\n",
            "[EPOCH 81] VALID ACCURACY: 97.917\n",
            "[EPOCH 81] TEST ACCURACY: 93.333\n",
            "0.9715293124318123\n",
            "1.2115781903266907\n",
            "0.9066218920052052\n",
            "0.9067370072007179\n",
            "0.9639863818883896\n",
            "[EPOCH 86] VALID ACCURACY: 95.833\n",
            "[EPOCH 86] TEST ACCURACY: 93.333\n",
            "0.9972614049911499\n",
            "0.9695209190249443\n",
            "1.091384395956993\n",
            "1.104663080535829\n",
            "1.611223891377449\n",
            "[EPOCH 91] VALID ACCURACY: 95.833\n",
            "[EPOCH 91] TEST ACCURACY: 91.667\n",
            "1.2552036494016647\n",
            "1.1456687599420547\n",
            "1.4636985510587692\n",
            "1.0834843963384628\n",
            "1.303577482700348\n",
            "[EPOCH 96] VALID ACCURACY: 89.583\n",
            "[EPOCH 96] TEST ACCURACY: 90.000\n",
            "1.487700030207634\n",
            "1.2735828459262848\n",
            "0.9545859694480896\n",
            "1.0369846522808075\n",
            "1.0641335025429726\n",
            "[EPOCH 101] VALID ACCURACY: 97.917\n",
            "[EPOCH 101] TEST ACCURACY: 91.667\n",
            "1.0437287390232086\n",
            "0.9590811431407928\n",
            "1.0043643042445183\n",
            "0.9517937898635864\n",
            "1.0104731135070324\n",
            "[EPOCH 106] VALID ACCURACY: 97.917\n",
            "[EPOCH 106] TEST ACCURACY: 93.333\n",
            "1.1678896434605122\n",
            "2.7113979160785675\n",
            "3.17193004488945\n",
            "2.9249046742916107\n",
            "4.404524207115173\n",
            "[EPOCH 111] VALID ACCURACY: 83.333\n",
            "[EPOCH 111] TEST ACCURACY: 85.000\n",
            "3.812632292509079\n",
            "2.4102848768234253\n",
            "2.607882410287857\n",
            "2.532902956008911\n",
            "2.2242980897426605\n",
            "[EPOCH 116] VALID ACCURACY: 89.583\n",
            "[EPOCH 116] TEST ACCURACY: 85.000\n",
            "2.458331048488617\n",
            "2.261859118938446\n",
            "2.4963276386260986\n",
            "2.1947643160820007\n",
            "2.260075122117996\n",
            "[EPOCH 121] VALID ACCURACY: 89.583\n",
            "[EPOCH 121] TEST ACCURACY: 85.000\n",
            "2.1959323287010193\n",
            "2.243612051010132\n",
            "2.2058239579200745\n",
            "2.2069049179553986\n",
            "2.1224971413612366\n",
            "[EPOCH 126] VALID ACCURACY: 89.583\n",
            "[EPOCH 126] TEST ACCURACY: 85.000\n",
            "2.2245123982429504\n",
            "1.9899802058935165\n",
            "2.347853124141693\n",
            "2.3873060047626495\n",
            "2.259781777858734\n",
            "[EPOCH 131] VALID ACCURACY: 89.583\n",
            "[EPOCH 131] TEST ACCURACY: 85.000\n",
            "2.8064545392990112\n",
            "4.215294063091278\n",
            "2.5240906178951263\n",
            "2.3357691764831543\n",
            "2.3572918325662613\n",
            "[EPOCH 136] VALID ACCURACY: 89.583\n",
            "[EPOCH 136] TEST ACCURACY: 85.000\n",
            "2.249730557203293\n",
            "2.069333106279373\n",
            "2.1367829740047455\n",
            "2.153927966952324\n",
            "2.126560926437378\n",
            "[EPOCH 141] VALID ACCURACY: 89.583\n",
            "[EPOCH 141] TEST ACCURACY: 85.000\n",
            "2.30668281018734\n",
            "2.084009498357773\n",
            "2.137348845601082\n",
            "2.042224884033203\n",
            "2.082244575023651\n",
            "[EPOCH 146] VALID ACCURACY: 89.583\n",
            "[EPOCH 146] TEST ACCURACY: 85.000\n",
            "2.0846977829933167\n",
            "2.2274090945720673\n",
            "2.033141389489174\n",
            "2.0360331535339355\n",
            "2.249929368495941\n",
            "[EPOCH 151] VALID ACCURACY: 89.583\n",
            "[EPOCH 151] TEST ACCURACY: 85.000\n",
            "2.2468787133693695\n",
            "2.1831856966018677\n",
            "2.1265391409397125\n",
            "2.099847584962845\n",
            "2.046599566936493\n",
            "[EPOCH 156] VALID ACCURACY: 89.583\n",
            "[EPOCH 156] TEST ACCURACY: 85.000\n",
            "2.029867500066757\n",
            "2.1116418838500977\n",
            "2.1114839911460876\n",
            "2.47482967376709\n",
            "2.162537604570389\n",
            "[EPOCH 161] VALID ACCURACY: 89.583\n",
            "[EPOCH 161] TEST ACCURACY: 85.000\n",
            "2.0361799597740173\n",
            "2.1464097797870636\n",
            "2.0067135840654373\n",
            "2.0900315046310425\n",
            "2.210250496864319\n",
            "[EPOCH 166] VALID ACCURACY: 89.583\n",
            "[EPOCH 166] TEST ACCURACY: 85.000\n",
            "2.0150070786476135\n",
            "2.024968206882477\n",
            "2.120185375213623\n",
            "1.9817119240760803\n",
            "2.1276915073394775\n",
            "[EPOCH 171] VALID ACCURACY: 89.583\n",
            "[EPOCH 171] TEST ACCURACY: 85.000\n",
            "2.207776814699173\n",
            "2.1091556400060654\n",
            "2.232659786939621\n",
            "1.968570277094841\n",
            "2.035362124443054\n",
            "[EPOCH 176] VALID ACCURACY: 89.583\n",
            "[EPOCH 176] TEST ACCURACY: 85.000\n",
            "2.233363687992096\n",
            "2.2888853549957275\n",
            "2.331198036670685\n",
            "2.1035990118980408\n",
            "2.1439049690961838\n",
            "[EPOCH 181] VALID ACCURACY: 89.583\n",
            "[EPOCH 181] TEST ACCURACY: 85.000\n",
            "2.0354090332984924\n",
            "1.9859284907579422\n",
            "2.194497764110565\n",
            "2.1377202570438385\n",
            "1.9606812000274658\n",
            "[EPOCH 186] VALID ACCURACY: 89.583\n",
            "[EPOCH 186] TEST ACCURACY: 85.000\n",
            "2.0978751480579376\n",
            "2.1244402527809143\n",
            "2.0462919175624847\n",
            "2.1623160243034363\n",
            "2.031178265810013\n",
            "[EPOCH 191] VALID ACCURACY: 89.583\n",
            "[EPOCH 191] TEST ACCURACY: 85.000\n",
            "2.005589574575424\n",
            "1.962871067225933\n",
            "2.03040087223053\n",
            "1.9769429415464401\n",
            "2.005586087703705\n",
            "[EPOCH 196] VALID ACCURACY: 89.583\n",
            "[EPOCH 196] TEST ACCURACY: 85.000\n",
            "2.0574796944856644\n",
            "2.156178116798401\n",
            "2.044663190841675\n",
            "1.9673823565244675\n",
            "2.1859178841114044\n",
            "[EPOCH 201] VALID ACCURACY: 89.583\n",
            "[EPOCH 201] TEST ACCURACY: 85.000\n",
            "2.0616797506809235\n",
            "2.0856645107269287\n",
            "2.1607498228549957\n",
            "1.9925523698329926\n",
            "2.103400230407715\n",
            "[EPOCH 206] VALID ACCURACY: 89.583\n",
            "[EPOCH 206] TEST ACCURACY: 85.000\n",
            "2.025253266096115\n",
            "2.053361713886261\n",
            "2.001942925155163\n",
            "2.104674145579338\n",
            "1.9910654723644257\n",
            "[EPOCH 211] VALID ACCURACY: 89.583\n",
            "[EPOCH 211] TEST ACCURACY: 85.000\n",
            "2.0772474706172943\n",
            "2.0755163580179214\n",
            "2.1281101405620575\n",
            "2.0228238999843597\n",
            "1.9447775781154633\n",
            "[EPOCH 216] VALID ACCURACY: 89.583\n",
            "[EPOCH 216] TEST ACCURACY: 85.000\n",
            "2.0287578999996185\n",
            "2.3286769688129425\n",
            "2.5361935198307037\n",
            "2.4124430418014526\n",
            "2.482616439461708\n",
            "[EPOCH 221] VALID ACCURACY: 89.583\n",
            "[EPOCH 221] TEST ACCURACY: 85.000\n",
            "2.1649429202079773\n",
            "2.3767034709453583\n",
            "2.252067059278488\n",
            "2.423577457666397\n",
            "2.075480967760086\n",
            "[EPOCH 226] VALID ACCURACY: 89.583\n",
            "[EPOCH 226] TEST ACCURACY: 85.000\n",
            "2.2757220566272736\n",
            "2.111027866601944\n",
            "2.0702788829803467\n",
            "2.3617009967565536\n",
            "2.1417528688907623\n",
            "[EPOCH 231] VALID ACCURACY: 89.583\n",
            "[EPOCH 231] TEST ACCURACY: 85.000\n",
            "2.0098858177661896\n",
            "1.9543664455413818\n",
            "1.938596248626709\n",
            "2.1452563405036926\n",
            "1.901567667722702\n",
            "[EPOCH 236] VALID ACCURACY: 89.583\n",
            "[EPOCH 236] TEST ACCURACY: 85.000\n",
            "2.2649934142827988\n",
            "2.15170618891716\n",
            "2.01653590798378\n",
            "1.8052574768662453\n",
            "2.1484613120555878\n",
            "[EPOCH 241] VALID ACCURACY: 89.583\n",
            "[EPOCH 241] TEST ACCURACY: 85.000\n",
            "1.9564865231513977\n",
            "1.8801319897174835\n",
            "1.9259769916534424\n",
            "2.053782969713211\n",
            "2.107219934463501\n",
            "[EPOCH 246] VALID ACCURACY: 89.583\n",
            "[EPOCH 246] TEST ACCURACY: 85.000\n",
            "2.169143706560135\n",
            "2.137921452522278\n",
            "2.0781002044677734\n",
            "2.0361307561397552\n",
            "1.9826160073280334\n",
            "[EPOCH 251] VALID ACCURACY: 89.583\n",
            "[EPOCH 251] TEST ACCURACY: 85.000\n",
            "1.9793845415115356\n",
            "1.8245534598827362\n",
            "2.027380019426346\n",
            "2.1956577748060226\n",
            "2.008030742406845\n",
            "[EPOCH 256] VALID ACCURACY: 89.583\n",
            "[EPOCH 256] TEST ACCURACY: 85.000\n",
            "2.7315840423107147\n",
            "1.9510150700807571\n",
            "2.153839558362961\n",
            "1.8440501391887665\n",
            "2.0786086171865463\n",
            "[EPOCH 261] VALID ACCURACY: 89.583\n",
            "[EPOCH 261] TEST ACCURACY: 85.000\n",
            "1.9807181656360626\n",
            "1.8628278225660324\n",
            "1.7603966146707535\n",
            "1.8883450627326965\n",
            "1.8146188706159592\n",
            "[EPOCH 266] VALID ACCURACY: 89.583\n",
            "[EPOCH 266] TEST ACCURACY: 85.000\n",
            "2.0410289764404297\n",
            "2.3217267394065857\n",
            "1.9864783585071564\n",
            "1.980570837855339\n",
            "2.2859779000282288\n",
            "[EPOCH 271] VALID ACCURACY: 89.583\n",
            "[EPOCH 271] TEST ACCURACY: 85.000\n",
            "2.1750882416963577\n",
            "2.2966471016407013\n",
            "2.2309699058532715\n",
            "2.189646452665329\n",
            "2.021949455142021\n",
            "[EPOCH 276] VALID ACCURACY: 89.583\n",
            "[EPOCH 276] TEST ACCURACY: 85.000\n",
            "1.9886859059333801\n",
            "2.00239734351635\n",
            "1.9523090869188309\n",
            "2.26689013838768\n",
            "2.096396893262863\n",
            "[EPOCH 281] VALID ACCURACY: 89.583\n",
            "[EPOCH 281] TEST ACCURACY: 85.000\n",
            "2.0001907646656036\n",
            "2.062794268131256\n",
            "2.0532270669937134\n",
            "1.9105761796236038\n",
            "1.9281013906002045\n",
            "[EPOCH 286] VALID ACCURACY: 89.583\n",
            "[EPOCH 286] TEST ACCURACY: 85.000\n",
            "2.006734162569046\n",
            "2.0702940821647644\n",
            "2.0314192473888397\n",
            "1.8182577639818192\n",
            "1.4946333765983582\n",
            "[EPOCH 291] VALID ACCURACY: 89.583\n",
            "[EPOCH 291] TEST ACCURACY: 85.000\n",
            "1.9516572207212448\n",
            "1.5250257849693298\n",
            "1.656455159187317\n",
            "1.4879541397094727\n",
            "1.2322158068418503\n",
            "[EPOCH 296] VALID ACCURACY: 95.833\n",
            "[EPOCH 296] TEST ACCURACY: 85.000\n",
            "1.53006973862648\n",
            "1.2832142114639282\n",
            "1.4357332438230515\n",
            "1.2867347449064255\n",
            "Average best validation accuracy from all folds: 96.39668655395508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKGv2A3qbmY0",
        "outputId": "f89c5345-4e31-4193-b3d1-ff901f96dd05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training begins now.\n",
            "89.22543382644653\n",
            "[EPOCH 1] VALID ACCURACY: 65.079\n",
            "[EPOCH 1] TEST ACCURACY: 62.360\n",
            "20.115480542182922\n",
            "20.678373992443085\n",
            "11.474108695983887\n",
            "10.17888456583023\n",
            "9.730381727218628\n",
            "[EPOCH 6] VALID ACCURACY: 65.079\n",
            "[EPOCH 6] TEST ACCURACY: 62.360\n",
            "10.050664901733398\n",
            "9.731226563453674\n",
            "9.303329765796661\n",
            "9.529983758926392\n",
            "9.52000641822815\n",
            "[EPOCH 11] VALID ACCURACY: 65.079\n",
            "[EPOCH 11] TEST ACCURACY: 62.360\n",
            "9.400119483470917\n",
            "9.583492517471313\n",
            "9.384684383869171\n",
            "9.478683829307556\n",
            "9.23806631565094\n",
            "[EPOCH 16] VALID ACCURACY: 65.079\n",
            "[EPOCH 16] TEST ACCURACY: 62.360\n",
            "9.372901797294617\n",
            "9.287330687046051\n",
            "9.257178127765656\n",
            "9.056545376777649\n",
            "8.994894623756409\n",
            "[EPOCH 21] VALID ACCURACY: 65.079\n",
            "[EPOCH 21] TEST ACCURACY: 62.360\n",
            "8.603565275669098\n",
            "7.221938371658325\n",
            "4.769300639629364\n",
            "3.3203458935022354\n",
            "3.334886595606804\n",
            "[EPOCH 26] VALID ACCURACY: 88.095\n",
            "[EPOCH 26] TEST ACCURACY: 89.326\n",
            "3.1660322844982147\n",
            "3.006790593266487\n",
            "2.880059242248535\n",
            "11.621533542871475\n",
            "8.2086780667305\n",
            "[EPOCH 31] VALID ACCURACY: 88.095\n",
            "[EPOCH 31] TEST ACCURACY: 89.326\n",
            "3.9023230224847794\n",
            "3.583435907959938\n",
            "3.700293928384781\n",
            "3.524839475750923\n",
            "3.0333989188075066\n",
            "[EPOCH 36] VALID ACCURACY: 88.095\n",
            "[EPOCH 36] TEST ACCURACY: 89.326\n",
            "3.100567474961281\n",
            "2.8951303213834763\n",
            "3.006611004471779\n",
            "2.6910848021507263\n",
            "2.707926094532013\n",
            "[EPOCH 41] VALID ACCURACY: 88.889\n",
            "[EPOCH 41] TEST ACCURACY: 89.326\n",
            "2.8873465061187744\n",
            "2.6743358969688416\n",
            "2.3655921816825867\n",
            "2.6295373141765594\n",
            "2.542350612580776\n",
            "[EPOCH 46] VALID ACCURACY: 91.270\n",
            "[EPOCH 46] TEST ACCURACY: 93.820\n",
            "2.0623845160007477\n",
            "1.7588919252157211\n",
            "1.7173642367124557\n",
            "2.2970090433955193\n",
            "1.760981746017933\n",
            "[EPOCH 51] VALID ACCURACY: 92.857\n",
            "[EPOCH 51] TEST ACCURACY: 95.506\n",
            "1.797180712223053\n",
            "1.5884492993354797\n",
            "1.5939582474529743\n",
            "1.6556213982403278\n",
            "1.7075019478797913\n",
            "[EPOCH 56] VALID ACCURACY: 93.651\n",
            "[EPOCH 56] TEST ACCURACY: 96.067\n",
            "1.7452391162514687\n",
            "1.4857930913567543\n",
            "1.6508351266384125\n",
            "1.837908137589693\n",
            "2.037333868443966\n",
            "[EPOCH 61] VALID ACCURACY: 93.651\n",
            "[EPOCH 61] TEST ACCURACY: 96.067\n",
            "1.7748909071087837\n",
            "1.5485343672335148\n",
            "1.5596447512507439\n",
            "1.5750362500548363\n",
            "1.492501925677061\n",
            "[EPOCH 66] VALID ACCURACY: 93.651\n",
            "[EPOCH 66] TEST ACCURACY: 96.067\n",
            "1.472757764160633\n",
            "1.4002756848931313\n",
            "1.4006936140358448\n",
            "1.4454199075698853\n",
            "1.5273016169667244\n",
            "[EPOCH 71] VALID ACCURACY: 93.651\n",
            "[EPOCH 71] TEST ACCURACY: 96.067\n",
            "1.523727923631668\n",
            "1.429172858595848\n",
            "1.3177350237965584\n",
            "1.4181780889630318\n",
            "1.5021716132760048\n",
            "[EPOCH 76] VALID ACCURACY: 93.651\n",
            "[EPOCH 76] TEST ACCURACY: 96.067\n",
            "1.4957865923643112\n",
            "1.5158605221658945\n",
            "1.5390825867652893\n",
            "1.622266249731183\n",
            "1.4595576897263527\n",
            "[EPOCH 81] VALID ACCURACY: 93.651\n",
            "[EPOCH 81] TEST ACCURACY: 96.067\n",
            "9.264007210731506\n",
            "8.582053035497665\n",
            "10.196896120905876\n",
            "4.203616410493851\n",
            "3.552958145737648\n",
            "[EPOCH 86] VALID ACCURACY: 88.095\n",
            "[EPOCH 86] TEST ACCURACY: 89.326\n",
            "2.2733957022428513\n",
            "1.7870820052921772\n",
            "1.836317103356123\n",
            "1.7680359706282616\n",
            "1.4802015125751495\n",
            "[EPOCH 91] VALID ACCURACY: 93.651\n",
            "[EPOCH 91] TEST ACCURACY: 96.067\n",
            "1.5813638307154179\n",
            "1.7511602155864239\n",
            "1.9625353440642357\n",
            "1.549139715731144\n",
            "1.5694839768111706\n",
            "[EPOCH 96] VALID ACCURACY: 93.651\n",
            "[EPOCH 96] TEST ACCURACY: 96.067\n",
            "1.4866707175970078\n",
            "1.4401552751660347\n",
            "1.4753215461969376\n",
            "1.3934361040592194\n",
            "1.5519734993577003\n",
            "[EPOCH 101] VALID ACCURACY: 93.651\n",
            "[EPOCH 101] TEST ACCURACY: 96.067\n",
            "1.4250495694577694\n",
            "1.288283810019493\n",
            "1.5030241161584854\n",
            "1.3269217237830162\n",
            "1.4945943728089333\n",
            "[EPOCH 106] VALID ACCURACY: 93.651\n",
            "[EPOCH 106] TEST ACCURACY: 96.067\n",
            "1.4711275100708008\n",
            "1.4545529037714005\n",
            "1.406073946505785\n",
            "1.3353495262563229\n",
            "1.4312692172825336\n",
            "[EPOCH 111] VALID ACCURACY: 93.651\n",
            "[EPOCH 111] TEST ACCURACY: 96.067\n",
            "1.4764482900500298\n",
            "1.347204651683569\n",
            "1.4538876712322235\n",
            "1.5108102187514305\n",
            "1.4043019581586123\n",
            "[EPOCH 116] VALID ACCURACY: 93.651\n",
            "[EPOCH 116] TEST ACCURACY: 96.067\n",
            "1.3604789152741432\n",
            "1.3597638383507729\n",
            "1.358358971774578\n",
            "1.3621230348944664\n",
            "1.3554149866104126\n",
            "[EPOCH 121] VALID ACCURACY: 93.651\n",
            "[EPOCH 121] TEST ACCURACY: 96.067\n",
            "1.307777762413025\n",
            "1.4080083221197128\n",
            "1.343239463865757\n",
            "1.3466124385595322\n",
            "1.661079116165638\n",
            "[EPOCH 126] VALID ACCURACY: 93.651\n",
            "[EPOCH 126] TEST ACCURACY: 96.067\n",
            "1.730744682252407\n",
            "1.5176442973315716\n",
            "2.0365262404084206\n",
            "3.046879731118679\n",
            "2.172418251633644\n",
            "[EPOCH 131] VALID ACCURACY: 92.857\n",
            "[EPOCH 131] TEST ACCURACY: 95.506\n",
            "1.74994395673275\n",
            "1.8078157044947147\n",
            "1.6147213727235794\n",
            "2.0897625014185905\n",
            "1.7585640773177147\n",
            "[EPOCH 136] VALID ACCURACY: 93.651\n",
            "[EPOCH 136] TEST ACCURACY: 94.944\n",
            "1.8485030382871628\n",
            "1.5745827294886112\n",
            "1.4448351338505745\n",
            "1.4069428369402885\n",
            "1.4221282936632633\n",
            "[EPOCH 141] VALID ACCURACY: 93.651\n",
            "[EPOCH 141] TEST ACCURACY: 96.067\n",
            "1.3194585219025612\n",
            "1.4129590317606926\n",
            "1.4292988330125809\n",
            "1.4516057409346104\n",
            "1.4085623025894165\n",
            "[EPOCH 146] VALID ACCURACY: 93.651\n",
            "[EPOCH 146] TEST ACCURACY: 96.067\n",
            "1.4694794192910194\n",
            "1.3964385613799095\n",
            "1.4181584492325783\n",
            "1.439490556716919\n",
            "1.4354656115174294\n",
            "[EPOCH 151] VALID ACCURACY: 93.651\n",
            "[EPOCH 151] TEST ACCURACY: 96.067\n",
            "1.4339469783008099\n",
            "1.6351501867175102\n",
            "1.3579389229416847\n",
            "1.5043901093304157\n",
            "1.3335930481553078\n",
            "[EPOCH 156] VALID ACCURACY: 93.651\n",
            "[EPOCH 156] TEST ACCURACY: 95.506\n",
            "1.4277598485350609\n",
            "1.3114714697003365\n",
            "1.5315314754843712\n",
            "1.3501077443361282\n",
            "1.4242787882685661\n",
            "[EPOCH 161] VALID ACCURACY: 93.651\n",
            "[EPOCH 161] TEST ACCURACY: 96.067\n",
            "1.4100481308996677\n",
            "1.353558637201786\n",
            "1.3276698142290115\n",
            "1.3441359959542751\n",
            "1.4166353419423103\n",
            "[EPOCH 166] VALID ACCURACY: 93.651\n",
            "[EPOCH 166] TEST ACCURACY: 96.067\n",
            "1.351412445306778\n",
            "1.4782305136322975\n",
            "1.5188363566994667\n",
            "1.3931968361139297\n",
            "1.3806320130825043\n",
            "[EPOCH 171] VALID ACCURACY: 93.651\n",
            "[EPOCH 171] TEST ACCURACY: 96.067\n",
            "1.339515831321478\n",
            "1.3021219074726105\n",
            "1.3491969555616379\n",
            "1.317367285490036\n",
            "1.3015726618468761\n",
            "[EPOCH 176] VALID ACCURACY: 93.651\n",
            "[EPOCH 176] TEST ACCURACY: 96.067\n",
            "1.2967474386096\n",
            "1.2439516596496105\n",
            "1.3110091798007488\n",
            "1.2167848981916904\n",
            "1.2961843088269234\n",
            "[EPOCH 181] VALID ACCURACY: 93.651\n",
            "[EPOCH 181] TEST ACCURACY: 96.067\n",
            "1.2696749679744244\n",
            "1.2474063262343407\n",
            "1.2647693185135722\n",
            "1.2111767940223217\n",
            "1.2735892944037914\n",
            "[EPOCH 186] VALID ACCURACY: 94.444\n",
            "[EPOCH 186] TEST ACCURACY: 96.629\n",
            "1.233634077012539\n",
            "1.2335757836699486\n",
            "1.330484714359045\n",
            "1.2448073476552963\n",
            "1.179966263473034\n",
            "[EPOCH 191] VALID ACCURACY: 96.032\n",
            "[EPOCH 191] TEST ACCURACY: 95.506\n",
            "1.2151160389184952\n",
            "1.239593155682087\n",
            "1.1123462095856667\n",
            "1.211499359458685\n",
            "1.34510887414217\n",
            "[EPOCH 196] VALID ACCURACY: 93.651\n",
            "[EPOCH 196] TEST ACCURACY: 96.629\n",
            "0.9717927686870098\n",
            "1.166555605828762\n",
            "1.0958659686148167\n",
            "1.180737417191267\n",
            "0.9923273585736752\n",
            "[EPOCH 201] VALID ACCURACY: 96.032\n",
            "[EPOCH 201] TEST ACCURACY: 97.191\n",
            "1.1346184089779854\n",
            "0.9842760488390923\n",
            "0.9989991188049316\n",
            "1.2793972454965115\n",
            "1.2100228536874056\n",
            "[EPOCH 206] VALID ACCURACY: 95.238\n",
            "[EPOCH 206] TEST ACCURACY: 96.629\n",
            "1.199645895510912\n",
            "1.657099038362503\n",
            "1.450111037120223\n",
            "2.240778863430023\n",
            "1.427610658109188\n",
            "[EPOCH 211] VALID ACCURACY: 95.238\n",
            "[EPOCH 211] TEST ACCURACY: 97.191\n",
            "1.2189494110643864\n",
            "1.0690388432703912\n",
            "1.0723318234086037\n",
            "1.0255103074014187\n",
            "0.8933999668806791\n",
            "[EPOCH 216] VALID ACCURACY: 96.032\n",
            "[EPOCH 216] TEST ACCURACY: 98.315\n",
            "0.9654300026595592\n",
            "0.8818335309624672\n",
            "0.8956813402473927\n",
            "0.940015172585845\n",
            "0.9192075319588184\n",
            "[EPOCH 221] VALID ACCURACY: 96.032\n",
            "[EPOCH 221] TEST ACCURACY: 98.315\n",
            "0.9489711858332157\n",
            "0.9829009082168341\n",
            "0.9940182641148567\n",
            "1.006546288728714\n",
            "0.9762768372893333\n",
            "[EPOCH 226] VALID ACCURACY: 96.032\n",
            "[EPOCH 226] TEST ACCURACY: 98.315\n",
            "1.2534518223255873\n",
            "1.1033624298870564\n",
            "0.9970785528421402\n",
            "1.5437584267929196\n",
            "1.0937116974964738\n",
            "[EPOCH 231] VALID ACCURACY: 95.238\n",
            "[EPOCH 231] TEST ACCURACY: 94.382\n",
            "8.951351419091225\n",
            "12.207770556211472\n",
            "12.06656214594841\n",
            "269.70519122481346\n",
            "504.9809112548828\n",
            "[EPOCH 236] VALID ACCURACY: 65.079\n",
            "[EPOCH 236] TEST ACCURACY: 62.360\n",
            "355.9758930206299\n",
            "152.6549153327942\n",
            "102.52682209014893\n",
            "104.31155395507812\n",
            "17.811558574438095\n",
            "[EPOCH 241] VALID ACCURACY: 93.651\n",
            "[EPOCH 241] TEST ACCURACY: 96.067\n",
            "9.679915376007557\n",
            "6.613263092935085\n",
            "5.305852023884654\n",
            "3.166922790929675\n",
            "2.5773050598800182\n",
            "[EPOCH 246] VALID ACCURACY: 93.651\n",
            "[EPOCH 246] TEST ACCURACY: 96.067\n",
            "20.927228286862373\n",
            "26.88908041268587\n",
            "7.279492437839508\n",
            "5.953347288072109\n",
            "2.50450935959816\n",
            "[EPOCH 251] VALID ACCURACY: 93.651\n",
            "[EPOCH 251] TEST ACCURACY: 96.067\n",
            "1.983037330210209\n",
            "1.6315304264426231\n",
            "1.3692098334431648\n",
            "1.6678822375833988\n",
            "1.4639319237321615\n",
            "[EPOCH 256] VALID ACCURACY: 93.651\n",
            "[EPOCH 256] TEST ACCURACY: 96.067\n",
            "1.1336414497345686\n",
            "1.2795797493308783\n",
            "1.2704428769648075\n",
            "1.152136281132698\n",
            "1.2503241039812565\n",
            "[EPOCH 261] VALID ACCURACY: 93.651\n",
            "[EPOCH 261] TEST ACCURACY: 96.629\n",
            "1.3633069600909948\n",
            "1.1066479245200753\n",
            "1.172690350562334\n",
            "1.2759369798004627\n",
            "1.160200111567974\n",
            "[EPOCH 266] VALID ACCURACY: 93.651\n",
            "[EPOCH 266] TEST ACCURACY: 97.191\n",
            "1.1671191714704037\n",
            "1.1125893220305443\n",
            "1.1336194351315498\n",
            "1.2299602888524532\n",
            "1.1419622674584389\n",
            "[EPOCH 271] VALID ACCURACY: 93.651\n",
            "[EPOCH 271] TEST ACCURACY: 96.067\n",
            "1.0893260687589645\n",
            "1.1876765303313732\n",
            "1.3167889900505543\n",
            "1.380779456347227\n",
            "1.1013853251934052\n",
            "[EPOCH 276] VALID ACCURACY: 93.651\n",
            "[EPOCH 276] TEST ACCURACY: 97.753\n",
            "1.0902370102703571\n",
            "1.099999327212572\n",
            "1.300687301903963\n",
            "1.3156669568270445\n",
            "1.1702182199805975\n",
            "[EPOCH 281] VALID ACCURACY: 93.651\n",
            "[EPOCH 281] TEST ACCURACY: 96.629\n",
            "1.2299801036715508\n",
            "1.229877669364214\n",
            "1.2455346882343292\n",
            "1.1097424179315567\n",
            "1.1186901796609163\n",
            "[EPOCH 286] VALID ACCURACY: 93.651\n",
            "[EPOCH 286] TEST ACCURACY: 96.629\n",
            "1.0770978778600693\n",
            "1.1178936250507832\n",
            "1.1796517670154572\n",
            "1.653036616742611\n",
            "1.071281936019659\n",
            "[EPOCH 291] VALID ACCURACY: 94.444\n",
            "[EPOCH 291] TEST ACCURACY: 97.753\n",
            "1.2325575612485409\n",
            "1.369962677359581\n",
            "1.418830219656229\n",
            "6.88034859392792\n",
            "3.589356854557991\n",
            "[EPOCH 296] VALID ACCURACY: 93.651\n",
            "[EPOCH 296] TEST ACCURACY: 94.944\n",
            "2.9241715893149376\n",
            "6.066289067268372\n",
            "3.374172732234001\n",
            "1.7462030686438084\n",
            "1.930608794093132\n",
            "[EPOCH 301] VALID ACCURACY: 93.651\n",
            "[EPOCH 301] TEST ACCURACY: 94.382\n",
            "1.6062250435352325\n",
            "1.5548584200441837\n",
            "1.5033766031265259\n",
            "1.3926848657429218\n",
            "1.6503885313868523\n",
            "[EPOCH 306] VALID ACCURACY: 93.651\n",
            "[EPOCH 306] TEST ACCURACY: 96.067\n",
            "1.7418777756392956\n",
            "1.8349721431732178\n",
            "1.5474208034574986\n",
            "1.7111532613635063\n",
            "1.574302963912487\n",
            "[EPOCH 311] VALID ACCURACY: 93.651\n",
            "[EPOCH 311] TEST ACCURACY: 96.067\n",
            "1.6972716115415096\n",
            "1.3086612224578857\n",
            "1.3536631725728512\n",
            "1.2902373149991035\n",
            "1.3863415140658617\n",
            "[EPOCH 316] VALID ACCURACY: 93.651\n",
            "[EPOCH 316] TEST ACCURACY: 96.067\n",
            "1.6246298924088478\n",
            "1.2453516758978367\n",
            "1.3192030414938927\n",
            "1.4608699344098568\n",
            "1.3222789987921715\n",
            "[EPOCH 321] VALID ACCURACY: 93.651\n",
            "[EPOCH 321] TEST ACCURACY: 97.191\n",
            "1.1389865018427372\n",
            "1.1212673485279083\n",
            "1.2918898686766624\n",
            "1.2986480332911015\n",
            "1.22767448797822\n",
            "[EPOCH 326] VALID ACCURACY: 93.651\n",
            "[EPOCH 326] TEST ACCURACY: 97.191\n",
            "1.2761923167854548\n",
            "1.2818704545497894\n",
            "1.1749602034687996\n",
            "1.1605057828128338\n",
            "1.175451673567295\n",
            "[EPOCH 331] VALID ACCURACY: 94.444\n",
            "[EPOCH 331] TEST ACCURACY: 96.629\n",
            "1.097279205918312\n",
            "0.9323918055742979\n",
            "1.1309684738516808\n",
            "1.0613080263137817\n",
            "1.208131529390812\n",
            "[EPOCH 336] VALID ACCURACY: 93.651\n",
            "[EPOCH 336] TEST ACCURACY: 97.753\n",
            "1.0025301985442638\n",
            "1.2217040993273258\n",
            "1.0648954473435879\n",
            "1.0291870534420013\n",
            "1.1088134814053774\n",
            "[EPOCH 341] VALID ACCURACY: 94.444\n",
            "[EPOCH 341] TEST ACCURACY: 97.191\n",
            "1.2249866276979446\n",
            "1.1630016937851906\n",
            "1.0822831019759178\n",
            "1.081883266568184\n",
            "1.04142009280622\n",
            "[EPOCH 346] VALID ACCURACY: 93.651\n",
            "[EPOCH 346] TEST ACCURACY: 97.753\n",
            "1.0836214944720268\n",
            "1.1770406365394592\n",
            "0.978111419826746\n",
            "1.1212866697460413\n",
            "1.061487551778555\n",
            "[EPOCH 351] VALID ACCURACY: 94.444\n",
            "[EPOCH 351] TEST ACCURACY: 97.753\n",
            "1.0324505306780338\n",
            "0.95392831787467\n",
            "1.0678302273154259\n",
            "0.9954748786985874\n",
            "1.0461138039827347\n",
            "[EPOCH 356] VALID ACCURACY: 94.444\n",
            "[EPOCH 356] TEST ACCURACY: 98.315\n",
            "1.0284265168011189\n",
            "1.0879232212901115\n",
            "0.9397736173123121\n",
            "1.2256344109773636\n",
            "1.0213170573115349\n",
            "[EPOCH 361] VALID ACCURACY: 93.651\n",
            "[EPOCH 361] TEST ACCURACY: 98.315\n",
            "1.0083677172660828\n",
            "1.0534640811383724\n",
            "1.0939460583031178\n",
            "1.183490239083767\n",
            "5.886121205985546\n",
            "[EPOCH 366] VALID ACCURACY: 93.651\n",
            "[EPOCH 366] TEST ACCURACY: 96.629\n",
            "1.2784728705883026\n",
            "1.6595745403319597\n",
            "2.456629387103021\n",
            "1.3885800056159496\n",
            "2.061898468993604\n",
            "[EPOCH 371] VALID ACCURACY: 93.651\n",
            "[EPOCH 371] TEST ACCURACY: 97.191\n",
            "1.7812061766162515\n",
            "1.3727219514548779\n",
            "1.3585573583841324\n",
            "1.2293780520558357\n",
            "1.3103050142526627\n",
            "[EPOCH 376] VALID ACCURACY: 94.444\n",
            "[EPOCH 376] TEST ACCURACY: 97.191\n",
            "1.1424464341253042\n",
            "1.1255776435136795\n",
            "1.0768648232333362\n",
            "1.0484306290745735\n",
            "1.1093789301812649\n",
            "[EPOCH 381] VALID ACCURACY: 94.444\n",
            "[EPOCH 381] TEST ACCURACY: 97.753\n",
            "1.0823742467910051\n",
            "1.112222220748663\n",
            "1.070237128995359\n",
            "1.2035695612430573\n",
            "1.2646392369642854\n",
            "[EPOCH 386] VALID ACCURACY: 93.651\n",
            "[EPOCH 386] TEST ACCURACY: 97.191\n",
            "1.2475424036383629\n",
            "1.1309278719127178\n",
            "1.0132493823766708\n",
            "0.973462663590908\n",
            "1.191636323928833\n",
            "[EPOCH 391] VALID ACCURACY: 95.238\n",
            "[EPOCH 391] TEST ACCURACY: 96.629\n",
            "1.1959647051990032\n",
            "0.9676899397745728\n",
            "1.1474434100091457\n",
            "1.1875374130904675\n",
            "1.3169675543904305\n",
            "[EPOCH 396] VALID ACCURACY: 96.032\n",
            "[EPOCH 396] TEST ACCURACY: 97.191\n",
            "1.196761529892683\n",
            "1.040692761540413\n",
            "1.0303328447043896\n",
            "1.2205302752554417\n",
            "1.0243535190820694\n",
            "[EPOCH 401] VALID ACCURACY: 93.651\n",
            "[EPOCH 401] TEST ACCURACY: 97.753\n",
            "1.0946228578686714\n",
            "1.1212803162634373\n",
            "1.0417019352316856\n",
            "0.9427122212946415\n",
            "1.0290662217885256\n",
            "[EPOCH 406] VALID ACCURACY: 95.238\n",
            "[EPOCH 406] TEST ACCURACY: 98.315\n",
            "1.0549302687868476\n",
            "0.9901113659143448\n",
            "0.9238313399255276\n",
            "1.1325005553662777\n",
            "1.0700465701520443\n",
            "[EPOCH 411] VALID ACCURACY: 93.651\n",
            "[EPOCH 411] TEST ACCURACY: 96.629\n",
            "0.9044069033116102\n",
            "1.2130183577537537\n",
            "1.0716562438756227\n",
            "1.1794642843306065\n",
            "1.2000442631542683\n",
            "[EPOCH 416] VALID ACCURACY: 93.651\n",
            "[EPOCH 416] TEST ACCURACY: 96.629\n",
            "1.0671941954642534\n",
            "0.9584247134625912\n",
            "1.0201169215142727\n",
            "0.9821749702095985\n",
            "1.2566922679543495\n",
            "[EPOCH 421] VALID ACCURACY: 93.651\n",
            "[EPOCH 421] TEST ACCURACY: 96.629\n",
            "1.08341608569026\n",
            "0.9802826978266239\n",
            "0.9699515365064144\n",
            "1.0246078819036484\n",
            "0.9581491183489561\n",
            "[EPOCH 426] VALID ACCURACY: 93.651\n",
            "[EPOCH 426] TEST ACCURACY: 96.629\n",
            "1.0323726739734411\n",
            "1.141075562685728\n",
            "1.0788538567721844\n",
            "1.232487853616476\n",
            "1.0984080657362938\n",
            "[EPOCH 431] VALID ACCURACY: 94.444\n",
            "[EPOCH 431] TEST ACCURACY: 97.753\n",
            "1.0992085188627243\n",
            "1.213592804968357\n",
            "1.3231230042874813\n",
            "1.0957835763692856\n",
            "1.0468299090862274\n",
            "[EPOCH 436] VALID ACCURACY: 93.651\n",
            "[EPOCH 436] TEST ACCURACY: 97.191\n",
            "0.9057547394186258\n",
            "1.0135433226823807\n",
            "1.022640932817012\n",
            "9.730880320072174\n",
            "2.433684229850769\n",
            "[EPOCH 441] VALID ACCURACY: 93.651\n",
            "[EPOCH 441] TEST ACCURACY: 96.067\n",
            "1.8900481462478638\n",
            "2.5452965078875422\n",
            "2.1204015370458364\n",
            "2.8005523160099983\n",
            "1.9622464179992676\n",
            "[EPOCH 446] VALID ACCURACY: 94.444\n",
            "[EPOCH 446] TEST ACCURACY: 97.191\n",
            "2.0803221240639687\n",
            "1.3021042067557573\n",
            "1.5091994851827621\n",
            "1.1370857506990433\n",
            "1.1380244437605143\n",
            "[EPOCH 451] VALID ACCURACY: 93.651\n",
            "[EPOCH 451] TEST ACCURACY: 97.191\n",
            "1.1267023645341396\n",
            "0.9887572713196278\n",
            "1.024301502853632\n",
            "1.0076027121394873\n",
            "1.0485916398465633\n",
            "[EPOCH 456] VALID ACCURACY: 93.651\n",
            "[EPOCH 456] TEST ACCURACY: 96.629\n",
            "1.0079242214560509\n",
            "1.1649194695055485\n",
            "0.9963599666953087\n",
            "0.9849377013742924\n",
            "1.0354948434978724\n",
            "[EPOCH 461] VALID ACCURACY: 96.032\n",
            "[EPOCH 461] TEST ACCURACY: 98.315\n",
            "1.0507628191262484\n",
            "1.0011709779500961\n",
            "1.0403068996965885\n",
            "0.9844935014843941\n",
            "1.0659531019628048\n",
            "[EPOCH 466] VALID ACCURACY: 96.032\n",
            "[EPOCH 466] TEST ACCURACY: 98.315\n",
            "1.0025076121091843\n",
            "0.9921787902712822\n",
            "1.0452460600063205\n",
            "1.0811097892001271\n",
            "0.9313179068267345\n",
            "[EPOCH 471] VALID ACCURACY: 96.032\n",
            "[EPOCH 471] TEST ACCURACY: 98.315\n",
            "1.0117629561573267\n",
            "1.1419519083574414\n",
            "1.0817846544086933\n",
            "1.709257691167295\n",
            "0.9107706248760223\n",
            "[EPOCH 476] VALID ACCURACY: 94.444\n",
            "[EPOCH 476] TEST ACCURACY: 97.753\n",
            "0.919823320582509\n",
            "1.0142183415591717\n",
            "1.0288638658821583\n",
            "0.9419013857841492\n",
            "0.9604153335094452\n",
            "[EPOCH 481] VALID ACCURACY: 95.238\n",
            "[EPOCH 481] TEST ACCURACY: 98.315\n",
            "0.9852010421454906\n",
            "1.013786245137453\n",
            "0.9617840088903904\n",
            "0.9193804450333118\n",
            "0.9892832729965448\n",
            "[EPOCH 486] VALID ACCURACY: 96.825\n",
            "[EPOCH 486] TEST ACCURACY: 98.315\n",
            "0.9704098291695118\n",
            "0.9682795694097877\n",
            "0.8844018131494522\n",
            "0.9994295351207256\n",
            "0.8712839875370264\n",
            "[EPOCH 491] VALID ACCURACY: 96.032\n",
            "[EPOCH 491] TEST ACCURACY: 94.382\n",
            "0.9511062800884247\n",
            "0.928459694609046\n",
            "0.8921299986541271\n",
            "0.9619262292981148\n",
            "1.4877085015177727\n",
            "[EPOCH 496] VALID ACCURACY: 96.032\n",
            "[EPOCH 496] TEST ACCURACY: 97.753\n",
            "0.7757739182561636\n",
            "0.9743800796568394\n",
            "1.1911444906145334\n",
            "0.9554981272667646\n",
            "1.0538952443748713\n",
            "[EPOCH 501] VALID ACCURACY: 96.032\n",
            "[EPOCH 501] TEST ACCURACY: 97.753\n",
            "1.1063674427568913\n",
            "0.9894946096464992\n",
            "0.9213505871593952\n",
            "0.8318527163937688\n",
            "0.9616762455552816\n",
            "[EPOCH 506] VALID ACCURACY: 96.032\n",
            "[EPOCH 506] TEST ACCURACY: 97.753\n",
            "0.8086296636611223\n",
            "0.9335647756233811\n",
            "1.0393205396831036\n",
            "0.8970928937196732\n",
            "0.9398241713643074\n",
            "[EPOCH 511] VALID ACCURACY: 95.238\n",
            "[EPOCH 511] TEST ACCURACY: 97.753\n",
            "0.7953479774296284\n",
            "0.8287501996383071\n",
            "0.8622529786080122\n",
            "0.9056448340415955\n",
            "1.0697485990822315\n",
            "[EPOCH 516] VALID ACCURACY: 95.238\n",
            "[EPOCH 516] TEST ACCURACY: 98.315\n",
            "0.9398968629539013\n",
            "1.0494434684515\n",
            "0.9018869623541832\n",
            "1.15954964235425\n",
            "1.1519407760351896\n",
            "[EPOCH 521] VALID ACCURACY: 95.238\n",
            "[EPOCH 521] TEST ACCURACY: 98.315\n",
            "0.9997190795838833\n",
            "0.8971812594681978\n",
            "0.8908926583826542\n",
            "0.8657055627554655\n",
            "0.8368367739021778\n",
            "[EPOCH 526] VALID ACCURACY: 96.825\n",
            "[EPOCH 526] TEST ACCURACY: 98.315\n",
            "0.816018283367157\n",
            "0.9161892412230372\n",
            "1.1676472499966621\n",
            "1.0332333659753203\n",
            "1.0462369099259377\n",
            "[EPOCH 531] VALID ACCURACY: 93.651\n",
            "[EPOCH 531] TEST ACCURACY: 97.753\n",
            "0.9549622610211372\n",
            "0.8284078668802977\n",
            "0.9643347952514887\n",
            "0.9078853642567992\n",
            "1.1108713578432798\n",
            "[EPOCH 536] VALID ACCURACY: 95.238\n",
            "[EPOCH 536] TEST ACCURACY: 97.753\n",
            "0.8616412095725536\n",
            "0.9087406806647778\n",
            "0.8841830529272556\n",
            "0.8657712051644921\n",
            "0.8312413953244686\n",
            "[EPOCH 541] VALID ACCURACY: 96.032\n",
            "[EPOCH 541] TEST ACCURACY: 98.315\n",
            "1.0135201923549175\n",
            "0.880108599551022\n",
            "0.852162916213274\n",
            "0.927705641835928\n",
            "0.8916870430111885\n",
            "[EPOCH 546] VALID ACCURACY: 96.825\n",
            "[EPOCH 546] TEST ACCURACY: 97.753\n",
            "0.8714458271861076\n",
            "0.9040467962622643\n",
            "0.9878934361040592\n",
            "1.0000203251838684\n",
            "0.979415288195014\n",
            "[EPOCH 551] VALID ACCURACY: 96.825\n",
            "[EPOCH 551] TEST ACCURACY: 97.191\n",
            "0.9184436239302158\n",
            "0.9097824431955814\n",
            "0.9433968709781766\n",
            "0.8712115362286568\n",
            "0.9442721586674452\n",
            "[EPOCH 556] VALID ACCURACY: 96.825\n",
            "[EPOCH 556] TEST ACCURACY: 98.315\n",
            "0.8598089329898357\n",
            "0.8484247885644436\n",
            "0.9112766906619072\n",
            "0.8694664686918259\n",
            "0.8103554546833038\n",
            "[EPOCH 561] VALID ACCURACY: 95.238\n",
            "[EPOCH 561] TEST ACCURACY: 97.191\n",
            "0.937127061188221\n",
            "0.8707615789026022\n",
            "0.8305878601968288\n",
            "0.8806494707241654\n",
            "0.8003271259367466\n",
            "[EPOCH 566] VALID ACCURACY: 93.651\n",
            "[EPOCH 566] TEST ACCURACY: 97.191\n",
            "0.8887122264131904\n",
            "0.9611807856708765\n",
            "0.9242055620998144\n",
            "0.8523977138102055\n",
            "0.8739667162299156\n",
            "[EPOCH 571] VALID ACCURACY: 96.825\n",
            "[EPOCH 571] TEST ACCURACY: 97.753\n",
            "0.8085766304284334\n",
            "0.868395259603858\n",
            "0.8785633873194456\n",
            "0.8054432272911072\n",
            "0.8320500515401363\n",
            "[EPOCH 576] VALID ACCURACY: 96.825\n",
            "[EPOCH 576] TEST ACCURACY: 97.191\n",
            "0.8293458335101604\n",
            "0.9521966986358166\n",
            "0.79733931645751\n",
            "0.9237905237823725\n",
            "0.9251425582915545\n",
            "[EPOCH 581] VALID ACCURACY: 95.238\n",
            "[EPOCH 581] TEST ACCURACY: 98.315\n",
            "0.9009984843432903\n",
            "0.9598587732762098\n",
            "0.8824594020843506\n",
            "0.9452214315533638\n",
            "1.0572637971490622\n",
            "[EPOCH 586] VALID ACCURACY: 95.238\n",
            "[EPOCH 586] TEST ACCURACY: 97.753\n",
            "0.8834360623732209\n",
            "0.9387639379128814\n",
            "0.9570458782836795\n",
            "1.113269528374076\n",
            "0.8874000832438469\n",
            "[EPOCH 591] VALID ACCURACY: 96.825\n",
            "[EPOCH 591] TEST ACCURACY: 97.753\n",
            "0.9435082171112299\n",
            "0.8813959583640099\n",
            "0.8766290880739689\n",
            "0.9108858406543732\n",
            "0.8624269217252731\n",
            "[EPOCH 596] VALID ACCURACY: 95.238\n",
            "[EPOCH 596] TEST ACCURACY: 97.191\n",
            "1.0661156475543976\n",
            "0.8943897821009159\n",
            "0.9206241006031632\n",
            "1.0983260795474052\n",
            "TOTAL NUMBER OF PARAMS: 109770460\n",
            "Accuracy on best model:  98.315\n"
          ]
        }
      ],
      "source": [
        "best_valid_auroc = 0\n",
        "best_valid_accuracy = 0\n",
        "best_test_auroc = 0\n",
        "best_test_accuracy = 0\n",
        "best_valid_rmse = 100000\n",
        "print('Training begins now.')\n",
        "for epoch in range(600):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        optimizer.zero_grad()\n",
        "        # x_categ is the the categorical data, with y appended as last feature. x_cont has continuous data. cat_mask is an array of ones same shape as x_categ except for last column(corresponding to y's) set to 0s. con_mask is an array of ones same shape as x_cont.\n",
        "        x_categ, x_cont, y_gts, cat_mask, con_mask = data[0].to(device), data[1].to(device),data[2].to(device),data[3].to(device),data[4].to(device)\n",
        "        if opt.train_noise_type is not None and opt.train_noise_level>0:\n",
        "            noise_dict = {\n",
        "                'noise_type' : opt.train_noise_type,\n",
        "                'lambda' : opt.train_noise_level\n",
        "            }\n",
        "            if opt.train_noise_type == 'cutmix':\n",
        "                x_categ, x_cont = add_noise(x_categ,x_cont, noise_params = noise_dict)\n",
        "            elif opt.train_noise_type == 'missing':\n",
        "                cat_mask, con_mask = add_noise(cat_mask, con_mask, noise_params = noise_dict)\n",
        "        # We are converting the data to embeddings in the next step\n",
        "        _ , x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask,model)\n",
        "        reps = model.transformer(x_categ_enc, x_cont_enc)\n",
        "        # select only the representations corresponding to y and apply mlp on it in the next step to get the predictions.\n",
        "        y_reps = reps[:,0,:]\n",
        "\n",
        "        y_outs = model.mlpfory(y_reps)\n",
        "        if opt.task == 'regression':\n",
        "            loss = criterion(y_outs,y_gts)\n",
        "        else:\n",
        "            loss = criterion(y_outs,y_gts.squeeze())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    print(running_loss)\n",
        "    if epoch%5==0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                if opt.task in ['binary','multiclass']:\n",
        "                    accuracy, auroc = classification_scores(model, validloader, device, opt.task)\n",
        "                    test_accuracy, test_auroc = classification_scores(model, testloader, device, opt.task)\n",
        "\n",
        "                    print('[EPOCH %d] VALID ACCURACY: %.3f' %\n",
        "                        (epoch + 1, accuracy ))\n",
        "                    print('[EPOCH %d] TEST ACCURACY: %.3f' %\n",
        "                        (epoch + 1, test_accuracy ))\n",
        "\n",
        "                    if opt.task =='multiclass':\n",
        "                        if accuracy > best_valid_accuracy:\n",
        "                            best_valid_accuracy = accuracy\n",
        "                            best_test_auroc = test_auroc\n",
        "                            best_test_accuracy = test_accuracy\n",
        "                            torch.save(model.state_dict(),'%s/bestmodel.pth' % (modelsave_path))\n",
        "                    else:\n",
        "                        if auroc > best_valid_auroc:\n",
        "                            best_valid_auroc = auroc\n",
        "                            best_test_auroc = test_auroc\n",
        "                            best_test_accuracy = test_accuracy\n",
        "                            torch.save(model.state_dict(),'%s/bestmodel.pth' % (modelsave_path))\n",
        "\n",
        "                else:\n",
        "                    valid_rmse = mean_sq_error(model, validloader, device)\n",
        "                    test_rmse = mean_sq_error(model, testloader, device)\n",
        "                    print('[EPOCH %d] VALID RMSE: %.3f' %\n",
        "                        (epoch + 1, valid_rmse ))\n",
        "                    print('[EPOCH %d] TEST RMSE: %.3f' %\n",
        "                        (epoch + 1, test_rmse ))\n",
        "                    if valid_rmse < best_valid_rmse:\n",
        "                        best_valid_rmse = valid_rmse\n",
        "                        best_test_rmse = test_rmse\n",
        "                        torch.save(model.state_dict(),'%s/bestmodel.pth' % (modelsave_path))\n",
        "            model.train()\n",
        "\n",
        "\n",
        "\n",
        "total_parameters = count_parameters(model)\n",
        "print('TOTAL NUMBER OF PARAMS: %d' %(total_parameters))\n",
        "print('Accuracy on best model:  %.3f' %(best_test_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Qdr5YhJc3CW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}