{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7S_phf5KnhAu",
        "outputId": "8c7fd955-dc6f-4ec5-8dd7-f52db2ada828"
      },
      "outputs": [],
      "source": [
        "!git clone https://kekayan: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@github.com/kekayan/progNet-SAINT.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgQlU4gZqmcw",
        "outputId": "e33a82aa-7aeb-4b32-c64b-74ebc22d4c37"
      },
      "outputs": [],
      "source": [
        "%pip install -q einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVLYmdb5pLIX",
        "outputId": "d5b9a5f4-afeb-47d8-d00a-ebfc3eac4040"
      },
      "outputs": [],
      "source": [
        "%cd progNet-SAINT/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RE5tP4RspzL_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EZXlfvHJpPt3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"../data/clinical_and_other_features.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rJ4fblrQqBEq"
      },
      "outputs": [],
      "source": [
        "def data_split(X,y,nan_mask,indices):\n",
        "    x_d = {\n",
        "        'data': X.values[indices],\n",
        "        'mask': nan_mask.values[indices]\n",
        "    }\n",
        "\n",
        "    if x_d['data'].shape != x_d['mask'].shape:\n",
        "        raise'Shape of data not same as that of nan mask!'\n",
        "\n",
        "    y_d = {\n",
        "        'data': y[indices].reshape(-1, 1)\n",
        "    }\n",
        "    return x_d, y_d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9ASN-qSsqHEA"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class DataSetCatCon(Dataset):\n",
        "    def __init__(self, X, Y, cat_cols,task='clf',continuous_mean_std=None):\n",
        "\n",
        "        cat_cols = list(cat_cols)\n",
        "        X_mask =  X['mask'].copy()\n",
        "        X = X['data'].copy()\n",
        "        con_cols = list(set(np.arange(X.shape[1])) - set(cat_cols))\n",
        "        self.X1 = X[:,cat_cols].copy().astype(np.int64) #categorical columns\n",
        "        self.X2 = X[:,con_cols].copy().astype(np.float32) #numerical columns\n",
        "        self.X1_mask = X_mask[:,cat_cols].copy().astype(np.int64) #categorical columns\n",
        "        self.X2_mask = X_mask[:,con_cols].copy().astype(np.int64) #numerical columns\n",
        "        self.y = Y['data']#.astype(np.float32) if regression\n",
        "        self.cls = np.zeros_like(self.y,dtype=int)\n",
        "        self.cls_mask = np.ones_like(self.y,dtype=int)\n",
        "        if continuous_mean_std is not None:\n",
        "            mean, std = continuous_mean_std\n",
        "            self.X2 = (self.X2 - mean) / std\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # X1 has categorical data, X2 has continuous\n",
        "        return np.concatenate((self.cls[idx], self.X1[idx])), self.X2[idx],self.y[idx], np.concatenate((self.cls_mask[idx], self.X1_mask[idx])), self.X2_mask[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9VzlurkiNJs-"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(df):\n",
        "  df1 = df.drop(['Overall Near-complete Response:  Looser Definition','Near-complete Response (Graded Measure)'],axis=1)\n",
        "  df1.columns = df1.columns.str.strip()\n",
        "  X = df1.drop('Overall Near-complete Response:  Stricter Definition',axis=1)\n",
        "  y = df1['Overall Near-complete Response:  Stricter Definition']\n",
        "  cont_columns = ['Date of Birth (Days)', 'Days to Surgery (from the date of diagnosis)', 'Age at last contact in EMR f/u(days)(from the date of diagnosis) ,last time patient known to be alive, unless age of death is reported(in such case the age of death',\n",
        "    'Age at mammo (days)', 'Days to distant recurrence(from the date of diagnosis)', 'Days to local recurrence (from the date of diagnosis)',\n",
        "    'Days to death (from the date of diagnosis)', 'Days to last local recurrence free assessment (from the date of diagnosis)', \n",
        "    ]\n",
        "  categorical_columns = list(set(X.columns) - set(cont_columns))\n",
        "\n",
        "  # convert categorical columns to str type\n",
        "  X[categorical_columns] = X[categorical_columns].astype(str)\n",
        "\n",
        "  cat_idxs = [X.columns.get_loc(c) for c in categorical_columns]\n",
        "  con_idxs = [X.columns.get_loc(c) for c in cont_columns]\n",
        "  X[\"Set\"] = np.random.choice([\"train\", \"valid\", \"test\"], p = [.65, .15, .2], size=(X.shape[0],))\n",
        "\n",
        "  train_indices = X[X.Set==\"train\"].index\n",
        "  valid_indices = X[X.Set==\"valid\"].index\n",
        "  test_indices = X[X.Set==\"test\"].index\n",
        "\n",
        "  X = X.drop(columns=['Set'])\n",
        "  temp = X.fillna(\"MissingValue\")\n",
        "#   creates a bert style mask for the missing values\n",
        "  nan_mask = temp.ne(\"MissingValue\").astype(int)\n",
        "\n",
        "  cat_dims = []\n",
        "  for col in categorical_columns:\n",
        "      X[col] = X[col].fillna(\"MissingValue\")\n",
        "      l_enc = LabelEncoder()\n",
        "      X[col] = l_enc.fit_transform(X[col].values)\n",
        "      cat_dims.append(len(l_enc.classes_))\n",
        "\n",
        "  for col in cont_columns:\n",
        "      X[col] = pd.to_numeric(X[col], errors='coerce')\n",
        "      X.fillna(X.loc[train_indices, col].mean(), inplace=True)\n",
        "  y = y.values\n",
        "  l_enc = LabelEncoder()\n",
        "  y = l_enc.fit_transform(y)\n",
        "  X_train, y_train = data_split(X,y,nan_mask,train_indices)\n",
        "  X_valid, y_valid = data_split(X,y,nan_mask,valid_indices)\n",
        "  X_test, y_test = data_split(X,y,nan_mask,test_indices)\n",
        "  train_mean, train_std = np.array(X_train['data'][:,con_idxs],dtype=np.float32).mean(0), np.array(X_train['data'][:,con_idxs],dtype=np.float32).std(0)\n",
        "  train_std = np.where(train_std < 1e-6, 1e-6, train_std)\n",
        "  continuous_mean_std = np.array([train_mean,train_std]).astype(np.float32)\n",
        "  train_ds = DataSetCatCon(X_train, y_train, cat_idxs,'clf',continuous_mean_std)\n",
        "  trainloader = DataLoader(train_ds, batch_size=64, shuffle=True,num_workers=1)\n",
        "\n",
        "  valid_ds = DataSetCatCon(X_valid, y_valid, cat_idxs,'clf', continuous_mean_std)\n",
        "  validloader = DataLoader(valid_ds, batch_size=64, shuffle=False,num_workers=1)\n",
        "\n",
        "  test_ds = DataSetCatCon(X_test, y_test, cat_idxs,'clf', continuous_mean_std)\n",
        "  testloader = DataLoader(test_ds, batch_size=64, shuffle=False,num_workers=1)\n",
        "  y_dim = len(np.unique(y_train['data'][:,0]))\n",
        "\n",
        "  cat_dims = np.append(np.array([1]),np.array(cat_dims)).astype(int) #Appending 1 for CLS token, this is later used to generate embeddings.\n",
        "\n",
        "  return trainloader, validloader, testloader, cat_dims, con_idxs , cat_idxs, y_dim , continuous_mean_std , X_train, y_train, X_valid, y_valid, X_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "flZw24r6qI4M"
      },
      "outputs": [],
      "source": [
        "trainloader, validloader, testloader, cat_dims, con_idxs , cat_idxs, y_dim , continuous_mean_std, X_train, y_train, X_valid, y_valid, X_test, y_test = prepare_dataset(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from models import SAINT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "upuJoXE5qkHO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from models import SAINT\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from utils import count_parameters, classification_scores, mean_sq_error\n",
        "from augmentations import embed_data_mask\n",
        "from augmentations import add_noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "awsDTKYwqtrz"
      },
      "outputs": [],
      "source": [
        "from pretraining import SAINT_pretrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3V75GTN5qvA7"
      },
      "outputs": [],
      "source": [
        "opt_dict = {\n",
        "    'd_task': 'clf',\n",
        "    'dtask': 'clf',\n",
        "    'task': 'multiclass',\n",
        "    'batchsize': 32,\n",
        "    'pt_aug': ['mixup', 'cutmix'],\n",
        "    'pt_aug_lam': 0.1,\n",
        "    'pretrain_epochs': 80, #50\n",
        "    'nce_temp': 0.7,\n",
        "    'lam0': 0.5,\n",
        "    'lam1': 10,\n",
        "    'lam2': 1,\n",
        "    'lam3': 10,\n",
        "    'pt_projhead_style': 'diff',\n",
        "    'pt_tasks': ['contrastive','denoising'],\n",
        "    'mixup_lam': 0.3,\n",
        "    'ssl_samples': 312,\n",
        "    'lr':0.0001,\n",
        "    'train_noise_type':None,\n",
        "    'train_noise_level':0,\n",
        "}\n",
        "\n",
        "class AttributeDict(dict):\n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__\n",
        "\n",
        "opt = AttributeDict(opt_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BCqdQ2JbqwmR"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYCUsqCOqzPG",
        "outputId": "d917d647-be4c-4ffb-f490-609aaee9b5c6"
      },
      "outputs": [],
      "source": [
        "model = SAINT(\n",
        "categories = tuple(cat_dims),\n",
        "num_continuous = len(con_idxs),\n",
        "dim = 32,              # embedding dimension\n",
        "dim_out = 1,\n",
        "depth = 1,             # depth of the network (nr. of transformer blocks)\n",
        "heads = 8,             # number of attention heads\n",
        "attn_dropout = 0.1,\n",
        "ff_dropout = 0.1,\n",
        "mlp_hidden_mults = (4, 2),\n",
        "cont_embeddings = 'MLP', # options: 'MLP', 'linear', 'hybrid' (MLP with continuous embeddings concatenated to the transformer block outputs)\n",
        "attentiontype = 'colrow', # options: 'col', 'row', 'colrow', 'colrowv2'\n",
        "final_mlp_style = 'sep',\n",
        "y_dim = y_dim\n",
        ")\n",
        "model.to(device)\n",
        "model = SAINT_pretrain(model, cat_idxs,X_train,y_train, continuous_mean_std, opt, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Finetune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4Vq0gpcPZoC"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv('../data/clinical_and_other_features_filtered.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efdaifJ-Sljg",
        "outputId": "da5ae6d3-9f1f-462a-d790-c4b87b425cbd"
      },
      "outputs": [],
      "source": [
        "df.shape == df2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5etGHMlPWoz"
      },
      "outputs": [],
      "source": [
        "trainloader, validloader, testloader, cat_dims, con_idxs , cat_idxs, y_dim , continuous_mean_std, X_train, y_train, X_valid, y_valid, X_test, y_test = prepare_dataset(df2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzxU_sUeq1un",
        "outputId": "71f8dc53-2a5e-4627-ec47-26f4d24971fd"
      },
      "outputs": [],
      "source": [
        "print('We are in semi-supervised learning case')\n",
        "\n",
        "train_bsize = min(opt.ssl_samples//4,opt.batchsize)\n",
        "\n",
        "train_ds = DataSetCatCon(X_train, y_train, cat_idxs,opt.dtask,continuous_mean_std)\n",
        "trainloader = DataLoader(train_ds, batch_size=train_bsize, shuffle=True,num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kexg0KluLMvi"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QH8tAREWBnE5"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.AdamW(model.parameters(),lr=0.001, betas=(0.9,0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Iws3MmrHZ6H"
      },
      "outputs": [],
      "source": [
        "device = 'cuda'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OqZChrQH4kM"
      },
      "outputs": [],
      "source": [
        "modelsave_path='outputs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytMEn18tEa4U",
        "outputId": "7ad6ab5b-49fa-4591-bc24-a93a4e1e2abd"
      },
      "outputs": [],
      "source": [
        "best_valid_auroc = 0\n",
        "best_valid_accuracy = 0\n",
        "best_test_auroc = 0\n",
        "best_test_accuracy = 0\n",
        "best_valid_rmse = 100000\n",
        "print('Training begins now.')\n",
        "for epoch in range(600):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        optimizer.zero_grad()\n",
        "        # x_categ is the the categorical data, with y appended as last feature. x_cont has continuous data. cat_mask is an array of ones same shape as x_categ except for last column(corresponding to y's) set to 0s. con_mask is an array of ones same shape as x_cont.\n",
        "        x_categ, x_cont, y_gts, cat_mask, con_mask = data[0].to(device), data[1].to(device),data[2].to(device),data[3].to(device),data[4].to(device)\n",
        "        if opt.train_noise_type is not None and opt.train_noise_level>0:\n",
        "            noise_dict = {\n",
        "                'noise_type' : opt.train_noise_type,\n",
        "                'lambda' : opt.train_noise_level\n",
        "            }\n",
        "            if opt.train_noise_type == 'cutmix':\n",
        "                x_categ, x_cont = add_noise(x_categ,x_cont, noise_params = noise_dict)\n",
        "            elif opt.train_noise_type == 'missing':\n",
        "                cat_mask, con_mask = add_noise(cat_mask, con_mask, noise_params = noise_dict)\n",
        "        # We are converting the data to embeddings in the next step\n",
        "        _ , x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask,model)\n",
        "        reps = model.transformer(x_categ_enc, x_cont_enc)\n",
        "        # select only the representations corresponding to y and apply mlp on it in the next step to get the predictions.\n",
        "        y_reps = reps[:,0,:]\n",
        "\n",
        "        y_outs = model.mlpfory(y_reps)\n",
        "        if opt.task == 'regression':\n",
        "            loss = criterion(y_outs,y_gts)\n",
        "        else:\n",
        "            loss = criterion(y_outs,y_gts.squeeze())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    print(running_loss)\n",
        "    if epoch%5==0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                if opt.task in ['binary','multiclass']:\n",
        "                    accuracy, auroc = classification_scores(model, validloader, device, opt.task)\n",
        "                    test_accuracy, test_auroc = classification_scores(model, testloader, device, opt.task)\n",
        "\n",
        "                    print('[EPOCH %d] VALID ACCURACY: %.3f' %\n",
        "                        (epoch + 1, accuracy ))\n",
        "                    print('[EPOCH %d] TEST ACCURACY: %.3f' %\n",
        "                        (epoch + 1, test_accuracy ))\n",
        "\n",
        "                    if opt.task =='multiclass':\n",
        "                        if accuracy > best_valid_accuracy:\n",
        "                            best_valid_accuracy = accuracy\n",
        "                            best_test_auroc = test_auroc\n",
        "                            best_test_accuracy = test_accuracy\n",
        "                            torch.save(model.state_dict(),'%s/bestmodel.pth' % (modelsave_path))\n",
        "                    else:\n",
        "                        if auroc > best_valid_auroc:\n",
        "                            best_valid_auroc = auroc\n",
        "                            best_test_auroc = test_auroc\n",
        "                            best_test_accuracy = test_accuracy\n",
        "                            torch.save(model.state_dict(),'%s/bestmodel.pth' % (modelsave_path))\n",
        "\n",
        "                else:\n",
        "                    valid_rmse = mean_sq_error(model, validloader, device)\n",
        "                    test_rmse = mean_sq_error(model, testloader, device)\n",
        "                    print('[EPOCH %d] VALID RMSE: %.3f' %\n",
        "                        (epoch + 1, valid_rmse ))\n",
        "                    print('[EPOCH %d] TEST RMSE: %.3f' %\n",
        "                        (epoch + 1, test_rmse ))\n",
        "                    if valid_rmse < best_valid_rmse:\n",
        "                        best_valid_rmse = valid_rmse\n",
        "                        best_test_rmse = test_rmse\n",
        "                        torch.save(model.state_dict(),'%s/bestmodel.pth' % (modelsave_path))\n",
        "            model.train()\n",
        "\n",
        "\n",
        "\n",
        "total_parameters = count_parameters(model)\n",
        "print('TOTAL NUMBER OF PARAMS: %d' %(total_parameters))\n",
        "print('Accuracy on best model:  %.3f' %(best_test_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1TMhY58W9--"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd7l1wK-bjL7"
      },
      "source": [
        "### without pre train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AgUEyhee6Ew"
      },
      "outputs": [],
      "source": [
        "model = SAINT(\n",
        "categories = tuple(cat_dims),\n",
        "num_continuous = len(con_idxs),\n",
        "dim = 32,              # embedding dimension\n",
        "dim_out = 1,\n",
        "depth = 1,             # depth of the network (nr. of transformer blocks)\n",
        "heads = 8,             # number of attention heads\n",
        "attn_dropout = 0.1,\n",
        "ff_dropout = 0.1,\n",
        "mlp_hidden_mults = (4, 2),\n",
        "cont_embeddings = 'MLP', # options: 'MLP', 'linear', 'hybrid' (MLP with continuous embeddings concatenated to the transformer block outputs)\n",
        "attentiontype = 'colrow', # options: 'col', 'row', 'colrow', 'colrowv2'\n",
        "final_mlp_style = 'sep',\n",
        "y_dim = y_dim\n",
        ")\n",
        "model.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKGv2A3qbmY0",
        "outputId": "461e5865-418a-4ab1-b06d-546a204273e9"
      },
      "outputs": [],
      "source": [
        "best_valid_auroc = 0\n",
        "best_valid_accuracy = 0\n",
        "best_test_auroc = 0\n",
        "best_test_accuracy = 0\n",
        "best_valid_rmse = 100000\n",
        "print('Training begins now.')\n",
        "for epoch in range(600):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        optimizer.zero_grad()\n",
        "        # x_categ is the the categorical data, with y appended as last feature. x_cont has continuous data. cat_mask is an array of ones same shape as x_categ except for last column(corresponding to y's) set to 0s. con_mask is an array of ones same shape as x_cont.\n",
        "        x_categ, x_cont, y_gts, cat_mask, con_mask = data[0].to(device), data[1].to(device),data[2].to(device),data[3].to(device),data[4].to(device)\n",
        "        if opt.train_noise_type is not None and opt.train_noise_level>0:\n",
        "            noise_dict = {\n",
        "                'noise_type' : opt.train_noise_type,\n",
        "                'lambda' : opt.train_noise_level\n",
        "            }\n",
        "            if opt.train_noise_type == 'cutmix':\n",
        "                x_categ, x_cont = add_noise(x_categ,x_cont, noise_params = noise_dict)\n",
        "            elif opt.train_noise_type == 'missing':\n",
        "                cat_mask, con_mask = add_noise(cat_mask, con_mask, noise_params = noise_dict)\n",
        "        # We are converting the data to embeddings in the next step\n",
        "        _ , x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask,model)\n",
        "        reps = model.transformer(x_categ_enc, x_cont_enc)\n",
        "        # select only the representations corresponding to y and apply mlp on it in the next step to get the predictions.\n",
        "        y_reps = reps[:,0,:]\n",
        "\n",
        "        y_outs = model.mlpfory(y_reps)\n",
        "        if opt.task == 'regression':\n",
        "            loss = criterion(y_outs,y_gts)\n",
        "        else:\n",
        "            loss = criterion(y_outs,y_gts.squeeze())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    print(running_loss)\n",
        "    if epoch%5==0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                if opt.task in ['binary','multiclass']:\n",
        "                    accuracy, auroc = classification_scores(model, validloader, device, opt.task)\n",
        "                    test_accuracy, test_auroc = classification_scores(model, testloader, device, opt.task)\n",
        "\n",
        "                    print('[EPOCH %d] VALID ACCURACY: %.3f' %\n",
        "                        (epoch + 1, accuracy ))\n",
        "                    print('[EPOCH %d] TEST ACCURACY: %.3f' %\n",
        "                        (epoch + 1, test_accuracy ))\n",
        "\n",
        "                    if opt.task =='multiclass':\n",
        "                        if accuracy > best_valid_accuracy:\n",
        "                            best_valid_accuracy = accuracy\n",
        "                            best_test_auroc = test_auroc\n",
        "                            best_test_accuracy = test_accuracy\n",
        "                            torch.save(model.state_dict(),'%s/bestmodel.pth' % (modelsave_path))\n",
        "                    else:\n",
        "                        if auroc > best_valid_auroc:\n",
        "                            best_valid_auroc = auroc\n",
        "                            best_test_auroc = test_auroc\n",
        "                            best_test_accuracy = test_accuracy\n",
        "                            torch.save(model.state_dict(),'%s/bestmodel.pth' % (modelsave_path))\n",
        "\n",
        "                else:\n",
        "                    valid_rmse = mean_sq_error(model, validloader, device)\n",
        "                    test_rmse = mean_sq_error(model, testloader, device)\n",
        "                    print('[EPOCH %d] VALID RMSE: %.3f' %\n",
        "                        (epoch + 1, valid_rmse ))\n",
        "                    print('[EPOCH %d] TEST RMSE: %.3f' %\n",
        "                        (epoch + 1, test_rmse ))\n",
        "                    if valid_rmse < best_valid_rmse:\n",
        "                        best_valid_rmse = valid_rmse\n",
        "                        best_test_rmse = test_rmse\n",
        "                        torch.save(model.state_dict(),'%s/bestmodel.pth' % (modelsave_path))\n",
        "            model.train()\n",
        "\n",
        "\n",
        "\n",
        "total_parameters = count_parameters(model)\n",
        "print('TOTAL NUMBER OF PARAMS: %d' %(total_parameters))\n",
        "print('Accuracy on best model:  %.3f' %(best_test_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Qdr5YhJc3CW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
